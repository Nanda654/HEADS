{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2bdbd6d8eb7541c5975551349618d71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73715692f36a48c8847b0bd53aaf3f32",
              "IPY_MODEL_1da13682bbc74d88a91d622027e0ee5d",
              "IPY_MODEL_faccbf65ddc941b281d4cbb59aeb70ba"
            ],
            "layout": "IPY_MODEL_8ecd530cd87d4aedaa6f0ee5be2d696f"
          }
        },
        "73715692f36a48c8847b0bd53aaf3f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64a971614faf493eb95d658b71fe356b",
            "placeholder": "​",
            "style": "IPY_MODEL_9851bc58b6ac4e37a05efa581651d4f3",
            "value": "vocab.json: "
          }
        },
        "1da13682bbc74d88a91d622027e0ee5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d232dcba5d1d4ac18b431612aee72c3a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3dcc5afeaa674454b7648e841a168abf",
            "value": 1
          }
        },
        "faccbf65ddc941b281d4cbb59aeb70ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b637236afdd64beb8d11296a4262696c",
            "placeholder": "​",
            "style": "IPY_MODEL_7ae74c4cbc8c4108967df576b2432d31",
            "value": " 899k/? [00:00&lt;00:00, 11.3MB/s]"
          }
        },
        "8ecd530cd87d4aedaa6f0ee5be2d696f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64a971614faf493eb95d658b71fe356b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9851bc58b6ac4e37a05efa581651d4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d232dcba5d1d4ac18b431612aee72c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3dcc5afeaa674454b7648e841a168abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b637236afdd64beb8d11296a4262696c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ae74c4cbc8c4108967df576b2432d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb6dedb10c3c4d3caf5d205f585c90ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b84d435c92b430aac8d4aade0092ff9",
              "IPY_MODEL_046ac3860fe944e0adcb7f7a0f0067f5",
              "IPY_MODEL_3fc3bb5ca2904c84a4b5c07fa3e4c4fe"
            ],
            "layout": "IPY_MODEL_7ec1301e58e04aa7b8473ab0413abf4d"
          }
        },
        "2b84d435c92b430aac8d4aade0092ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce021636f43243a9ac64632e4bea1367",
            "placeholder": "​",
            "style": "IPY_MODEL_dc824fb3186e471db1603dbe46608b8c",
            "value": "merges.txt: "
          }
        },
        "046ac3860fe944e0adcb7f7a0f0067f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffe6e6d265e3436eace734d81dbe41a3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69220195cd5447c1bf1b5e647e13abf5",
            "value": 1
          }
        },
        "3fc3bb5ca2904c84a4b5c07fa3e4c4fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0009e95d452438aadfea6edd7a0bc0c",
            "placeholder": "​",
            "style": "IPY_MODEL_5beb847abe5a4e349cb3a58f1148f050",
            "value": " 456k/? [00:00&lt;00:00, 13.1MB/s]"
          }
        },
        "7ec1301e58e04aa7b8473ab0413abf4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce021636f43243a9ac64632e4bea1367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc824fb3186e471db1603dbe46608b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffe6e6d265e3436eace734d81dbe41a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "69220195cd5447c1bf1b5e647e13abf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0009e95d452438aadfea6edd7a0bc0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5beb847abe5a4e349cb3a58f1148f050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e58c784360c4f3ab8f956cc6b0c5b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_157a56945292436d992abfaf6ee2df11",
              "IPY_MODEL_6089b16e6510446b9d1feffcbfcd2006",
              "IPY_MODEL_f66f5f28be00475f98c748e7493e0ad6"
            ],
            "layout": "IPY_MODEL_a56dbca2ffa54f4db0ad6c89c58de485"
          }
        },
        "157a56945292436d992abfaf6ee2df11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e743bc2501214d04828d0610b18560a0",
            "placeholder": "​",
            "style": "IPY_MODEL_a810b7e5de814b9794c1f4c63fa00f24",
            "value": "tokenizer.json: "
          }
        },
        "6089b16e6510446b9d1feffcbfcd2006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6152ed74c0724a78b12f4870bc28cb06",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d295bedb0bca491c852b556d329fe326",
            "value": 1
          }
        },
        "f66f5f28be00475f98c748e7493e0ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dec4b92e299140bb9e24be14183a7610",
            "placeholder": "​",
            "style": "IPY_MODEL_4d728483ce2b4b499698bc9eda5d9cd0",
            "value": " 1.36M/? [00:00&lt;00:00, 14.8MB/s]"
          }
        },
        "a56dbca2ffa54f4db0ad6c89c58de485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e743bc2501214d04828d0610b18560a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a810b7e5de814b9794c1f4c63fa00f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6152ed74c0724a78b12f4870bc28cb06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d295bedb0bca491c852b556d329fe326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dec4b92e299140bb9e24be14183a7610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d728483ce2b4b499698bc9eda5d9cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66686495cc8847be85dc81b532b2d112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8be2a5f41f5c45eeb3595b84096a69c0",
              "IPY_MODEL_f47181468734442e8675fee0a72bca58",
              "IPY_MODEL_f0e3f975eb47414eb1aba3e284ca91fd"
            ],
            "layout": "IPY_MODEL_8c464a4c781f46f0b7ce12b1d006d765"
          }
        },
        "8be2a5f41f5c45eeb3595b84096a69c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd41339c585640d5b3274d05b41d26b7",
            "placeholder": "​",
            "style": "IPY_MODEL_fcf614e8b60b4f7fbdd1dc8304223aea",
            "value": "config.json: "
          }
        },
        "f47181468734442e8675fee0a72bca58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_face5a50e61f4d1b846bffea4234fd5f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f4bcbcb1ca7473fb1b5c3098e014920",
            "value": 1
          }
        },
        "f0e3f975eb47414eb1aba3e284ca91fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_752405d45a644374becb7da9f50e92e9",
            "placeholder": "​",
            "style": "IPY_MODEL_ba80f833c67d419db7534034c1d84528",
            "value": " 1.58k/? [00:00&lt;00:00, 90.0kB/s]"
          }
        },
        "8c464a4c781f46f0b7ce12b1d006d765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd41339c585640d5b3274d05b41d26b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcf614e8b60b4f7fbdd1dc8304223aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "face5a50e61f4d1b846bffea4234fd5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9f4bcbcb1ca7473fb1b5c3098e014920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "752405d45a644374becb7da9f50e92e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba80f833c67d419db7534034c1d84528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f74057c8834f7ca991deffb86ec368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5555b9830e774ea9897fa063ca71e4da",
              "IPY_MODEL_7848e951443c466886d60d08a66d64d9",
              "IPY_MODEL_54475a8c1abb4fbf825306321ed1b9e7"
            ],
            "layout": "IPY_MODEL_cac3c4061061473cb9c25fdddfa04b68"
          }
        },
        "5555b9830e774ea9897fa063ca71e4da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_874f5ba35bb44ac9bb370dfa445932ae",
            "placeholder": "​",
            "style": "IPY_MODEL_fd9d2c196dff4920990099bd8ad93bef",
            "value": "model.safetensors: 100%"
          }
        },
        "7848e951443c466886d60d08a66d64d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff133a7899f04b0c90770d9a1fb0d459",
            "max": 1625222120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eaf7feeeec354d0d8fd6df14cf86fb6f",
            "value": 1625222120
          }
        },
        "54475a8c1abb4fbf825306321ed1b9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e59b1f0945504a95aa73b96724a44846",
            "placeholder": "​",
            "style": "IPY_MODEL_ff40b9c78c634885bb1238b70aa1d3b3",
            "value": " 1.63G/1.63G [00:56&lt;00:00, 41.7MB/s]"
          }
        },
        "cac3c4061061473cb9c25fdddfa04b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "874f5ba35bb44ac9bb370dfa445932ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd9d2c196dff4920990099bd8ad93bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff133a7899f04b0c90770d9a1fb0d459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaf7feeeec354d0d8fd6df14cf86fb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e59b1f0945504a95aa73b96724a44846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff40b9c78c634885bb1238b70aa1d3b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9dd76272d1645cca46f657082447413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10774af1e56342eca5823bf6826cb03f",
              "IPY_MODEL_401cf9f0080745edb3dbd8fa7e9324fa",
              "IPY_MODEL_b27c53dc4b3048b79d6adb63440abd60"
            ],
            "layout": "IPY_MODEL_1d6e9452b7e04558abbbcce600cb4243"
          }
        },
        "10774af1e56342eca5823bf6826cb03f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89a221e0db4c4c4c8a26b416ab766446",
            "placeholder": "​",
            "style": "IPY_MODEL_3335f91528254238b20675bcb6be9f9c",
            "value": "generation_config.json: 100%"
          }
        },
        "401cf9f0080745edb3dbd8fa7e9324fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96e7c5515283440f81916bd07bd6fdc9",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0a909221eb945a79e68cba7f7808e03",
            "value": 363
          }
        },
        "b27c53dc4b3048b79d6adb63440abd60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4b35222ad484cfb886f66933ef60a7f",
            "placeholder": "​",
            "style": "IPY_MODEL_9bfe6e34e0af4c20b9e18b40c82fee50",
            "value": " 363/363 [00:00&lt;00:00, 17.2kB/s]"
          }
        },
        "1d6e9452b7e04558abbbcce600cb4243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89a221e0db4c4c4c8a26b416ab766446": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3335f91528254238b20675bcb6be9f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96e7c5515283440f81916bd07bd6fdc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0a909221eb945a79e68cba7f7808e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4b35222ad484cfb886f66933ef60a7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bfe6e34e0af4c20b9e18b40c82fee50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a2a80c8f5f24b90962dbc9cbdee1713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8e22cf02a634719a5bedb870cb20ecb",
              "IPY_MODEL_a45f75ac71324ebb80d1d3d96a40398d",
              "IPY_MODEL_f2bf11194a104f3c8c5054017390500d"
            ],
            "layout": "IPY_MODEL_702500c637134c9e9df5bc8a95306cc2"
          }
        },
        "c8e22cf02a634719a5bedb870cb20ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0b28d81e2cd410aac01f4b501b13cd3",
            "placeholder": "​",
            "style": "IPY_MODEL_1d16733b929c4099b9a3423e99fe9eaa",
            "value": "modules.json: 100%"
          }
        },
        "a45f75ac71324ebb80d1d3d96a40398d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da1188c015174efa9bcaf8f803b52eb1",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28abb456e6f647c88c0d9f4c7a1091c0",
            "value": 349
          }
        },
        "f2bf11194a104f3c8c5054017390500d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc9c0fcd3afc46d88e567a4c5d24b1a8",
            "placeholder": "​",
            "style": "IPY_MODEL_7efce61a72fd46629cd1abb6e24f4a27",
            "value": " 349/349 [00:00&lt;00:00, 10.4kB/s]"
          }
        },
        "702500c637134c9e9df5bc8a95306cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0b28d81e2cd410aac01f4b501b13cd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d16733b929c4099b9a3423e99fe9eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da1188c015174efa9bcaf8f803b52eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28abb456e6f647c88c0d9f4c7a1091c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc9c0fcd3afc46d88e567a4c5d24b1a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7efce61a72fd46629cd1abb6e24f4a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9021a3d0c78d429290703e94154989b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f2b247ebf07403bab441c0ea01be0fb",
              "IPY_MODEL_9d004cac89b040c5a3e34709fa22dc30",
              "IPY_MODEL_7bef30519b9c49678b1dd01ee7ed97d6"
            ],
            "layout": "IPY_MODEL_edc76b4c2ec44cda8037cde790980ac7"
          }
        },
        "1f2b247ebf07403bab441c0ea01be0fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b2c7af41f5241dcaabe405580c6170d",
            "placeholder": "​",
            "style": "IPY_MODEL_f614eb3cbb6d447e9426429b70ae13bc",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "9d004cac89b040c5a3e34709fa22dc30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79a4c90d209f421c9ee22bc7cd34aa63",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfbad31101a84f7dae49aa4949b8730a",
            "value": 116
          }
        },
        "7bef30519b9c49678b1dd01ee7ed97d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1d04eab10dd4c9c941dc31e8b2e71fc",
            "placeholder": "​",
            "style": "IPY_MODEL_a83662f519484c0c81bd726dca3ad5e3",
            "value": " 116/116 [00:00&lt;00:00, 5.70kB/s]"
          }
        },
        "edc76b4c2ec44cda8037cde790980ac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b2c7af41f5241dcaabe405580c6170d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f614eb3cbb6d447e9426429b70ae13bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79a4c90d209f421c9ee22bc7cd34aa63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfbad31101a84f7dae49aa4949b8730a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1d04eab10dd4c9c941dc31e8b2e71fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a83662f519484c0c81bd726dca3ad5e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac17084f442f43e6b6962c0fcff4cedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b68ea7eb54654b4ab6fb1ac923343f8f",
              "IPY_MODEL_de6c32f64a864198b3bebbd39e2d2c27",
              "IPY_MODEL_9a2b72c991214a9195acdcdaa8265eb0"
            ],
            "layout": "IPY_MODEL_103bb9066e2f45ac8847c1f08e894392"
          }
        },
        "b68ea7eb54654b4ab6fb1ac923343f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5cc8809c81c4b269b97e2eb7a307e5f",
            "placeholder": "​",
            "style": "IPY_MODEL_705f391447c340b28bd645a81860cac2",
            "value": "README.md: "
          }
        },
        "de6c32f64a864198b3bebbd39e2d2c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a28860eb2654078ab93593a5548c24f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74bb256ea84e4c49a8343658808cf6da",
            "value": 1
          }
        },
        "9a2b72c991214a9195acdcdaa8265eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7226b4c225cf44ecb5e3e0fe7bcaf2e8",
            "placeholder": "​",
            "style": "IPY_MODEL_3c1233045e0f4f3fb79d2642dc8eb9c5",
            "value": " 10.5k/? [00:00&lt;00:00, 490kB/s]"
          }
        },
        "103bb9066e2f45ac8847c1f08e894392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5cc8809c81c4b269b97e2eb7a307e5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "705f391447c340b28bd645a81860cac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a28860eb2654078ab93593a5548c24f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "74bb256ea84e4c49a8343658808cf6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7226b4c225cf44ecb5e3e0fe7bcaf2e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c1233045e0f4f3fb79d2642dc8eb9c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "597de5fbd5a74a50958c676d0785c36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbcb4c6eee4c4bad904fb699b7fb2d22",
              "IPY_MODEL_fa4d668a3a4f4f66b7daa93830e8c954",
              "IPY_MODEL_2ca117a519bb480099b4ac9c2178ffe3"
            ],
            "layout": "IPY_MODEL_bb39145ebf9d460e9c6649afd602295d"
          }
        },
        "fbcb4c6eee4c4bad904fb699b7fb2d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35387b5e69c94a058bfcf5f2298e91e3",
            "placeholder": "​",
            "style": "IPY_MODEL_b20f7d836f8c4fb481849ca6595ed051",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "fa4d668a3a4f4f66b7daa93830e8c954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbc4d6e6f024432f859b7d7da8f84326",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aadacd9902cc41f9b253be70677f387d",
            "value": 53
          }
        },
        "2ca117a519bb480099b4ac9c2178ffe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52595b3febee4dfeac0cc7d795bdeeed",
            "placeholder": "​",
            "style": "IPY_MODEL_ec1115c354714bc9a85e519130a87819",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.47kB/s]"
          }
        },
        "bb39145ebf9d460e9c6649afd602295d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35387b5e69c94a058bfcf5f2298e91e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b20f7d836f8c4fb481849ca6595ed051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbc4d6e6f024432f859b7d7da8f84326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aadacd9902cc41f9b253be70677f387d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52595b3febee4dfeac0cc7d795bdeeed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec1115c354714bc9a85e519130a87819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "243ea253c9784c4a85f16e4ecb1327f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29852302d7fa4143adcabb63cd4153f9",
              "IPY_MODEL_96431934d9164993958a25a650c0b551",
              "IPY_MODEL_9158e6d07adb431b9eeefb890dbc6eaf"
            ],
            "layout": "IPY_MODEL_7924c2ba34424c37bfa004b79b00ad60"
          }
        },
        "29852302d7fa4143adcabb63cd4153f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbe1fdd8109b4b07a3b82445f8f1198b",
            "placeholder": "​",
            "style": "IPY_MODEL_9b4475e05cc140a882f13930d6499de7",
            "value": "config.json: 100%"
          }
        },
        "96431934d9164993958a25a650c0b551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3221b016d18144e1bb2a7a1fccbafa99",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8479546eebc649a1b478b981a1fe407a",
            "value": 612
          }
        },
        "9158e6d07adb431b9eeefb890dbc6eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02b5dfa4780544979e52f24da27231be",
            "placeholder": "​",
            "style": "IPY_MODEL_c9dd868dcf694b87b335535a799b9f9e",
            "value": " 612/612 [00:00&lt;00:00, 25.2kB/s]"
          }
        },
        "7924c2ba34424c37bfa004b79b00ad60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbe1fdd8109b4b07a3b82445f8f1198b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b4475e05cc140a882f13930d6499de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3221b016d18144e1bb2a7a1fccbafa99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8479546eebc649a1b478b981a1fe407a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02b5dfa4780544979e52f24da27231be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9dd868dcf694b87b335535a799b9f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7423b50d8a0c43bba8d3a407818ccd16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_470062f4359041d09675d23b99939cc8",
              "IPY_MODEL_df9f6a02402545a7a9f5d9864e165913",
              "IPY_MODEL_5fa31f3c7a6d427fa55c639f3832eeb1"
            ],
            "layout": "IPY_MODEL_d6829027fed647f89dfbd82192ca70f8"
          }
        },
        "470062f4359041d09675d23b99939cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfbd8addb32b4bf6acc04fdbd6454fa2",
            "placeholder": "​",
            "style": "IPY_MODEL_9e4441c234984f8f8f4ab305ae2ee649",
            "value": "model.safetensors: 100%"
          }
        },
        "df9f6a02402545a7a9f5d9864e165913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d658399eaf64bac9c908a050ef9fbf6",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ab5a57648324b24b5460a9c736b4eb2",
            "value": 90868376
          }
        },
        "5fa31f3c7a6d427fa55c639f3832eeb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8faf98a3a9746f48cdf03ceda15a2d8",
            "placeholder": "​",
            "style": "IPY_MODEL_0efcf3b142e748e29d525b6e09e79b5f",
            "value": " 90.9M/90.9M [00:02&lt;00:00, 54.3MB/s]"
          }
        },
        "d6829027fed647f89dfbd82192ca70f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfbd8addb32b4bf6acc04fdbd6454fa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e4441c234984f8f8f4ab305ae2ee649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d658399eaf64bac9c908a050ef9fbf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ab5a57648324b24b5460a9c736b4eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8faf98a3a9746f48cdf03ceda15a2d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0efcf3b142e748e29d525b6e09e79b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fe26e542ca94404ad1449a9eb457daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c621267a25547b4b71b5537ed0f5eab",
              "IPY_MODEL_c3178c15bde643c79de03f957e38ea73",
              "IPY_MODEL_0ff0cfb81f3348ceb6542e97fc949e40"
            ],
            "layout": "IPY_MODEL_89915b778ee541e9b74dc7e182a453b0"
          }
        },
        "5c621267a25547b4b71b5537ed0f5eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5382513ff2294cffa5a679d63effd9d0",
            "placeholder": "​",
            "style": "IPY_MODEL_40b2770426df4be4a82e4071b5016c01",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c3178c15bde643c79de03f957e38ea73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_774dccd0147e4a9f9426de2708e6b80d",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3aa263361282439aa17588a0939c4a88",
            "value": 350
          }
        },
        "0ff0cfb81f3348ceb6542e97fc949e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_004bac3ab77e4638929e4349e1d3897d",
            "placeholder": "​",
            "style": "IPY_MODEL_ed94bc2aaa7b44f2ac84cdf8b097708b",
            "value": " 350/350 [00:00&lt;00:00, 7.27kB/s]"
          }
        },
        "89915b778ee541e9b74dc7e182a453b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5382513ff2294cffa5a679d63effd9d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b2770426df4be4a82e4071b5016c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "774dccd0147e4a9f9426de2708e6b80d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa263361282439aa17588a0939c4a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "004bac3ab77e4638929e4349e1d3897d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed94bc2aaa7b44f2ac84cdf8b097708b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46198efeae1446db9d916a02494aba71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c5c3ba0260e43ae8786c73f8fe828cc",
              "IPY_MODEL_d757a69fb5874c2798d2e0866375ebc5",
              "IPY_MODEL_234145d805a74e18aca5d5bc0200ca92"
            ],
            "layout": "IPY_MODEL_cfd872b6677b4e84b8645a1bbd36d3fd"
          }
        },
        "0c5c3ba0260e43ae8786c73f8fe828cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d550b0e77734027a12730e0cd82f3c3",
            "placeholder": "​",
            "style": "IPY_MODEL_e1e779ff4a104c01a02ee206017d20c8",
            "value": "vocab.txt: "
          }
        },
        "d757a69fb5874c2798d2e0866375ebc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f77ddced70384fa1aee3c1697323acb3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49b0dce90c214651bfe7ed908f9334c3",
            "value": 1
          }
        },
        "234145d805a74e18aca5d5bc0200ca92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1be111dc9e6a4687bd023213eaf4401d",
            "placeholder": "​",
            "style": "IPY_MODEL_4b28054ad3b946b284a63cb7f0e1801c",
            "value": " 232k/? [00:00&lt;00:00, 3.13MB/s]"
          }
        },
        "cfd872b6677b4e84b8645a1bbd36d3fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d550b0e77734027a12730e0cd82f3c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1e779ff4a104c01a02ee206017d20c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f77ddced70384fa1aee3c1697323acb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "49b0dce90c214651bfe7ed908f9334c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1be111dc9e6a4687bd023213eaf4401d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b28054ad3b946b284a63cb7f0e1801c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39806386824b4bcfa8524156393f3e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aedb2acce2a544839e13081425428c94",
              "IPY_MODEL_fe30a136718d41658aea61bd4a32457f",
              "IPY_MODEL_18132abd0d88431bbd75796976ed5088"
            ],
            "layout": "IPY_MODEL_ab4638198ad1489f9f1587780a0bae50"
          }
        },
        "aedb2acce2a544839e13081425428c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a472ed9504e40ffa296b460f872e86c",
            "placeholder": "​",
            "style": "IPY_MODEL_032010fd90854101b2dd4d04b7f8c463",
            "value": "tokenizer.json: "
          }
        },
        "fe30a136718d41658aea61bd4a32457f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cb00e1d43814ed8aea3a83e0a82472c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a207a3e49ab74056b64f26e96598e709",
            "value": 1
          }
        },
        "18132abd0d88431bbd75796976ed5088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0701c7e2439c4c84a56b3cb74aa4fc35",
            "placeholder": "​",
            "style": "IPY_MODEL_0459ce2e0a1640a290c58dcbdfc6675e",
            "value": " 466k/? [00:00&lt;00:00, 6.86MB/s]"
          }
        },
        "ab4638198ad1489f9f1587780a0bae50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a472ed9504e40ffa296b460f872e86c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "032010fd90854101b2dd4d04b7f8c463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cb00e1d43814ed8aea3a83e0a82472c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a207a3e49ab74056b64f26e96598e709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0701c7e2439c4c84a56b3cb74aa4fc35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0459ce2e0a1640a290c58dcbdfc6675e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25a64562b8344f6a929897ba88c3ac34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a5516d48205446da4c7fa349e1a7719",
              "IPY_MODEL_15f89fd7493b443ab80ffc65cb53ee3f",
              "IPY_MODEL_5bfe6ea6905d42a8a1b7b4db48c0c065"
            ],
            "layout": "IPY_MODEL_c0ce90230f544844be42bca62ec85de2"
          }
        },
        "7a5516d48205446da4c7fa349e1a7719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a35dc2474e0341779b5283ed3f20ef5a",
            "placeholder": "​",
            "style": "IPY_MODEL_b3e1a371dd7b4901a21dad711f85060b",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "15f89fd7493b443ab80ffc65cb53ee3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_889718c99e7f4f85bea8ae84bfed7d79",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54e8b0da81b1458d893fc5487c0e4eff",
            "value": 112
          }
        },
        "5bfe6ea6905d42a8a1b7b4db48c0c065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_199bad31a51646efa4d9921cee8a4098",
            "placeholder": "​",
            "style": "IPY_MODEL_db4146b184914f6bbe1f9d4efbcb3984",
            "value": " 112/112 [00:00&lt;00:00, 3.17kB/s]"
          }
        },
        "c0ce90230f544844be42bca62ec85de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a35dc2474e0341779b5283ed3f20ef5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3e1a371dd7b4901a21dad711f85060b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "889718c99e7f4f85bea8ae84bfed7d79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54e8b0da81b1458d893fc5487c0e4eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "199bad31a51646efa4d9921cee8a4098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db4146b184914f6bbe1f9d4efbcb3984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3568e1d33b44e6ca48d721e9184b491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c04c324e1cb42ea99a5b8a0d9fc98f6",
              "IPY_MODEL_c441f1741ce8400ba11810c047101320",
              "IPY_MODEL_24096a724d6d43ef803048e4924cfc12"
            ],
            "layout": "IPY_MODEL_cf3106123ae44809905f14ea5990a64f"
          }
        },
        "9c04c324e1cb42ea99a5b8a0d9fc98f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cd9c62238db4b4781f09e988c57e6c4",
            "placeholder": "​",
            "style": "IPY_MODEL_d38817f5d37d4f0eafaacff84fd511b7",
            "value": "config.json: 100%"
          }
        },
        "c441f1741ce8400ba11810c047101320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82290315c28e47edac537cb78be8ce9b",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_473c53521b3b4deca31b0830a41a62db",
            "value": 190
          }
        },
        "24096a724d6d43ef803048e4924cfc12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_964326f9e937431ca2aed4928f8f277c",
            "placeholder": "​",
            "style": "IPY_MODEL_7e272f3412fe4dbdbd1adc3130dc8d07",
            "value": " 190/190 [00:00&lt;00:00, 5.81kB/s]"
          }
        },
        "cf3106123ae44809905f14ea5990a64f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cd9c62238db4b4781f09e988c57e6c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d38817f5d37d4f0eafaacff84fd511b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82290315c28e47edac537cb78be8ce9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "473c53521b3b4deca31b0830a41a62db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "964326f9e937431ca2aed4928f8f277c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e272f3412fe4dbdbd1adc3130dc8d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bda06ce543648c9a4a66eadede1d357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2d62f629df44bf5ac320c30a2fd2324",
              "IPY_MODEL_a06f3f2528e5414a934e58eb820aaa9e",
              "IPY_MODEL_b09f624ee90e4cb6ab30203d306df210"
            ],
            "layout": "IPY_MODEL_926d3acb405645de850d114a280ff26e"
          }
        },
        "d2d62f629df44bf5ac320c30a2fd2324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25a54270fe42432a97b4ab5956011de0",
            "placeholder": "​",
            "style": "IPY_MODEL_3f50358d833f48379349dd92badaa419",
            "value": "Evaluating sentences: 100%"
          }
        },
        "a06f3f2528e5414a934e58eb820aaa9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4da878febe9448bd8d17929c4a58e45e",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e7f7810b6f54b218a1bce7baf5403c8",
            "value": 20
          }
        },
        "b09f624ee90e4cb6ab30203d306df210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfb572e6a05b4a75b2e6fb6a772a5365",
            "placeholder": "​",
            "style": "IPY_MODEL_73d0621770344bd3aa0eff467b335b99",
            "value": " 20/20 [00:02&lt;00:00,  8.73it/s]"
          }
        },
        "926d3acb405645de850d114a280ff26e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "25a54270fe42432a97b4ab5956011de0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f50358d833f48379349dd92badaa419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4da878febe9448bd8d17929c4a58e45e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e7f7810b6f54b218a1bce7baf5403c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfb572e6a05b4a75b2e6fb6a772a5365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73d0621770344bd3aa0eff467b335b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6d6db55cdd545d4aa41a00d6efec3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_211e5e658d22426bb78bb1fb462aecd1",
              "IPY_MODEL_e4e9dc8c62be4e9594a8312b5ae229c7",
              "IPY_MODEL_f29d576c8dca4f9ba1fe9e7112d3149a"
            ],
            "layout": "IPY_MODEL_03ac61c0cf604d0ba95ccd7aa7fcee5b"
          }
        },
        "211e5e658d22426bb78bb1fb462aecd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff6a3d52b30b4e1da26f19c4b5857ecd",
            "placeholder": "​",
            "style": "IPY_MODEL_ead05daeb26a4a45b4d8d05f84f976be",
            "value": "Evaluating sentences: 100%"
          }
        },
        "e4e9dc8c62be4e9594a8312b5ae229c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d5ea08a37bf4988884a1c9f3125e3a3",
            "max": 23,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d792524051e842c78251872c72910d8d",
            "value": 23
          }
        },
        "f29d576c8dca4f9ba1fe9e7112d3149a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eb9dbba91aa428fad57388cf2c53d71",
            "placeholder": "​",
            "style": "IPY_MODEL_0553c93c74b6455fad78a75f35bca672",
            "value": " 23/23 [00:02&lt;00:00, 11.42it/s]"
          }
        },
        "03ac61c0cf604d0ba95ccd7aa7fcee5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ff6a3d52b30b4e1da26f19c4b5857ecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ead05daeb26a4a45b4d8d05f84f976be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d5ea08a37bf4988884a1c9f3125e3a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d792524051e842c78251872c72910d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4eb9dbba91aa428fad57388cf2c53d71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0553c93c74b6455fad78a75f35bca672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f001aff0c904052ad51e53adb41899b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_634a91a0b919458b810041973130a442",
              "IPY_MODEL_871ef31c31314986b6f899a66c889500",
              "IPY_MODEL_48cf7f8ab1d44b099a29a4cf3b2d30d6"
            ],
            "layout": "IPY_MODEL_38c5d31498c64671971a42931ba05304"
          }
        },
        "634a91a0b919458b810041973130a442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b9eb2ae340742edb1423105fa13520e",
            "placeholder": "​",
            "style": "IPY_MODEL_8c1a636462354c96aee7522f1e4eab86",
            "value": "Evaluating summary sentences: 100%"
          }
        },
        "871ef31c31314986b6f899a66c889500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ee7359d73c648afb82cd7fb72308c1e",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e63e9f3b10b3470a9a79b4b44af138c2",
            "value": 20
          }
        },
        "48cf7f8ab1d44b099a29a4cf3b2d30d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88c310391a4a4a98aa18fe96abdeff3b",
            "placeholder": "​",
            "style": "IPY_MODEL_fbd216299dd244008209ad8cf1e3428b",
            "value": " 20/20 [00:18&lt;00:00,  1.07it/s]"
          }
        },
        "38c5d31498c64671971a42931ba05304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "7b9eb2ae340742edb1423105fa13520e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c1a636462354c96aee7522f1e4eab86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ee7359d73c648afb82cd7fb72308c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e63e9f3b10b3470a9a79b4b44af138c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88c310391a4a4a98aa18fe96abdeff3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd216299dd244008209ad8cf1e3428b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22537df3b83c4f9aa4e4e58856a83cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40f3661aaede4d398399e6b962ebd7cb",
              "IPY_MODEL_76da52345e3a498c94269499ee4a92c4",
              "IPY_MODEL_3668a72f28fa4d3c842f3d7b8c1e77df"
            ],
            "layout": "IPY_MODEL_c003ff3b8ca94ecaafb17f7f49953c60"
          }
        },
        "40f3661aaede4d398399e6b962ebd7cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_830ec8e9a4d6469cb181803868ef11ee",
            "placeholder": "​",
            "style": "IPY_MODEL_fac7d9c1fc644871942b372d6c280676",
            "value": "vocab.json: "
          }
        },
        "76da52345e3a498c94269499ee4a92c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d5cd66bd4a94e6fbd86760e91cb50ca",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0afdd3a8776742d2a682348fec6a1695",
            "value": 1
          }
        },
        "3668a72f28fa4d3c842f3d7b8c1e77df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5aa53c4ee46647958645d47d6a01ade7",
            "placeholder": "​",
            "style": "IPY_MODEL_adcc9dfd4f564776885fb55c58f900ed",
            "value": " 899k/? [00:00&lt;00:00, 10.1MB/s]"
          }
        },
        "c003ff3b8ca94ecaafb17f7f49953c60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "830ec8e9a4d6469cb181803868ef11ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac7d9c1fc644871942b372d6c280676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d5cd66bd4a94e6fbd86760e91cb50ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0afdd3a8776742d2a682348fec6a1695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5aa53c4ee46647958645d47d6a01ade7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adcc9dfd4f564776885fb55c58f900ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "518e7080508d446c98afacdc625758c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d50375b8adc4427f9f7bece38b339e68",
              "IPY_MODEL_63df4d908b454f98a99f77e98980d918",
              "IPY_MODEL_f2d421fb036e4de39b4f6f7d83ee66f7"
            ],
            "layout": "IPY_MODEL_c0cb47a7ef344658ab163cdb49fc963f"
          }
        },
        "d50375b8adc4427f9f7bece38b339e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f94d14b8b33a40fdb4abc88c7770bc80",
            "placeholder": "​",
            "style": "IPY_MODEL_74ecf0fb6cf4421ea6755443918d46f4",
            "value": "merges.txt: "
          }
        },
        "63df4d908b454f98a99f77e98980d918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_935ebf5b94f44dfea6307d170af82b25",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c130afc296d449b39f97cef531b63297",
            "value": 1
          }
        },
        "f2d421fb036e4de39b4f6f7d83ee66f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef46336c625c41faa09efb9949059e7c",
            "placeholder": "​",
            "style": "IPY_MODEL_6487755510af44e395d02e73f1fadca8",
            "value": " 456k/? [00:00&lt;00:00, 6.00MB/s]"
          }
        },
        "c0cb47a7ef344658ab163cdb49fc963f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f94d14b8b33a40fdb4abc88c7770bc80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74ecf0fb6cf4421ea6755443918d46f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "935ebf5b94f44dfea6307d170af82b25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c130afc296d449b39f97cef531b63297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef46336c625c41faa09efb9949059e7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6487755510af44e395d02e73f1fadca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f0a6d59a9864d209eb37083ad635f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ce4b3904a2f42fabe095ed800132932",
              "IPY_MODEL_496979664779400c9daa12354a5ee93b",
              "IPY_MODEL_50b67aeea7d64100b32d9185ca0be4c7"
            ],
            "layout": "IPY_MODEL_c02593a968ed460380acf2e65197cd2b"
          }
        },
        "6ce4b3904a2f42fabe095ed800132932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0d804d067aa490e99e006715f240bc0",
            "placeholder": "​",
            "style": "IPY_MODEL_77d9c4c95123455b93825d8077678159",
            "value": "tokenizer.json: "
          }
        },
        "496979664779400c9daa12354a5ee93b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_244423e696874033ac23096e3b397b1b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff2b51400bb14de8a7802835f93faccf",
            "value": 1
          }
        },
        "50b67aeea7d64100b32d9185ca0be4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01e76dcf787c4f1a88960bb4b072f360",
            "placeholder": "​",
            "style": "IPY_MODEL_b15d8c8f2f0b4653a1e2b0bf6c3d59fc",
            "value": " 1.36M/? [00:00&lt;00:00, 11.3MB/s]"
          }
        },
        "c02593a968ed460380acf2e65197cd2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0d804d067aa490e99e006715f240bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77d9c4c95123455b93825d8077678159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "244423e696874033ac23096e3b397b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ff2b51400bb14de8a7802835f93faccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01e76dcf787c4f1a88960bb4b072f360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b15d8c8f2f0b4653a1e2b0bf6c3d59fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19b2425326eb49df9c14e6518665d7ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99e2b523bd9c4e91a7a422a40be7291e",
              "IPY_MODEL_11fec2d312324bac8631c5b3ded6735e",
              "IPY_MODEL_3fbcdc6f34134741a5897aff2b3b265c"
            ],
            "layout": "IPY_MODEL_75693058f5824163967ff9779ce68c79"
          }
        },
        "99e2b523bd9c4e91a7a422a40be7291e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4b1121adf8541a8ae58a74f5042dfc6",
            "placeholder": "​",
            "style": "IPY_MODEL_04997f88a06944c8885fd7ef83d447e7",
            "value": "config.json: "
          }
        },
        "11fec2d312324bac8631c5b3ded6735e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2b7dfc774c44a5e9e49e1fa1945219b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd64653d45a84e5eb6a97a9bee5e6801",
            "value": 1
          }
        },
        "3fbcdc6f34134741a5897aff2b3b265c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7574d97ce7e24ffba324c0f684d2ee4a",
            "placeholder": "​",
            "style": "IPY_MODEL_4251cd99154b4a55b449c4a572e59170",
            "value": " 1.58k/? [00:00&lt;00:00, 19.2kB/s]"
          }
        },
        "75693058f5824163967ff9779ce68c79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b1121adf8541a8ae58a74f5042dfc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04997f88a06944c8885fd7ef83d447e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2b7dfc774c44a5e9e49e1fa1945219b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bd64653d45a84e5eb6a97a9bee5e6801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7574d97ce7e24ffba324c0f684d2ee4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4251cd99154b4a55b449c4a572e59170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4493f98683da472a8157724a4c3184f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ca3d330663943e89c102be90eb3e0f8",
              "IPY_MODEL_a80f2595751848d8a608c6bbb8085101",
              "IPY_MODEL_53953922e15f452db9b1d090d2ecb23e"
            ],
            "layout": "IPY_MODEL_5018a79d8de842a29edc2d4b2fa7363e"
          }
        },
        "0ca3d330663943e89c102be90eb3e0f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c38ee423c544f7bb34efa6772459719",
            "placeholder": "​",
            "style": "IPY_MODEL_9eb8761156eb447283bb61c7631db9f2",
            "value": "model.safetensors: 100%"
          }
        },
        "a80f2595751848d8a608c6bbb8085101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_996139d3fdcb4f56bd3dc79914eaeef0",
            "max": 1625222120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cbfa6c7a6234a4fbc796bebf500a904",
            "value": 1625222120
          }
        },
        "53953922e15f452db9b1d090d2ecb23e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22b8818fb6ee4dccb04b9be1930c06dd",
            "placeholder": "​",
            "style": "IPY_MODEL_8e9cabb5b1674b98b65c0d4ddb42130d",
            "value": " 1.63G/1.63G [02:04&lt;00:00, 10.6MB/s]"
          }
        },
        "5018a79d8de842a29edc2d4b2fa7363e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c38ee423c544f7bb34efa6772459719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eb8761156eb447283bb61c7631db9f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "996139d3fdcb4f56bd3dc79914eaeef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cbfa6c7a6234a4fbc796bebf500a904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22b8818fb6ee4dccb04b9be1930c06dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e9cabb5b1674b98b65c0d4ddb42130d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f26d4473ba1e41e7839d2ba9fac676e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_614a102da597452baba1e0649d4b30aa",
              "IPY_MODEL_69dd7d9061244c1390ec451c5db1a13e",
              "IPY_MODEL_1c796f12024c4dcd83081a1d17f410ac"
            ],
            "layout": "IPY_MODEL_b35402a7da524170b707232c68beee6d"
          }
        },
        "614a102da597452baba1e0649d4b30aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83c4e7e3ebb342beb24a8d729468a45f",
            "placeholder": "​",
            "style": "IPY_MODEL_17a1c36a6dda491d912ba5ceadf40efc",
            "value": "generation_config.json: 100%"
          }
        },
        "69dd7d9061244c1390ec451c5db1a13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ea161c5589d4846976a9c27961ecc43",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f18590cc9af451bb55118ed64199b69",
            "value": 363
          }
        },
        "1c796f12024c4dcd83081a1d17f410ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc0cd42a6b2a4af593a1603733368ddc",
            "placeholder": "​",
            "style": "IPY_MODEL_9705759e7dbd47129c6795e2e145c161",
            "value": " 363/363 [00:00&lt;00:00, 22.0kB/s]"
          }
        },
        "b35402a7da524170b707232c68beee6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83c4e7e3ebb342beb24a8d729468a45f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a1c36a6dda491d912ba5ceadf40efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ea161c5589d4846976a9c27961ecc43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f18590cc9af451bb55118ed64199b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc0cd42a6b2a4af593a1603733368ddc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9705759e7dbd47129c6795e2e145c161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nanda654/HEADS/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Input text with original text, extrative summary and abstractive summary"
      ],
      "metadata": {
        "id": "cVC0hifgGc_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#original text\n",
        "x1 = \"\"\"In our prior work, we have found that technological innovation involves not only creating new ideas but also translating those ideas into a new product or service. Innovation, and the research driving it, is inherently risky because the likelihood that research can be translated into a product or service and the ultimate value of that product or service are unknown. The Department of Commerce\\u2019s National Institute of Standards and Technology describes the path from innovation to commercialization as comprised of three overarching stages: inventing, transitioning to making, and selling. (See fig. 1 for a description of the path from innovation to commercialization.) FDA and USDA have responsibility for overseeing the safety of the food supply. In general, FDA is responsible for ensuring the safety of virtually all domestic and imported food products except those regulated by USDA. USDA is responsible for ensuring the safety of meat, poultry, processed egg products, and catfish. FDA and USDA cooperate with states, tribes, and local food safety and public health agencies to carry out their federal responsibilities. FDA and USDA carry out their responsibilities in part through inspections of facilities where food is produced. The frequency of inspections the agencies conduct varies, as follows: FDA. FDA\\u2019s authority requires a risk-based approach, in which inspection rates vary depending on the level of risk associated with a food product. FDA conducts risk-based inspections of high-risk and non-high-risk food facilities. For example, the FDA Food Safety Modernization Act, signed into law in 2011, specified that FDA had to inspect all high-risk domestic facilities at least every 3 years. USDA. Depending on the type of facility, USDA conducts inspections at least once per operating shift or maintains a constant presence. Specifically, USDA conducts carcass-by-carcass inspection at all federally inspected meat and poultry slaughter facilities and verifies that these establishments follow all food safety and humane handling requirements. At facilities that process meat and poultry products, USDA conducts inspections at least once per production shift, following the agency\\u2019s longstanding interpretation of its statutes requiring it to do so. Among other things, the Federal Food, Drug, and Cosmetic Act requires that food additives be approved by FDA before they can be lawfully used in foods. Substances added to food are considered unsafe unless the agency establishes that the use of the food additive, under specific conditions for use, will be safe, or unless the substance is generally recognized as safe (GRAS) under the conditions of its intended use among qualified experts. As we reported in 2010, the Federal Food, Drug, and Cosmetic Act exempts GRAS substances from the act\\u2019s general requirement that companies obtain FDA approval before marketing food containing a new additive. GRAS substances include hundreds of spices and artificial flavors, emulsifiers and binders, vitamins and minerals, and preservatives that manufacturers add to enhance a food\\u2019s taste, texture, nutritional content, or shelf life. The GRAS exemption allows companies, without notice to or approval from FDA, to determine whether there is enough support to claim a substance is GRAS. For a company to claim a substance is GRAS, it must conclude that there is common knowledge about the safety of the substance among experts qualified by scientific training and experience to evaluate its safety. In addition, as part of their oversight of the food supply, FDA and USDA oversee food labeling of the products under their respective jurisdictions. USDA, by statute, is charged with assuring that products under its jurisdiction, including meat, poultry, and catfish, in interstate or foreign commerce are properly marked, labeled, and packaged. USDA develops and applies the labeling requirements for these products, and food manufacturers are responsible for complying with the USDA labeling rules and adhering to the process maintained by USDA for the evaluation and approval of these product labels. Consistent with its statutes, USDA requires preapproval of all labels before manufacturers can market their products. The Federal Food, Drug, and Cosmetic Act prohibits the misbranding of food, which includes food labeling that is false or misleading. Consistent with its statutes, FDA ensures that foods within its jurisdiction are not misbranded by focusing on the labels of products already in the market. FDA establishes regulations for the enforcement of these provisions and issues guidance. Food manufacturers are responsible for compliance with misbranding provisions in the Federal Food, Drug, and Cosmetic Act and its implementing regulations. From time to time, new technologies, such as those used to make cell- cultured meat, generate challenges for FDA\\u2019s and USDA\\u2019s regulatory structure. Other examples of new food technologies to which federal agencies have needed to adapt include the genetic modification of plants and irradiation of foods. In the case of genetically modified plants, there are no specific regulations addressing products resulting from the manipulation of the genetic material of living seeds. However, under FDA policy, new genetically engineered crop varieties are treated like other foods (including their conventional counterparts) under the Federal Food Drug and Cosmetic Act and may not contain either unapproved food additives or contaminants that would adulterate the food. In 1995, FDA established a voluntary pre-market consultation process through which companies are encouraged to notify the agency before marketing a food produced from a genetically modified crop and voluntarily submit a summary of the developer-performed safety assessment. FDA evaluates the safety assessment for any issues that need to be addressed and works with the developer to resolve those issues. In the case of irradiated foods, companies seeking approval for a source of radiation used to treat a food may submit a food additive petition to FDA demonstrating the safety of the proposed use. FDA grants approval only after agency scientists have determined that the proposed use is safe, then the process can be employed commercially. General information about the process of making cell-cultured meat is available, but specific information about the technology being used and the eventual commercial production methods as well as the final products is not yet known. While firms may vary in how they make cell-cultured meat, the general process they use can be described in five phases. However, the technology and methods to commercially produce cell- cultured meat are still in development, and producers, regulators, and consumers do not yet have clarity on what these will entail. The composition of the final product is also not yet known. The general process for making cell-cultured meat contains five phases: biopsy, cell banking, growth, harvest, and food processing. (See fig. 2.) The five-phase process is generally as follows: 1. Biopsy. A biopsy is taken by collecting rice-sized tissue samples from an animal, such as livestock, chicken, or fish. During this and subsequent phases, specific laboratory sanitation procedures are followed, and antibiotics may be used in order to avoid or minimize contamination from bacteria. Growth Media According to researchers and representatives from cell-cultured meat firms, the growth media for cell-cultured meat often contains fetal bovine serum, which is obtained from blood drawn from a bovine fetus at slaughter. However, researchers and representatives from cell-culturing firms we spoke with said they are working to develop growth media that do not contain fetal bovine serum. Representatives from some of these firms also told us that the composition of the growth media, including the exact ingredients and their proportions, can vary based on the specific needs of the cells and the variety of serum used. For example, cell-cultured seafood may have different growth media and environmental requirements than cell-cultured livestock and poultry. 2. Cell banking. Biopsied cells with the most desirable traits are selected and either used immediately for cell growth or frozen to create a cell bank for later use. These desirable traits can be obtained by either selecting existing cells or using genetic engineering methods to insert, delete, or edit the DNA to target desired traits in cells. Examples of desirable traits may include cells that divide quickly, cells that divide a greater number of times, cells that result in a reduced cholesterol or fat content or other desirable nutritional traits, or cells that are more resilient to environmental factors, such as temperature, than other cells. According to agency officials and representatives from cell-cultured meat firms, this phase represents an important opportunity to ensure that the source cells used to initiate commercial production are free of pathogens or other contaminants. 3. Growth. During the cell growth phase, cells are placed in a bioreactor and begin to divide and differentiate. A bioreactor is a container that creates an environment that can sustain the growth of cells and includes the ability to control factors such as temperature, pH, and oxygen and carbon dioxide concentrations. Bioreactors can vary in size, including microwave-sized and refrigerator-sized units, but could be as large as 20 to 30 feet tall in commercial production. Bioreactors contain a growth medium, which may include ingredients such as glucose, amino acids, hormones and other growth factors, and other basic nutrients that cells need to consume in order to thrive. In addition to the medium needed for growth, the cells may need to be attached to a structure, referred to as a scaffold, to properly develop into cell-cultured meat. 4. Harvest. Once the cells have divided to form a sufficiently large amount of cell-cultured meat, producers remove\\u2014or harvest\\u2014it from the growth medium and bioreactor. \"\"\"\n",
        "x2=\"\"\"If a scaffold was used to provide a structure for cells to grow on, then the cell-cultured meat would either be separated from the scaffold during harvesting or left attached to an edible scaffold. 5. Food processing. The harvested cell-cultured meat is then prepared into a product such as meatballs or chicken nuggets. In the future, products similar to intact cuts of meat such as steak or chicken breast may be produced. The technology to produce cell-cultured meat at a commercial scale is still in development, and information about the methods to be used for commercial production and the composition of the final product are not yet known. In the continuum of moving a technology from innovation to commercialization, cell-cultured meat firms are in the middle stage of building and testing their prototypes, based on our discussions with representatives from these firms. Consequently, they have not finalized aspects of the technology and eventual commercial production methods to be used or the composition of the final product. As a result, certain information is not yet available to stakeholders\\u2014including cell-cultured meat firms themselves, regulators, and the public\\u2014about specific aspects of the technology and commercial production methods that will be used, such as the composition of the growth medium and of the final products. In addition to technology development, the scarcity of publicly available research on cell-cultured meat production limits information available to agency officials and the public. Each cell-cultured meat firm is developing detailed information on its own eventual commercial production methods for making cell-cultured meat. However, the firms, similar to other technology start-ups, are reluctant to disclose intellectual property and business-sensitive information due to concerns about competition. For example, one firm told us that they can reverse engineer parts of another company\\u2019s commercial production method by seeing pictures of the equipment the other company is using. In addition, cell-cultured meat firms compete with other firms for funding from sources such as venture capitalists, foreign governments, and conventional meat companies. This competition for funding contributes to firms being reluctant to share information they consider important intellectual property, such as parts of their production processes. As a result, agency officials and other stakeholders told us that they must largely rely on whatever information the cell-cultured meat firms are willing to provide to understand details of the companies\\u2019 prototype processes and products. This limitation can affect agencies\\u2019 ability to make regulatory and other decisions. Specifically, FDA and USDA officials said they have limited information on cell-cultured meat production methods and products and need more in order to regulate this new food. One USDA official explained that the agency cannot establish labeling requirements if the agency does not know the nutritional profile of the final product. For example, if the scaffold on which the cell-cultured meat is grown is not edible, the agencies may require firms to disclose certain aspects of their commercial production methods, such as how they removed the cell- cultured meat from the scaffold. However, if the scaffold is edible, it will affect the final composition of the product, which may require different labeling than a product that was developed without edible scaffolding. This lack of information results in unanswered questions about cell- cultured meat as it relates to the eventual technology and commercial production methods to be used and the composition of the final products. Among other things, this lack of information creates challenges for industry and federal regulatory agencies as cell-cultured meat nears commercialization. The sources we reviewed and stakeholders we talked to identified a number of open questions, including the following: Tissue collection. How often will producers need to collect biopsy samples from animals, and what animals will be used? Some stakeholders have stated concerns about whether, and how, regulators will ensure that biopsies are collected from healthy animals. For example, one cell-cultured meat firm stated that tissue samples would be taken from slaughtered donor animals that met federal standards for conventional processing at the time of slaughter. However, USDA and FDA have not indicated whether they would require cell-cultured meat firms to do so. Additionally, representatives from cell-cultured meat firms stated that they did not yet know how frequently they would need to collect biopsies from animals for commercial-level production. Additionally, according to researchers, there are too many unknowns to accurately estimate how much cell- cultured meat could be produced from a single biopsy of animal tissue. Genetic engineering. Will commercial production methods involve genetic engineering? Some stakeholders expressed concern that the use of genetic engineering in cell-cultured meat production could cause the product to experience a lengthy wait for regulatory approval, similar to that for genetically engineered salmon, which took approximately 20 years. One representative from a cell-cultured meat firm noted that uncertainty about pending government regulations could negatively affect firms\\u2019 ability to attract and retain investors. Representatives from some firms said understanding what regulatory requirements will look like might influence which scientific pathways they pursue as they continue to develop their commercial production methods. According to FDA officials and representatives from one cell-cultured meat firm, it is likely that some firms will use genetic engineering in their commercial cell-cultured meat production methods. However, representatives from two other cell-cultured meat firms told us they were undecided as to whether they would use genetic engineering in their commercial production methods. Antibiotics. Will antibiotics be used to make cell-cultured meat, and will residues be present in the final product? According to agency officials, the presence of antibiotics in commercial production and the potential for residues in the resulting product would represent a significant potential concern for food safety and public health. Officials stated that they would not expect antibiotics to be used past the cell- banking phase. Representatives from cell-cultured meat firms we spoke to differed on whether they planned to use antibiotics in their commercial production process, but they had not finalized their decisions. According to one firm, if antibiotics are used, the use would be limited both in quantity and duration. Growth medium. What type of growth medium will producers use, and how might variations in the media affect the final product? According to agency officials and other stakeholders, the ingredients used in the growth medium could affect the end product\\u2019s composition and raise potential safety concerns. For example, FDA officials stated that residual growth factors, such as hormones, in the final product would be something they would likely evaluate in premarket consultations. However, representatives from cell-cultured meat firms stated that their firms have not finalized the medium they plan to use. In addition, the formulation of the medium firms use could be an important piece of intellectual property or confidential business information. Scaffold. What type of scaffold will producers use, if any, and will it be edible or inedible? The use of edible or food-grade scaffolds, where they are used, will affect the composition of the product and may need to be evaluated by federal agencies for safety. According to USDA officials, the composition of edible scaffolding may also create labeling and jurisdictional concerns. For example, USDA officials stated that the addition of edible scaffolding may require significant additional aspects of production to be subject to USDA jurisdiction. Additionally, researchers have commented that a chemical separation technique needed to separate some inedible scaffolds may also need to be evaluated for potential safety concerns. Point of harvest. How will FDA and USDA define the point of harvest? The point of harvest is the point at which FDA will transfer oversight responsibilities, including inspections, to USDA. Stakeholders have raised concerns that not having a clear definition of the point of harvest could lead to challenges such as overlapping inspection requirements or a gap in inspection. Representatives from several cell-cultured meat firms we spoke to in the spring of 2019 said it was ambiguous how FDA and USDA intended to define the point of harvest. These representatives also said it is unclear how often each agency plans to conduct inspections during the phases for which it is responsible. Agency officials stated that they are working to develop a detailed process for the transfer of jurisdiction, including defining the point of harvest. Scaling up production. How will firms scale up production to commercial levels? One 2018 study conducted by researchers in the United Kingdom stated that to produce one pound of cell-cultured meat, firms would need bioreactors at least 2 1\\/2 times larger than what is currently available. Similarly, a senior FDA official stated that the capacity of existing production equipment is a challenge for firms seeking to produce cell-cultured meat products at a commercial scale. As a result, the firms themselves may have to develop the equipment or custom order such equipment. Representatives from one cell- cultured meat firm told us that they are interacting with equipment providers to identify commercial-scale production equipment. Production cost. How will firms sell their product at a price point that is both profitable to the firms and affordable to the consumer? Some studies and stakeholders we interviewed, including representatives from cell-cultured meat firms, said that the high production cost of cell- cultured meat is a key industry challenge. For example, in the last two years, one firm reported that it cost $600 to make a cell-cultured meat hamburger patty and reported that it cost about $1,200 to produce a single cell-cultured meatball. One of the biggest cost drivers in the production of cell-cultured meat is the growth medium, according to some studies and some cell-cultured meat firms. To address issues of cost and scale, some firms may develop their own, less expensive growth media. Safety considerations. Are potential safety hazards in commercial production methods for cell-cultured meat different from those for conventional meat, and how will eventual commercial production methods affect the overall safety of the product? According to agency officials, cell-cultured meat may present different safety challenges compared to conventional meat. For example, according to agency officials, residues and constituents in harvested cell-cultured meat would be expected to be different from those in conventional meat, depending on the details of the production process. Representatives from one cell-cultured meat firm told us that they likely will use food processing techniques similar to those used for conventional meat, abide by similar health and safety standards, and possibly share food processing facilities. However, because specific information about commercial production methods and final products is not yet known, it is unclear whether cell-cultured meat produced on a commercial scale will pose any hazards not present in conventional meat. Product composition. What will be the composition of any eventual products? Agency officials told us that without knowing the composition of a cell-cultured meat product, it is impossible to predict how food safety and labeling requirements will apply. According to representatives from some cell-cultured meat firms, initial cell-cultured meat products most likely will not be composed entirely of cell- cultured meat but, rather, a mixture of cell-cultured meat and other ingredients such as binding, flavoring ingredients, and plant-based materials used in conventional food products. Some firms have developed prototypes of cell-cultured meat products as part of their research and development. In April 2019, representatives from one firm told us that their prototype included about 90 percent plant-based ingredients and 10 percent cell-cultured meat. However, representatives from cell-cultured meat firms stated that they aim to produce products that contain more cell-cultured meat than other ingredients. For example, some cell-cultured meat firms have stated that a long-term goal is to commercially produce cell-cultured meat products that are similar to intact cuts of meat, such as steaks. As of December 2019, these firms had not provided regulators with specific information detailing the composition of their cell-cultured meat prototypes, according to FDA and USDA officials. Environmental, animal welfare, and health impacts. How will cell- cultured meat impact the environment, animal welfare, or human health, if at all? Cell-cultured meat firms and researchers have made various claims about the potential environmental, animal welfare, and health advantages of cell-cultured meat over conventionally produced meat. For example, some cell-cultured meat firms have claimed that cell-cultured meat production would use less water and emit less greenhouse gases than conventional meat production. Some cell- cultured meat firms have also claimed that cell-cultured meat will improve animal welfare because slaughter will be unnecessary. Additionally, some stakeholders stated that because there is less opportunity for contamination from animal feces\\u2014a potential source of contamination for conventional meat\\u2014cell-cultured meat would be less likely than conventional meat to contain foodborne pathogens. However, there are disagreements regarding the accuracy of these claims. Stakeholders told us that until commercial production methods and final products are established, these claims about impacts on the environment, animal welfare, and human health will remain unsubstantiated. Timeline to market. When will cell-cultured meat products reach consumers? As of December 2019, no cell-cultured meat products were available for retail sale in the United States. Stakeholders give varying estimates for when cell-cultured meat may be commercially available. Some estimates suggest that firms may be able to commercially produce some form of cell-cultured meat product as soon as 2020, while others estimate that such products may not be available for 2 to 4 years. Labeling. How will cell-cultured meat be labeled? Labeling was an area of concern for representatives from both conventional and cell- cultured meat firms who explained that the specific terminology, such as \\u201cclean meat\\u201d or \\u201clab-grown meat,\\u201d can sometimes reflect bias for, or against, certain products, potentially affecting consumer acceptance of these products. Additionally, stakeholders, as well as agency officials, have emphasized the importance of labeling to ensure consumers have accurate information about what they are buying. For example, in February 2018 the United States Cattlemen\\u2019s Association submitted a petition to USDA requesting that the agency limit the term \\u201cbeef\\u201d to products \\u201cborn, raised, and harvested in a traditional manner\\u201d and \\u201cmeat\\u201d to mean the \\u201ctissue or flesh of animals that have been harvested in the traditional manner.\\u201d USDA received over 6,000 comments on the petition, and the agency had not responded to the petition as of December 2019. However, according to agency officials, USDA has committed to a public process, likely rulemaking, for the development of labeling requirements for cell- cultured meat and poultry. In addition, in recent years, a number of states have passed laws that could affect the labeling of cell-cultured meat when it comes to market. For example, in 2018, Missouri enacted a law to prohibit plant-based products and cell-cultured meat from being labeled as \\u201cmeat.\\u201d Consumer Acceptance How will consumers respond to cell-cultured meat? It remains unclear whether consumers will embrace and purchase cell-cultured meat products. Stakeholders we interviewed and studies we reviewed cited consumer acceptance as a challenge for commercializing cell-cultured meat. One study noted that consumers have both positive and negative views toward cell-cultured meat, which could impact their willingness to purchase and consume such products. FDA and USDA have established multiple mechanisms to collaborate on regulatory oversight of cell-cultured meat. Specifically, the agencies have collaborated through a joint public meeting, an interagency agreement, and three working groups. However, the interagency agreement and working groups, which are ongoing mechanisms, do not fully incorporate leading practices for interagency collaboration. In addition, FDA and USDA have not documented which agency will oversee cell-cultured seafood not covered by the interagency agreement. In 2018, FDA and USDA began taking steps to collaborate on the regulatory oversight of cell-cultured meat through several mechanisms: a joint public meeting, an interagency agreement, and three working groups. The agencies held the joint meeting in October 2018 to discuss the use of cell-culture technology to develop products derived from livestock and poultry, and topics included potential hazards, oversight considerations, and labeling. As part of this meeting, FDA and USDA held an open public comment period from September through December 2018, gathered 315 written comments, and offered interested parties the opportunity to offer comments in person. The agencies received public comments from members of the public, as well as from representatives from cell-cultured meat and conventional meat industries, food and consumer safety groups, animal welfare groups, and environmental organizations, among others. The written comments the agencies received focused on such topics as environmental considerations, labeling, potential health and safety implications, and potential regulatory and inspection processes. Stakeholders also presented multiple perspectives on these issues at the meeting. For example, stakeholders expressed different views as to whether cell-cultured meat should be regulated as a food additive, considered a GRAS substance, or whether new regulations were needed. In March 2019, FDA and USDA issued a formal interagency agreement that describes the intended roles and responsibilities of each agency in overseeing cell-cultured meat. The agreement establishes the following: Oversight. FDA will oversee the early phases of growing cell-cultured meat through the point of harvest. During harvest, FDA will work with USDA to transfer regulatory oversight to USDA. USDA will then assume oversight of cell-cultured meat through the food processing phase, including labeling, as shown in figure 3. Types of meat covered. The agreement covers cell-cultured meat derived from species overseen by USDA, such as livestock, poultry, and catfish. Future actions. The agreement also details future actions the agencies plan to take, such as developing a more detailed regulatory framework or standard operating procedures and developing joint principles for product labeling. Reviewing and updating the agreement. The agreement states that the agencies have the ability to modify it as needed and will review the agreement every 3 years to determine whether they should modify or terminate it. In June 2019, FDA and USDA created three working groups to carry out the terms of the interagency agreement.\"\"\"\n",
        "x3=\"\"\"The working groups are comprised of FDA and USDA officials and operate independently, though some individuals are members of multiple groups. The groups are as follows: Pre-market assessment working group. Led by FDA, this group was created to clarify the process FDA will use for pre-market reviews of cell-cultured meat. Labeling working group. Led by USDA, this group will focus on developing joint principles for product labeling and claims. Transfer of jurisdiction working group. Co-led by FDA and USDA, this group will develop procedures for the transfer of inspection at harvest, among other things. According to agency officials, the working groups are still in the initial phases of development, though some have progressed further than others. For example, as of December 2019, the pre-market assessment and labeling groups had met and begun to address various areas, while the transfer of jurisdiction working group was still in discussions to outline the roles, responsibilities, and outcomes for the group and had not held a formal meeting. FDA and USDA could more fully incorporate leading practices for collaboration in their interagency agreement and working groups. We have previously reported that interagency mechanisms or strategies to coordinate programs that address crosscutting issues may reduce potentially duplicative, overlapping, and fragmented efforts. In addition, while collaborative mechanisms may differ in complexity and scope, they all benefit from certain leading practices, which raise issues to consider when implementing these mechanisms. We compared the agencies\\u2019 interagency agreement and working groups with the seven leading practices to enhance and sustain interagency collaboration that we previously identified. These leading practices, and examples of the associated issues to consider, are as follows: Defining outcomes and monitoring accountability. Is there a way to track and monitor progress toward short-term and long-term outcomes? Do participating agencies have collaboration-related competencies or performance standards against which individual performance can be evaluated? Bridging organizational cultures. What are the commonalities between the participating agencies\\u2019 missions and cultures, and what are some potential challenges? Have participating agencies developed ways for operating across agency boundaries? Have participating agencies agreed on common terminology and definitions? Identifying and sustaining leadership. How will leadership be sustained over the long term? If leadership is shared, have roles and responsibilities been clearly identified and agreed upon? Clarifying roles and responsibilities. Have participating agencies clarified roles and responsibilities? Have participating agencies articulated and agreed to a process for making and enforcing decisions? Including relevant participants. Have all relevant participants been included? Do participants have appropriate knowledge, skills, and abilities to contribute? Identifying and leveraging resources. How will the collaborative mechanism be funded and staffed? Developing and updating written guidance and agreements. If appropriate, have the participating agencies documented their agreement regarding how they will collaborate? (A written document can incorporate agreements reached in any or all of the following areas: leadership, accountability, roles and responsibilities, and resources.) Have participating agencies developed ways to continually update or monitor written agreements? See appendix II for a full list of the associated issues to consider for each leading practice. We found that the interagency agreement for oversight of cell-cultured meat partially incorporates all seven leading practices for collaboration. For example: Defining outcomes and monitoring accountability. The interagency agreement partially incorporates the leading practice of defining outcomes and monitoring progress toward these outcomes. Specifically, the agreement identifies broad outcomes such as the development of labeling principles. However, the agreement does not describe how the agencies will track and monitor progress toward outcomes. Identifying and sustaining leadership. The agreement partially incorporates the leading practice of clarifying leadership structures. For example, it assigns each agency as the lead, or designates shared leadership, for different phases of the cell-cultured meat production process. However, the interagency agreement does not identify how the agencies will sustain leadership over the long term, including through succession planning. We have previously reported that given the importance of leadership to any collaborative effort, transitions and inconsistent leadership can weaken the effectiveness of any collaborative mechanism. Developing and updating written guidance and agreements. The agreement partially incorporates the leading practice of documenting how the agencies will collaborate. For example, the agreement includes a method for updating the document by including a provision that requires a review of the document every 3 years. This is consistent with our leading collaboration practice to continually update or monitor written agreements. However, the interagency agreement does not document how the agencies will track and monitor progress toward short-term and long-term outcomes. Table 1 provides more detail about the agencies\\u2019 incorporation of these leading collaboration practices in their interagency agreement. FDA and USDA officials told us that the interagency agreement was intended to be an initial, general outline for their collaboration. They also said that as the technology to produce cell-cultured meat develops and they implement the agreement, including developing the content of a regulatory program, they will consider incorporating leading practices for interagency collaboration. For example: Clarifying roles and responsibilities. FDA and USDA officials said in December 2019 that through the working groups the agencies would continue to explore and define the specific details of how they will manage their shared oversight responsibility. Including relevant participants. FDA officials said in December 2019 that the agency would like to engage many more stakeholders as it continues to develop its oversight of cell-cultured meat. Identifying and leveraging resources. As of December 2019, the pre-market assessment working group and the labeling working group were working to identify any human resources, physical, or financial resources they might need, according to FDA and USDA officials. The federal food safety system is on our High Risk List due to concerns about fragmentation, which we have reported has caused inconsistent oversight, ineffective coordination, and inefficient use of resources. As the agencies continue to collaborate on their shared oversight of cell- cultured meat, by more fully incorporating all seven leading practices for collaboration into their interagency agreement, they will be better positioned to address potential fragmentation in their efforts to ensure the safety of the food supply as cell-cultured meat products near commercialization and entry into the marketplace. We found that the pre-market assessment, labeling, and transfer of jurisdiction working groups that FDA and USDA created to carry out the terms of the interagency agreement either partially incorporate or do not incorporate the seven leading practices for interagency collaboration. Specifically, all three working groups have partially incorporated three of the seven leading practices for collaboration, but none of the working groups have incorporated the four remaining leading practices. For example: Defining outcomes and monitoring accountability. The working groups have all defined and agreed upon their general purposes. However, FDA and USDA have not established methods, such as milestones and metrics, to evaluate the progress of any of the working groups. For example, FDA officials said in December 2019 that their next steps are to conduct a general and qualitative risk assessment of animal cell culture food technology to systematically identify particular areas of interest from a food safety perspective and prepare detailed procedural guidelines for cell-cultured meat firms to follow. However, the officials did not have time frames or a method to evaluate progress towards completing these actions. Including relevant participants. While the working groups have included relevant FDA and USDA officials, none of the groups have included state or tribal officials in initial discussions and planning. According to the state officials we spoke with, being excluded from these federal-level discussions may hinder their ability to align their safety and labeling requirements, among other things, with federal standards. Developing and updating written guidance and agreements. None of the working groups have documented how they will collaborate. For example, the working groups have not documented leadership, accountability, roles and responsibilities, or resources needed for working groups. Table 2 provides more detail about FDA and USDA\\u2019s incorporation of leading collaboration practices in the three working groups. In December 2019, FDA and USDA officials said that as they continued to stand up these working groups, they were considering leading practices for collaboration. For example: Defining outcomes and monitoring accountability. FDA and USDA officials said they were considering means to monitor, evaluate, or report on the results of the pre-market assessment working group. Including relevant participants. FDA and USDA officials said that they were working to determine what knowledge participants in the pre-market assessment working group and the labeling working group needed to perform the work of the working group. Developing and updating written guidance and agreements. FDA and USDA officials said they were considering documenting how they will collaborate in the pre-market assessment working group, including potentially creating a charter for the working group. We have previously reported that fragmentation has caused inconsistent oversight and inefficient use of resources in the federal food safety oversight system. \"\"\"\n",
        "x4=\"\"\"The agencies\\u2019 2019 agreement to share oversight of cell-cultured meat creates a new relationship between FDA and USDA, since the agencies will oversee different stages of the production of the same food and hand off oversight at a certain point in that production. These factors contribute to an already complicated system in which the two agencies must coordinate on food safety oversight. In this context, some industry representatives and other stakeholders have expressed concerns about potential fragmentation or overlap in oversight of cell-cultured meat, such as could occur during the harvest phase of cell-cultured meat production when FDA hands off its oversight to USDA. Additionally, representatives from one cell-cultured meat firm stated that avoiding overlap in federal oversight whenever possible was important to them. For example, representatives from one firm pointed to inspection, record-keeping requirements, and regulations as potential areas at risk of overlap. They stated that potential overlap would add unnecessary, burdensome requirements and create an uneven playing field with the conventional meat industry. By more fully incorporating all seven leading practices for interagency collaboration early in the development of the three working groups, FDA and USDA could proactively minimize potential fragmentation and overlap in their oversight of cell-cultured meat, ensure consistency and efficient use of resources, and provide clarity to key stakeholders. While FDA and USDA officials told us they have decided who will oversee cell-cultured seafood, they have not formally announced or documented this decision, and some stakeholders have reported confusion or ambiguity about which agency will oversee cell-cultured seafood other than catfish. Specifically, FDA and USDA\\u2019s interagency agreement regarding cell-cultured meat states that it covers all cell-cultured meat derived from USDA-amenable species required to bear a USDA mark of inspection, which in the agreement includes livestock, poultry, and catfish. However, the agreement does not mention cell-cultured meat made from the cells of other fish, such as tuna and shellfish. FDA and USDA officials told us that FDA will have sole oversight responsibility for cell-cultured seafood other than catfish. According to FDA officials, they have verbally communicated this decision in various meetings with stakeholders. However, FDA and USDA officials told us that formally documenting FDA\\u2019s sole oversight of most cell- cultured seafood in their interagency agreement was unnecessary because FDA currently oversees most conventional seafood. According to cell-cultured meat firms, some firms are working on developing cell- cultured versions of seafood, such as bluefin tuna. However, stakeholders from two cell-cultured meat firms, including representatives of a cell- cultured seafood firm we spoke with in April 2019, stated that they did not know who in the federal government would oversee cell-cultured seafood. Representatives from one cell-cultured seafood firm said that not being able to rule out oversight by USDA prevented them from making key decisions regarding what direction to pursue in developing their commercial production method. While FDA and USDA officials told us they had agreed that FDA would oversee cell-cultured seafood other than catfish, as of December 2019, the agencies had not formally announced or documented this agreement. Developing and updating written guidance and agreements is a leading practice for collaboration, as we have previously reported. In addition, standards for internal control in the federal government state that agency management should externally communicate the necessary quality information to achieve its objectives and should select appropriate methods of communication, such as a written document or a face-to-face meeting. Management should also periodically evaluate the entity\\u2019s methods of communication so that the organization has the appropriate tools to communicate quality information throughout and outside of the entity on a timely basis. While FDA and USDA officials have informally communicated to some stakeholders that FDA will have sole oversight of most cell-cultured seafood, FDA has not communicated this information formally or in a method readily available to all relevant stakeholders, such as in their interagency agreement or other publicly available written document. FDA and USDA officials told us that they wanted to communicate this information through outreach to individual firms, but FDA or USDA officials said they did not think that revising their interagency agreement was necessary. By taking steps to document which agency will oversee cell-cultured seafood other than catfish, FDA and USDA will better ensure the public, including key stakeholders such as cell-cultured meat firms, have clarity about the agencies\\u2019 oversight responsibilities in this area. Cell-cultured meat is a new food product that raises many questions. FDA and USDA\\u2019s shared oversight of cell-cultured meat poses various challenges for these agencies, as well as stakeholders such as industry. Compounding this challenge is that specific information about key aspects of cell-cultured meat, such as the technology and production methods to be used as well as the composition of the products, is not yet known. FDA and USDA have taken steps to collaborate on their shared regulatory oversight of cell-cultured meat, including establishing an interagency agreement and three working groups. However, the interagency agreement only partially incorporates the seven leading collaboration practices that can enhance and sustain agencies\\u2019 collaborative efforts, and the working groups either partially incorporate or do not incorporate these leading practices, which has raised concerns about potential fragmentation or overlap in oversight. By more fully incorporating all seven leading practices for collaboration into their interagency agreement, FDA and USDA could build on their existing efforts and be better positioned to sustain and enhance their collaborative efforts. Moreover, by more fully incorporating all seven leading practices for interagency collaboration early in the development of the working groups, FDA and USDA could proactively minimize potential fragmentation and overlap in their oversight of cell-cultured meat and ensure they are utilizing resources efficiently or effectively. Furthermore, the interagency agreement states that it covers USDA- amenable species required to bear a USDA mark of inspection, which in the agreement includes livestock, poultry, and catfish but does not include cell-cultured seafood other than catfish. FDA and USDA officials told us they have decided FDA will oversee most cell-cultured seafood, but the agencies have not formally documented this decision. By taking steps to document in their interagency agreement, or other publicly available document, which agency will oversee cell-cultured seafood other than catfish, FDA and USDA could better ensure that members of the public and other key stakeholders such as cell-cultured meat firms have clarity about the agencies\\u2019 oversight responsibilities in this area. We are making a total of six recommendations, three to FDA and three to USDA: The Commissioner of the Food and Drug Administration, in coordination with the Secretary of Agriculture, should more fully incorporate the seven leading practices for effective collaboration in the agencies\\u2019 interagency agreement for the joint oversight of cell-cultured meat. (Recommendation 1) The Secretary of Agriculture, in coordination with the Commissioner of the Food and Drug Administration, should more fully incorporate the seven leading practices for effective collaboration in the agencies\\u2019 interagency agreement for the joint oversight of cell-cultured meat. (Recommendation 2) As the three cell-cultured meat working groups move forward, the Commissioner of the Food and Drug Administration, in coordination with the Secretary of Agriculture, should more fully incorporate the seven leading practices for effective collaboration, such as identifying specific outcomes and a way to monitor and evaluate progress toward outcomes. (Recommendation 3) As the three cell-cultured meat working groups move forward, the Secretary of Agriculture, in coordination with the Commissioner of the Food and Drug Administration, should more fully incorporate the seven leading practices for effective collaboration, such as identifying specific outcomes and a way to monitor and evaluate progress toward outcomes. (Recommendation 4) The Commissioner of the Food and Drug Administration, in coordination with the Secretary of Agriculture, should clearly document in their interagency agreement, or other publicly available document, which agency will oversee cell-cultured seafood other than catfish. (Recommendation 5) The Secretary of Agriculture, in coordination with the Commissioner of the Food and Drug Administration, should clearly document in their interagency agreement, or other publicly available document, which agency will oversee cell-cultured seafood other than catfish. (Recommendation 6) We provided a draft of this report to the Department of Health and Human Services\\u2019 (HHS) Food and Drug Administration (FDA) and the U.S. Department of Agriculture (USDA) for review and comment. In FDA\\u2019s comments, reproduced in appendix III, the agency stated that it values GAO\\u2019s recognition of the importance of collaborative mechanisms that facilitate coordination and affirmed its commitment to coordinate closely with USDA to ensure the regulatory framework for cell-cultured meat is clear and transparent to stakeholders. In USDA\\u2019s comments, reproduced in appendix IV, the department stated that the report put too much focus on best practices for interagency collaboration and not enough emphasis on industry\\u2019s role in providing the agencies with the information they need to move their processes forward to effectively regulate cell-cultured meat.\"\"\"\n",
        "x5=\"\"\" USDA stated that it is difficult to review a developing technology and its future regulatory oversight when so little detailed information about the technology is known. We agree that the technology to produce cell-cultured meat is still in development and that information about the commercial production methods and composition of the final product are not yet known, as we state in our report. We also acknowledge in our report that having limited information can affect the agencies\\u2019 ability to make regulatory and other decisions. We recognize that cell-cultured meat is a new food product that raises many new questions and that specific information about key aspects of cell-cultured meat is not yet known. In light of this challenging context, it is all the more important that FDA and USDA more fully incorporate leading practices for collaboration into their joint efforts in order to ensure they are in the best possible position to oversee this new food product. FDA concurred with two recommendations and partially concurred with one. USDA also concurred with two recommendations and partially concurred with one. Specifically, both agencies agreed with our recommendations regarding (1) more fully incorporating the seven leading practices for effective collaboration in the three cell-cultured meat working groups as they move forward and (2) clearly documenting which agency will oversee cell-cultured seafood other than catfish. FDA and USDA partially concurred with our recommendation, directed to each agency, to more fully incorporate the seven leading practices for effective collaboration into the agencies\\u2019 interagency agreement for the joint oversight of cell-cultured meat. FDA stated that it concurred with the intent of incorporating the seven leading practices into the interagency agreement, and both agencies said that they are open to incorporating the practices into their development of the structure for joint oversight of cell-cultured meat. However, the agencies stated that they did not agree to revise the agreement at this time. FDA and USDA stated that the agreement is a general framework and that incorporating the leading practices would constitute an inappropriate level of detail. Instead, the agencies stated that they believe it would be most valuable to incorporate the leading practices into a more detailed joint framework or standard operating procedure they plan to issue. We appreciate the agencies\\u2019 willingness to incorporate the leading practices for effective collaboration into their efforts. The March 2019 interagency agreement states that the agencies have the ability to modify it as needed and will review the agreement every 3 years to determine whether they should modify or terminate it. Therefore, the agencies are due to revisit the agreement in March 2022, if not sooner. Regarding the agencies\\u2019 concern that incorporating the leading practices in the interagency agreement would add an inappropriate level of detail, we note that, as we state in our report, the existing agreement already partially incorporates each of the seven leading practices. We continue to believe that FDA and USDA should more fully incorporate the seven leading practices for effective collaboration into their interagency agreement for the joint oversight of cell-cultured meat. Developing a more detailed joint framework or standard operating procedure in accordance with the existing interagency agreement that incorporates those leading practices would meet the intent of our recommendation to improve the effectiveness of the agencies\\u2019 collaboration. FDA and USDA also provided technical comments, which we incorporated as appropriate. As agreed with your office, unless you publicly announce its contents earlier, we plan no further distribution of this report until 30 days from its issue date. At that time, we will send copies of this report to the appropriate congressional committees, the Secretary of Health and Human Services, the Secretary of Agriculture, and other interested parties. In addition, the report is available at no charge on the GAO website at http:\\/\\/www.gao.gov. If you or your staff members have any questions regarding this report, please contact me at (202) 512-3841 or morriss@gao.gov. Contact points for our Offices of Congressional Relations and Public Affairs may be found on the last page of this report. GAO staff who made key contributions to this report are listed in appendix V. Our report (1) describes what is known about methods for commercially producing cell-cultured meat and (2) examines the extent to which the Food and Drug Administration (FDA) and U.S. Department of Agriculture (USDA) are collaborating to provide regulatory oversight of cell-cultured meat. For both objectives, we conducted a literature review of journal and media articles from 2016 through 2019 to inform our understanding of cell- cultured meat, as well as regulatory activity related to cell-cultured meat in the United States and in other countries. Specifically, we conducted a review of scholarly and trade news from 2016 through July 2019 for specific terms related to cell-cultured meat and regulatory approaches. We conducted searches in more than 30 different academic and trade databases\\u2014such as SCOPUS, Foodline, and ProQuest\\u2019s Environmental Science Collection\\u2014and identified studies relevant to our research objectives. In addition to these formal literature searches, we also asked agency officials and stakeholders to refer us to research articles and publications on cell-cultured meat. We also reviewed documentation from FDA and USDA, including the 2019 interagency agreement, existing memoranda of understanding between the two agencies, Federal Register notices about relevant public meetings, and press releases. We also reviewed documentation such as letters to regulators, presentation slides, and information on organizations\\u2019 websites from the cell-cultured meat industry, conventional meat industry, and consumer safety groups, among others. We also interviewed officials from FDA and USDA and representatives of stakeholders from the cell-cultured meat industry and industry associations, conventional meat firms and industry associations, academia, food and consumer safety groups, and state and tribal public health associations, among others. We identified stakeholders to interview through consultation with agency officials and nonfederal stakeholders and through our review of literature. We conducted 17 interviews with representatives or researchers from: six cell-cultured meat firms or industry associations, four conventional meat firms or industry associations, two food and consumer safety groups, one state and tribal public health association, and one food law policy firm. Because this is a nongeneralizable sample, the results of these interviews do not represent the views of all stakeholders involved in or with an interest in the cell-cultured or conventional meat industries or federal regulation of cell-cultured meat. However, they illustrate the range of perspectives on these topics. We also attended public meetings and conferences and conducted site visits to several locations. Specifically, we attended FDA and USDA\\u2019s public meeting in October 2018 and four conferences in 2019 that included content pertaining to food safety or cell-cultured meat. We conducted site visits to two conventional meat-processing facilities in Georgia, three cell-cultured meat firms in California, an academic cell- culturing laboratory in California, and a medical cell-culturing facility in Maryland. We identified facilities and laboratories to visit through our literature review, online research, and the assistance of agency officials and stakeholders, such as representatives from the cell-cultured meat and conventional meat industry. To describe what is known about the process for producing cell-cultured meat and potential commercial production methods, we also reviewed two sets of public comments submitted to FDA and USDA in association with the two 2018 public meetings pertaining to cell-cultured meat. These meetings were \\u201cFoods Produced Using Animal Cell Culture Technology\\u201d in July 2018 and \\u201cUse of Cell Culture Technology to Develop Products Derived from Livestock and Poultry\\u201d in October 2018. Public comments were submitted by members of the public; representatives from cell- cultured meat firms and industry associations, conventional meat companies and industry associations, food and consumer safety groups, and animal welfare groups; and environmental organizations, among others. We reviewed and analyzed all comments submitted to (1) FDA related to the July 2018 meeting and (2) FDA and USDA related to the October 2018 meeting. We also attended the October 2018 meeting and listened to agency officials\\u2019 presentations and oral remarks made by stakeholders and members of the public. We shared our description of the process for making cell-cultured meat, and associated questions, with representatives from three cell-cultured meat firms and academic researchers at two universities for their technical review and incorporated revisions as appropriate. To examine the extent to which FDA and USDA are coordinating to provide regulatory oversight of cell-cultured meat, we identified actions they took to coordinate from July 2018 through April 2020. To identify these actions, we interviewed agency officials, emailed agency officials written questions, reviewed agency documentation and public announcements, and attended public events such as the October 2018 public meeting. We compared the agencies\\u2019 interagency agreement and working groups with seven leading practices to enhance and sustain interagency collaboration. Specifically, two independent GAO reviewers assessed the degree to which agencies\\u2019 actions incorporated these leading practices. A description of these leading practices and the associated issues to consider is in appendix II. We also assessed the agencies\\u2019 actions against standards for internal control in the federal government, including standards related to communicating quality information. In this report, and in our past work, we define collaboration as any joint activity that is intended to produce more public value than could be produced when organizations act alone. We use the terms \\u201ccoordination\\u201d and \\u201ccollaboration\\u201d interchangeably in this report. For the purposes of our report, we define cell-cultured meat as food derived from animal cells that were grown in a controlled environment outside of the animal. We define cell-cultured seafood as a subcategory of cell-cultured meat. When referencing conventional meat, we are referring to food produced from the traditional method of slaughtering an animal, such as a cow, hog, chicken, or fish. When referencing seafood, we are referring to shellfish, sea fish, and freshwater fish served as food. We conducted this performance audit from October 2018 to April 2020 in accordance with generally accepted government auditing standards. Those standards require that we plan and perform the audit to obtain sufficient, appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives. We believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives. Appendix II: Key Issues to Consider for Implementing Interagency Collaborative Mechanisms Issues to consider Have short-term and long-term outcomes been clearly defined? Is there a way to track and monitor progress toward the short-term and long-term outcomes? Do participating agencies have collaboration-related competencies or performance standards against which individual performance can be evaluated? Do participating agencies have the means to recognize and reward accomplishments related to collaboration? What are the missions and organizational cultures of the participating agencies? What are the commonalities between the participating agencies\\u2019 missions and cultures and what are some potential challenges? Have participating agencies developed ways for operating across agency boundaries? Have participating agencies agreed on common terminology and definitions? Has a lead agency or individual been identified? If leadership will be shared between one or more agencies, have roles and responsibilities been clearly identified and agreed upon? How will leadership be sustained over the long term? Have participating agencies clarified the roles and responsibilities of the participants? Have participating agencies articulated and agreed to a process for making and enforcing decisions? Have all relevant participants been included? Do the participants have: Full knowledge of the relevant resources in their agency? The ability to commit these resources? The ability to regularly attend activities of the collaborative mechanism? The appropriate knowledge, skills, and abilities to contribute? Developing and updating written guidance and agreements How will the collaborative mechanism be funded? If interagency funding is needed, is it permitted? If interagency funding is needed and permitted, is there a means to track funds in a standardized manner? How will the collaborative mechanism be staffed? Are there incentives available to encourage staff or agencies to participate? If relevant, do agencies have compatible technological systems? Have participating agencies developed online tools or other resources that facilitate joint interactions? If appropriate, have the participating agencies documented their agreement regarding how they will be collaborating? A written document can incorporate agreements reached in any or all of the following areas: Leadership Accountability Roles and responsibilities Resources Have participating agencies developed ways to continually update or monitor written agreements? Steve D. Morris, (202) 512-3841 or morriss@gao.gov In addition to the contact named above, Nico Sloss (Assistant Director), Angela Miles (Analyst-in-Charge), Sahar Angadjivand, Tim Bober, Kevin Bray, Colleen Candrl, Pin En Annie Chou, Tara Congdon, Heather Dowey, Kim Gianopoulos, Gina Hoover, Hayden Huang, Robert Lepzler, Serena Lo, David Lysy, Marc Meyer, Michael Polak, Danny Royer, Sara Sullivan, and Sarah Veale made key contributions to this report\"\"\"\n",
        "para1 = x1+x2+x3+x4+x5\n",
        "original_document = para1\n",
        "#extractive summary\n",
        "para2 = \"\"\"FDA and USDA have responsibility for overseeing the safety of the food supply. General information about the process of making cell-cultured meat is available, but specific information about the technology being used and the eventual commercial production methods as well as the final products is not yet known. However, the technology and methods to commercially produce cell- cultured meat are still in development, and producers, regulators, and consumers do not yet have clarity on what these will entail. The composition of the final product is also not yet known. The general process for making cell-cultured meat contains five phases: biopsy, cell banking, growth, harvest, and food processing. The technology to produce cell-cultured meat at a commercial scale is still in development, and information about the methods to be used for commercial production and the composition of the final product are not yet known. Consequently, they have not finalized aspects of the technology and eventual commercial production methods to be used or the composition of the final product. As a result, certain information is not yet available to stakeholders\\u2014including cell-cultured meat firms themselves, regulators, and the public\\u2014about specific aspects of the technology and commercial production methods that will be used, such as the composition of the growth medium and of the final products. This lack of information results in unanswered questions about cell- cultured meat as it relates to the eventual technology and commercial production methods to be used and the composition of the final products. Some firms have developed prototypes of cell-cultured meat products as part of their research and development. In June 2019, FDA and USDA created three working groups to carry out the terms of the interagency agreement. FDA and USDA could more fully incorporate leading practices for collaboration in their interagency agreement and working groups. Developing and updating written guidance and agreements. However, the agreement does not describe how the agencies will track and monitor progress toward outcomes. Developing and updating written guidance and agreements. Developing and updating written guidance and agreements. Developing and updating written guidance and agreements. By more fully incorporating all seven leading practices for interagency collaboration early in the development of the three working groups, FDA and USDA could proactively minimize potential fragmentation and overlap in their oversight of cell-cultured meat, ensure consistency and efficient use of resources, and provide clarity to key stakeholders. While FDA and USDA officials told us they have decided who will oversee cell-cultured seafood, they have not formally announced or documented this decision, and some stakeholders have reported confusion or ambiguity about which agency will oversee cell-cultured seafood other than catfish. While FDA and USDA officials told us they had agreed that FDA would oversee cell-cultured seafood other than catfish, as of December 2019, the agencies had not formally announced or documented this agreement. Developing and updating written guidance and agreements is a leading practice for collaboration, as we have previously reported. Compounding this challenge is that specific information about key aspects of cell-cultured meat, such as the technology and production methods to be used as well as the composition of the products, is not yet known. FDA and USDA officials told us they have decided FDA will oversee most cell-cultured seafood, but the agencies have not formally documented this decision. We agree that the technology to produce cell-cultured meat is still in development and that information about the commercial production methods and composition of the final product are not yet known, as we state in our report. FDA concurred with two recommendations and partially concurred with one. USDA also concurred with two recommendations and partially concurred with one. FDA and USDA partially concurred with our recommendation, directed to each agency, to more fully incorporate the seven leading practices for effective collaboration into the agencies\\u2019 interagency agreement for the joint oversight of cell-cultured meat. We continue to believe that FDA and USDA should more fully incorporate the seven leading practices for effective collaboration into their interagency agreement for the joint oversight of cell-cultured meat. GAO staff who made key contributions to this report are listed in appendix V. Our report (1) describes what is known about methods for commercially producing cell-cultured meat and (2) examines the extent to which the Food and Drug Administration (FDA) and U.S. Department of Agriculture (USDA) are collaborating to provide regulatory oversight of cell-cultured meat. Developing and updating written guidance and agreements How will the collaborative mechanism be funded?\"\"\"\n",
        "extractive_summary = para2\n",
        "#abstractive summary\n",
        "abstractive_summary = \"\"\"Multiple firms have produced cell-cultured meat as part of their research and development. These products appear likely to become available to consumers in coming years. FDA and USDA are the primary agencies responsible for overseeing the safety of the nation's food supply. However, some stakeholders have expressed concern about the agencies' oversight of cell-cultured meat amidst a fragmented federal food safety oversight system. GAO was asked to review federal oversight of cell-cultured meat. This report (1) describes what is known about methods for commercially producing cell-cultured meat, and (2) examines the extent to which FDA and USDA are collaborating to provide regulatory oversight of cell-cultured meat. GAO conducted a literature review; reviewed documentation from FDA, USDA, and stakeholder groups; analyzed public comments submitted to the agencies; compared agency efforts with leading practices for interagency collaboration; and conducted site visits to selected cell-cultured meat firms. General information about the process of making cell-cultured meat\\u2014food products grown from the cells of livestock, poultry, and seafood\\u2014is available. However, no company is commercially producing cell-cultured meat. Specific information about the technology being used, eventual commercial production methods, and composition of the final products is not yet known. The general process contains five phases: biopsy, cell banking, growth, harvest, and food processing (see figure). The technology and methods to be used for commercial production are still in development, and producers, regulators, and consumers do not have clarity about many specifics about the process and final product. For example, it is unclear whether production methods and products will use or contain genetically-engineered cells or medications such as antibiotics. The Food and Drug Administration (FDA) and U.S. Department of Agriculture (USDA) have begun collaborating on regulatory oversight of cell-cultured meat. For example, in 2019, the agencies signed an interagency agreement and created three working groups to carry out the terms of the agreement. However, the agreement and working groups could more fully incorporate practices to enhance and sustain collaboration, such as defining outcomes. For example, the agreement identifies the development of labeling principles as an outcome, but does not describe how the agencies will track and monitor progress toward this outcome, and the working groups identify a lead agency but not members' roles. Also, agency officials said they decided FDA would oversee cell-cultured seafood other than catfish, but they have not formally announced or documented this decision. Developing and updating written guidance and agreements is also a leading practice for interagency collaboration. By fully incorporating leading practices into their efforts to collaborate, the agencies could minimize potential overlap and fragmentation, use resources in a more efficient manner, and better ensure the public and other key stakeholders have clarity about the agencies' oversight responsibilities. GAO recommends that FDA and USDA more fully incorporate leading practices for effective collaboration in the agencies' interagency agreement. FDA and USDA partially concurred and indicated a willingness to incorporate these practices in a more detailed agreement, which would also meet the intent of the recommendations. The agencies concurred with the four other recommendations.\"\"\""
      ],
      "metadata": {
        "id": "D8RnY-zXGkWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Longforner"
      ],
      "metadata": {
        "id": "xEnHz7uX4Wuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from transformers import LongformerModel, LongformerTokenizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cdist\n",
        "import numpy as np\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# --- Load Longformer Model and Tokenizer ---\n",
        "print(\"Loading Longformer model and tokenizer...\")\n",
        "model_name = 'allenai/longformer-base-4096'\n",
        "tokenizer = LongformerTokenizer.from_pretrained(model_name)\n",
        "model = LongformerModel.from_pretrained(model_name)\n",
        "\n",
        "# --- Set Device (GPU if available, else CPU) ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.eval() # Set model to evaluation mode\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "print(\"Longformer model loaded.\")\n",
        "\n",
        "# --- Helper Function for Sentence Embeddings ---\n",
        "def get_sentence_embeddings(text, batch_size=4):\n",
        "    \"\"\"\n",
        "    Splits text into sentences, tokenizes them, and gets Longformer embeddings.\n",
        "    Handles long documents by processing sentences in batches.\n",
        "    Returns:\n",
        "        sentences (list): List of original sentence strings.\n",
        "        sentence_embeddings (np.array): NumPy array of sentence embeddings.\n",
        "    \"\"\"\n",
        "    doc = nlp(text) # nlp is globally defined at the start of the cell\n",
        "    sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
        "\n",
        "    if not sentences:\n",
        "        print(\"Warning: No valid sentences found in the input text.\")\n",
        "        return [], np.array([])\n",
        "\n",
        "    all_sentence_embeddings = []\n",
        "    print(f\"Total sentences to process: {len(sentences)}\")\n",
        "\n",
        "    for i in range(0, len(sentences), batch_size):\n",
        "        batch_sentences = sentences[i:i + batch_size] # CORRECTED: using batch_size\n",
        "        try:\n",
        "            inputs = tokenizer(\n",
        "                batch_sentences,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=tokenizer.model_max_length\n",
        "            ).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            all_sentence_embeddings.extend(cls_embeddings)\n",
        "            # Removed detailed batch print to reduce output clutter unless needed for debugging speed\n",
        "            # print(f\"  Processed batch {i // batch_size + 1}/{(len(sentences) + batch_size - 1) // batch_size}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing batch of sentences (index {i}-{i+len(batch_sentences)-1}): {e}\")\n",
        "            all_sentence_embeddings.extend([np.zeros(model.config.hidden_size)] * len(batch_sentences))\n",
        "            continue\n",
        "\n",
        "    return sentences, np.array(all_sentence_embeddings)\n",
        "\n",
        "# --- Centroid-Based Summarization Function (Optimized to accept pre-calculated embeddings) ---\n",
        "def centroid_summarization_optimized(sentences, embeddings, num_sentences=3):\n",
        "    \"\"\"\n",
        "    Generates an extractive summary using a centroid-based approach.\n",
        "    Accepts pre-calculated sentences and embeddings.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Starting Centroid-Based Summarization ---\")\n",
        "    if not sentences or embeddings.shape[0] == 0:\n",
        "        print(\"  No sentences or embeddings provided. Cannot summarize.\")\n",
        "        return [], []\n",
        "\n",
        "    if num_sentences <= 0:\n",
        "        print(\"  Number of sentences for summary must be positive.\")\n",
        "        return [], []\n",
        "\n",
        "    num_sentences_to_extract = min(num_sentences, len(sentences))\n",
        "\n",
        "    document_centroid = np.mean(embeddings, axis=0)\n",
        "    similarities = cosine_similarity(embeddings, document_centroid.reshape(1, -1)).flatten()\n",
        "\n",
        "    summary_sentences_mmr = []\n",
        "    selected_indices = set()\n",
        "    ranked_initial_indices = np.argsort(similarities)[::-1]\n",
        "\n",
        "    for _ in range(num_sentences_to_extract):\n",
        "        best_sentence_idx = -1\n",
        "        max_mmr_score = -1\n",
        "\n",
        "        for i in ranked_initial_indices:\n",
        "            if i not in selected_indices:\n",
        "                relevance = similarities[i]\n",
        "\n",
        "                if not selected_indices:\n",
        "                    mmr_score = relevance\n",
        "                else:\n",
        "                    diversity_scores = cosine_similarity(embeddings[i].reshape(1, -1),\n",
        "                                                         embeddings[list(selected_indices)])\n",
        "                    redundancy = np.max(diversity_scores)\n",
        "                    lambda_param = 0.5\n",
        "                    mmr_score = lambda_param * relevance - (1 - lambda_param) * redundancy\n",
        "\n",
        "                if mmr_score > max_mmr_score:\n",
        "                    max_mmr_score = mmr_score\n",
        "                    best_sentence_idx = i\n",
        "\n",
        "        if best_sentence_idx != -1:\n",
        "            summary_sentences_mmr.append((sentences[best_sentence_idx], best_sentence_idx))\n",
        "            selected_indices.add(best_sentence_idx)\n",
        "            ranked_initial_indices = ranked_initial_indices[ranked_initial_indices != best_sentence_idx]\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    summary_sentences_mmr.sort(key=lambda x: x[1])\n",
        "    final_summary_sents = [s[0] for s in summary_sentences_mmr]\n",
        "    final_summary_indices = [s[1] for s in summary_sentences_mmr]\n",
        "\n",
        "    print(\"--- Centroid-Based Summarization Complete ---\")\n",
        "    return final_summary_sents, final_summary_indices\n",
        "\n",
        "# --- K-Means Based Summarization Function (Optimized to accept pre-calculated embeddings) ---\n",
        "def kmeans_summarization_optimized(sentences, embeddings, num_clusters=25, num_sentences_per_cluster=1):\n",
        "    \"\"\"\n",
        "    Generates an extractive summary using K-Means clustering.\n",
        "    Accepts pre-calculated sentences and embeddings.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Starting K-Means Based Summarization ---\")\n",
        "    if not sentences or embeddings.shape[0] == 0:\n",
        "        print(\"  No sentences or embeddings provided. Cannot summarize.\")\n",
        "        return [], []\n",
        "\n",
        "    if num_clusters <= 0 or num_sentences_per_cluster <= 0:\n",
        "        print(\"  Number of clusters and sentences per cluster must be positive.\")\n",
        "        return [], []\n",
        "\n",
        "    effective_num_clusters = min(num_clusters, len(sentences))\n",
        "\n",
        "    if effective_num_clusters == 0:\n",
        "        print(\"  Not enough sentences to form clusters.\")\n",
        "        return [], []\n",
        "\n",
        "    kmeans = KMeans(n_clusters=effective_num_clusters, random_state=42, n_init='auto')\n",
        "    kmeans.fit(embeddings)\n",
        "    clusters = kmeans.labels_\n",
        "    centroids = kmeans.cluster_centers_\n",
        "\n",
        "    summary_sentences_with_idx = []\n",
        "    selected_indices = set()\n",
        "\n",
        "    for i in range(effective_num_clusters):\n",
        "        cluster_sentence_indices = np.where(clusters == i)[0]\n",
        "\n",
        "        if len(cluster_sentence_indices) == 0:\n",
        "            continue\n",
        "\n",
        "        distances = cdist(embeddings[cluster_sentence_indices], centroids[i].reshape(1, -1), 'cosine').flatten()\n",
        "        sorted_cluster_indices = cluster_sentence_indices[np.argsort(distances)]\n",
        "\n",
        "        count_selected_from_cluster = 0\n",
        "        for original_idx in sorted_cluster_indices:\n",
        "            if original_idx not in selected_indices:\n",
        "                summary_sentences_with_idx.append((sentences[original_idx], original_idx))\n",
        "                selected_indices.add(original_idx)\n",
        "                count_selected_from_cluster += 1\n",
        "                if count_selected_from_cluster >= num_sentences_per_cluster:\n",
        "                    break\n",
        "\n",
        "    summary_sentences_with_idx.sort(key=lambda x: x[1])\n",
        "    final_summary_sents = [s[0] for s in summary_sentences_with_idx]\n",
        "    final_summary_indices = [s[1] for s in summary_sentences_with_idx]\n",
        "\n",
        "    print(\"--- K-Means Based Summarization Complete ---\")\n",
        "    return final_summary_sents, final_summary_indices\n",
        "\n",
        "# --- Combined Extractive Summarization Function (Optimized to accept pre-calculated embeddings) ---\n",
        "def combined_extractive_summary_optimized(sentences, embeddings, total_summary_sentences=7,\n",
        "                                centroid_sentences_to_propose=5,\n",
        "                                kmeans_clusters_to_propose=4,\n",
        "                                kmeans_sentences_per_cluster_to_propose=1,\n",
        "                                lambda_param_mmr=0.7):\n",
        "    \"\"\"\n",
        "    Generates a single extractive summary by combining candidates from\n",
        "    both centroid-based and K-Means approaches, then using MMR for final selection.\n",
        "    Accepts pre-calculated sentences and embeddings.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Starting Combined Extractive Summarization ---\")\n",
        "    if not sentences or embeddings.shape[0] == 0:\n",
        "        print(\"  No sentences or embeddings provided. Cannot summarize combined.\")\n",
        "        return []\n",
        "\n",
        "    centroid_candidates_sents, centroid_candidates_indices = centroid_summarization_optimized(\n",
        "        sentences, embeddings, num_sentences=centroid_sentences_to_propose\n",
        "    )\n",
        "    print(f\"  Centroid proposed {len(centroid_candidates_sents)} candidates.\")\n",
        "\n",
        "    kmeans_candidates_sents, kmeans_candidates_indices = kmeans_summarization_optimized(\n",
        "        sentences, embeddings, num_clusters=kmeans_clusters_to_propose, num_sentences_per_cluster=kmeans_sentences_per_cluster_to_propose\n",
        "    )\n",
        "    print(f\"  K-Means proposed {len(kmeans_candidates_sents)} candidates.\")\n",
        "\n",
        "    # Combine candidates and their original indices, removing duplicates\n",
        "    combined_candidates_map = {}\n",
        "    for idx, sent in zip(centroid_candidates_indices, centroid_candidates_sents):\n",
        "        combined_candidates_map[idx] = sent\n",
        "    for idx, sent in zip(kmeans_candidates_indices, kmeans_candidates_sents):\n",
        "        combined_candidates_map[idx] = sent\n",
        "\n",
        "    all_candidate_indices_sorted = sorted(combined_candidates_map.keys())\n",
        "    all_candidate_sentences = [combined_candidates_map[idx] for idx in all_candidate_indices_sorted]\n",
        "    all_candidate_embeddings = np.array([embeddings[idx] for idx in all_candidate_indices_sorted])\n",
        "\n",
        "    if not all_candidate_sentences or all_candidate_embeddings.shape[0] == 0:\n",
        "        print(\"  No unique candidates found after combining. Cannot generate combined summary.\")\n",
        "        return []\n",
        "\n",
        "    num_sentences_to_extract = min(total_summary_sentences, len(all_candidate_sentences))\n",
        "    print(f\"  Total unique candidates: {len(all_candidate_sentences)}. Extracting {num_sentences_to_extract} for combined summary.\")\n",
        "\n",
        "    document_centroid = np.mean(embeddings, axis=0)\n",
        "    candidate_similarities = cosine_similarity(all_candidate_embeddings, document_centroid.reshape(1, -1)).flatten()\n",
        "\n",
        "    final_summary_sentences = []\n",
        "    selected_candidate_indices = set()\n",
        "\n",
        "    ranked_initial_candidate_indices = np.argsort(candidate_similarities)[::-1]\n",
        "\n",
        "    for _ in range(num_sentences_to_extract):\n",
        "        best_idx_in_candidates = -1\n",
        "        max_mmr_score = -1\n",
        "\n",
        "        for i_candidate in ranked_initial_candidate_indices:\n",
        "            if i_candidate not in selected_candidate_indices:\n",
        "                relevance = candidate_similarities[i_candidate]\n",
        "\n",
        "                if not selected_candidate_indices:\n",
        "                    mmr_score = relevance\n",
        "                else:\n",
        "                    diversity_scores = cosine_similarity(all_candidate_embeddings[i_candidate].reshape(1, -1),\n",
        "                                                         all_candidate_embeddings[list(selected_candidate_indices)])\n",
        "                    redundancy = np.max(diversity_scores)\n",
        "\n",
        "                    mmr_score = lambda_param_mmr * relevance - (1 - lambda_param_mmr) * redundancy\n",
        "\n",
        "                if mmr_score > max_mmr_score:\n",
        "                    max_mmr_score = mmr_score\n",
        "                    best_idx_in_candidates = i_candidate\n",
        "\n",
        "        if best_idx_in_candidates != -1:\n",
        "            final_summary_sentences.append((all_candidate_sentences[best_idx_in_candidates],\n",
        "                                             all_candidate_indices_sorted[best_idx_in_candidates]))\n",
        "            selected_candidate_indices.add(best_idx_in_candidates)\n",
        "            ranked_initial_candidate_indices = ranked_initial_candidate_indices[ranked_initial_candidate_indices != best_idx_in_candidates]\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    final_summary_sentences.sort(key=lambda x: x[1])\n",
        "    final_summary = [s[0] for s in final_summary_sentences]\n",
        "\n",
        "    print(\"--- Combined Extractive Summarization Complete ---\")\n",
        "    return final_summary\n",
        "\n",
        "# --- Example Usage and Testing ---\n",
        "long_document = original_document\n",
        "\"\"\"Artificial intelligence (AI) has rapidly transformed various sectors, revolutionizing industries from healthcare to finance. In healthcare, AI assists in diagnosing diseases earlier and more accurately, personalizing treatment plans, and accelerating drug discovery. Machine learning algorithms, a subset of AI, analyze vast amounts of patient data to identify patterns that human doctors might miss, leading to more effective interventions. For instance, AI-powered tools can detect subtle signs of retinopathy from eye scans, potentially preventing blindness. The integration of AI into electronic health records is also streamlining administrative tasks, freeing up medical professionals to focus more on patient care. This technological leap promises to enhance diagnostic capabilities and optimize treatment protocols significantly.\n",
        "\n",
        "The financial industry also heavily leverages AI for fraud detection, algorithmic trading, and personalized financial advice. AI systems can monitor transactions in real-time, identifying unusual patterns indicative of fraudulent activity with high precision. Furthermore, robo-advisors powered by AI provide automated, data-driven investment advice tailored to individual risk tolerance and financial goals, making financial planning more accessible to a wider demographic. The use of AI in predicting market trends and managing portfolios is becoming increasingly sophisticated, offering new avenues for investors.\n",
        "\n",
        "Beyond these, AI is deeply embedded in everyday life through virtual assistants like Siri and Alexa, recommendation engines on streaming platforms, and autonomous vehicles. AI's role in natural language processing (NLP) has led to advancements in language translation and sentiment analysis, impacting global communication and customer service. The ethical implications of AI, however, are a growing concern among researchers and policymakers. Issues such as algorithmic bias, job displacement due to automation, and privacy breaches require careful consideration and robust regulation. Ensuring transparency, fairness, and accountability in AI development is paramount to harnessing its benefits responsibly.\n",
        "\n",
        "Research in AI continues to advance at an astonishing pace, focusing on areas like explainable AI (XAI) to make AI decisions more understandable, and robust AI to improve performance in real-world, unpredictable environments. Novel architectures like generative adversarial networks (GANs) and reinforcement learning are pushing the boundaries of what AI can achieve, from creating realistic imagery to mastering complex games. The future of AI promises even more integration into society, with potential breakthroughs in areas like general artificial intelligence (AGI) and enhanced human-computer interaction, leading to smarter cities and more efficient resource management. However, achieving these advancements responsibly will necessitate ongoing collaboration between technologists, policymakers, and ethicists to address the complex challenges that arise. The rapid pace of development means that continuous public discourse and legislative adaptation are critical to navigate the challenges and maximize the societal benefits of AI, ensuring it serves humanity's best interests.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Original Document Length (sentences):\", sum(1 for _ in nlp(long_document).sents))\n",
        "\n",
        "# --- OPTIMIZATION: Calculate document embeddings only ONCE ---\n",
        "print(\"\\nCalculating document embeddings (this might take a while for long texts)...\")\n",
        "sentences_list, embeddings_array = get_sentence_embeddings(long_document, batch_size=8)\n",
        "print(\"Embeddings calculation complete.\")\n",
        "\n",
        "\n",
        "# --- Individual Centroid-Based Summarization ---\n",
        "'''print(\"\\n\" + \"=\"*80)\n",
        "print(\"Individual Centroid-Based Summary:\")\n",
        "centroid_summary, _ = centroid_summarization_optimized(sentences_list, embeddings_array, num_sentences=5)\n",
        "for i, sent in enumerate(centroid_summary):\n",
        "    print(f\"{i+1}. {sent}\")\n",
        "\n",
        "\n",
        "# --- Individual K-Means Based Summarization ---\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Individual K-Means Based Summary:\")\n",
        "kmeans_summary, _ = kmeans_summarization_optimized(sentences_list, embeddings_array, num_clusters=4, num_sentences_per_cluster=1)\n",
        "for i, sent in enumerate(kmeans_summary):\n",
        "    print(f\"{i+1}. {sent}\")'''\n",
        "\n",
        "\n",
        "# --- Combined Extractive Summarization ---\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Combined Extractive Summary:\")\n",
        "combined_summary = combined_extractive_summary_optimized(\n",
        "    sentences_list,\n",
        "    embeddings_array,\n",
        "    total_summary_sentences=6,\n",
        "    centroid_sentences_to_propose=7,\n",
        "    kmeans_clusters_to_propose=5,\n",
        "    kmeans_sentences_per_cluster_to_propose=1\n",
        ")\n",
        "for i, sent in enumerate(combined_summary):\n",
        "    print(f\"{i+1}. {sent}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"\\nAll summarization processes complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9WZGQZ-5Lx5",
        "outputId": "49766c44-ae2c-495b-8c24-fc464eef92a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Longformer model and tokenizer...\n",
            "Using device: cpu\n",
            "Longformer model loaded.\n",
            "Original Document Length (sentences): 430\n",
            "\n",
            "Calculating document embeddings (this might take a while for long texts)...\n",
            "Total sentences to process: 430\n",
            "Embeddings calculation complete.\n",
            "\n",
            "================================================================================\n",
            "Combined Extractive Summary:\n",
            "\n",
            "--- Starting Combined Extractive Summarization ---\n",
            "\n",
            "--- Starting Centroid-Based Summarization ---\n",
            "--- Centroid-Based Summarization Complete ---\n",
            "  Centroid proposed 7 candidates.\n",
            "\n",
            "--- Starting K-Means Based Summarization ---\n",
            "--- K-Means Based Summarization Complete ---\n",
            "  K-Means proposed 5 candidates.\n",
            "  Total unique candidates: 12. Extracting 6 for combined summary.\n",
            "--- Combined Extractive Summarization Complete ---\n",
            "1. In March 2019, FDA and USDA issued a formal interagency agreement that describes the intended roles and responsibilities of each agency in overseeing cell-cultured meat.\n",
            "2. Labeling working group.\n",
            "3. However, the officials did not have time frames or a method to evaluate progress towards completing these actions.\n",
            "4. Compounding this challenge is that specific information about key aspects of cell-cultured meat, such as the technology and production methods to be used as well as the composition of the products, is not yet known.\n",
            "5. We continue to believe that FDA and USDA should more fully incorporate the seven leading practices for effective collaboration into their interagency agreement for the joint oversight of cell-cultured meat.\n",
            "6. Do participating agencies have the means to recognize and reward accomplishments related to collaboration?\n",
            "\n",
            "================================================================================\n",
            "\n",
            "All summarization processes complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LongformerModel, LongformerTokenizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cdist\n",
        "import numpy as np\n",
        "import spacy\n",
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "# --- Constants ---\n",
        "JSON_FILE_PATH = \"govreport_tfidf_vscode2/test.json\"\n",
        "OUTPUT_FILE_PATH = \"summaries_output.json\"\n",
        "\n",
        "# --- Load Spacy model ---\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    print(\"Downloading 'en_core_web_sm' model. This will happen only once.\")\n",
        "    spacy.cli.download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# --- Load Longformer Model and Tokenizer ---\n",
        "print(\"Loading Longformer model and tokenizer...\")\n",
        "model_name = 'allenai/longformer-base-4096'\n",
        "tokenizer = LongformerTokenizer.from_pretrained(model_name)\n",
        "model = LongformerModel.from_pretrained(model_name)\n",
        "\n",
        "# --- Set Device (GPU if available, else CPU) ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.eval()\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "print(\"Longformer model loaded.\")\n",
        "\n",
        "# --- Helper Function to calculate summary length ---\n",
        "def calculate_summary_length(num_original_sentences, percentage=0.10):\n",
        "    \"\"\"\n",
        "    Calculates the number of sentences for the summary based on a percentage.\n",
        "    Ensures a minimum of 1 sentence and rounds to the nearest integer.\n",
        "    \"\"\"\n",
        "    if num_original_sentences <= 0:\n",
        "        return 1\n",
        "\n",
        "    summary_len = math.ceil(num_original_sentences * percentage)\n",
        "\n",
        "    # Ensure at least 1 sentence is always extracted.\n",
        "    return max(1, int(summary_len))\n",
        "\n",
        "# --- Helper Function for Sentence Embeddings ---\n",
        "def get_sentence_embeddings(text, batch_size=4):\n",
        "    \"\"\"\n",
        "    Splits text into sentences, tokenizes them, and gets Longformer embeddings.\n",
        "    Handles long documents by processing sentences in batches.\n",
        "    Returns:\n",
        "        sentences (list): List of original sentence strings.\n",
        "        sentence_embeddings (np.array): NumPy array of sentence embeddings.\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
        "\n",
        "    if not sentences:\n",
        "        return [], np.array([])\n",
        "\n",
        "    all_sentence_embeddings = []\n",
        "\n",
        "    # No progress bar here to avoid clutter. The outer loop's progress bar is sufficient.\n",
        "    for i in range(0, len(sentences), batch_size):\n",
        "        batch_sentences = sentences[i:i + batch_size]\n",
        "        try:\n",
        "            inputs = tokenizer(\n",
        "                batch_sentences,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=tokenizer.model_max_length\n",
        "            ).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            all_sentence_embeddings.extend(cls_embeddings)\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"Error processing batch of sentences (index {i}-{i+len(batch_sentences)-1}): {e}\")\n",
        "            all_sentence_embeddings.extend([np.zeros(model.config.hidden_size)] * len(batch_sentences))\n",
        "            continue\n",
        "\n",
        "    return sentences, np.array(all_sentence_embeddings)\n",
        "\n",
        "# --- Summarization functions (rest of the code is unchanged) ---\n",
        "def centroid_summarization_optimized(sentences, embeddings, num_sentences=3):\n",
        "    if not sentences or embeddings.shape[0] == 0:\n",
        "        tqdm.write(\"  No sentences or embeddings provided. Cannot summarize.\")\n",
        "        return [], []\n",
        "    if num_sentences <= 0:\n",
        "        tqdm.write(\"  Number of sentences for summary must be positive.\")\n",
        "        return [], []\n",
        "    num_sentences_to_extract = min(num_sentences, len(sentences))\n",
        "    document_centroid = np.mean(embeddings, axis=0)\n",
        "    similarities = cosine_similarity(embeddings, document_centroid.reshape(1, -1)).flatten()\n",
        "    summary_sentences_mmr = []\n",
        "    selected_indices = set()\n",
        "    ranked_initial_indices = np.argsort(similarities)[::-1]\n",
        "    for _ in range(num_sentences_to_extract):\n",
        "        best_sentence_idx = -1\n",
        "        max_mmr_score = -1\n",
        "        for i in ranked_initial_indices:\n",
        "            if i not in selected_indices:\n",
        "                relevance = similarities[i]\n",
        "                if not selected_indices:\n",
        "                    mmr_score = relevance\n",
        "                else:\n",
        "                    diversity_scores = cosine_similarity(embeddings[i].reshape(1, -1),\n",
        "                                                         embeddings[list(selected_indices)])\n",
        "                    redundancy = np.max(diversity_scores)\n",
        "                    lambda_param = 0.5\n",
        "                    mmr_score = lambda_param * relevance - (1 - lambda_param) * redundancy\n",
        "                if mmr_score > max_mmr_score:\n",
        "                    max_mmr_score = mmr_score\n",
        "                    best_sentence_idx = i\n",
        "        if best_sentence_idx != -1:\n",
        "            summary_sentences_mmr.append((sentences[best_sentence_idx], best_sentence_idx))\n",
        "            selected_indices.add(best_sentence_idx)\n",
        "            ranked_initial_indices = ranked_initial_indices[ranked_initial_indices != best_sentence_idx]\n",
        "        else:\n",
        "            break\n",
        "    summary_sentences_mmr.sort(key=lambda x: x[1])\n",
        "    final_summary_sents = [s[0] for s in summary_sentences_mmr]\n",
        "    final_summary_indices = [s[1] for s in summary_sentences_mmr]\n",
        "    return final_summary_sents, final_summary_indices\n",
        "\n",
        "def kmeans_summarization_optimized(sentences, embeddings, num_clusters=25, num_sentences_per_cluster=1):\n",
        "    if not sentences or embeddings.shape[0] == 0:\n",
        "        tqdm.write(\"  No sentences or embeddings provided. Cannot summarize.\")\n",
        "        return [], []\n",
        "    if num_clusters <= 0 or num_sentences_per_cluster <= 0:\n",
        "        tqdm.write(\"  Number of clusters and sentences per cluster must be positive.\")\n",
        "        return [], []\n",
        "    effective_num_clusters = min(num_clusters, len(sentences))\n",
        "    if effective_num_clusters == 0:\n",
        "        tqdm.write(\"  Not enough sentences to form clusters.\")\n",
        "        return [], []\n",
        "    kmeans = KMeans(n_clusters=effective_num_clusters, random_state=42, n_init='auto')\n",
        "    kmeans.fit(embeddings)\n",
        "    clusters = kmeans.labels_\n",
        "    centroids = kmeans.cluster_centers_\n",
        "    summary_sentences_with_idx = []\n",
        "    selected_indices = set()\n",
        "    for i in range(effective_num_clusters):\n",
        "        cluster_sentence_indices = np.where(clusters == i)[0]\n",
        "        if len(cluster_sentence_indices) == 0:\n",
        "            continue\n",
        "        distances = cdist(embeddings[cluster_sentence_indices], centroids[i].reshape(1, -1), 'cosine').flatten()\n",
        "        sorted_cluster_indices = cluster_sentence_indices[np.argsort(distances)]\n",
        "        count_selected_from_cluster = 0\n",
        "        for original_idx in sorted_cluster_indices:\n",
        "            if original_idx not in selected_indices:\n",
        "                summary_sentences_with_idx.append((sentences[original_idx], original_idx))\n",
        "                selected_indices.add(original_idx)\n",
        "                count_selected_from_cluster += 1\n",
        "                if count_selected_from_cluster >= num_sentences_per_cluster:\n",
        "                    break\n",
        "    summary_sentences_with_idx.sort(key=lambda x: x[1])\n",
        "    final_summary_sents = [s[0] for s in summary_sentences_with_idx]\n",
        "    final_summary_indices = [s[1] for s in summary_sentences_with_idx]\n",
        "    return final_summary_sents, final_summary_indices\n",
        "\n",
        "def combined_extractive_summary_optimized(sentences, embeddings, total_summary_sentences=7,\n",
        "                                          centroid_sentences_to_propose=5,\n",
        "                                          kmeans_clusters_to_propose=4,\n",
        "                                          kmeans_sentences_per_cluster_to_propose=1,\n",
        "                                          lambda_param_mmr=0.7):\n",
        "    if not sentences or embeddings.shape[0] == 0:\n",
        "        tqdm.write(\"  No sentences or embeddings provided. Cannot generate combined summary.\")\n",
        "        return []\n",
        "    centroid_candidates_sents, centroid_candidates_indices = centroid_summarization_optimized(\n",
        "        sentences, embeddings, num_sentences=centroid_sentences_to_propose\n",
        "    )\n",
        "    kmeans_candidates_sents, kmeans_candidates_indices = kmeans_summarization_optimized(\n",
        "        sentences, embeddings, num_clusters=kmeans_clusters_to_propose, num_sentences_per_cluster=kmeans_sentences_per_cluster_to_propose\n",
        "    )\n",
        "    combined_candidates_map = {}\n",
        "    for idx, sent in zip(centroid_candidates_indices, centroid_candidates_sents):\n",
        "        combined_candidates_map[idx] = sent\n",
        "    for idx, sent in zip(kmeans_candidates_indices, kmeans_candidates_sents):\n",
        "        combined_candidates_map[idx] = sent\n",
        "    all_candidate_indices_sorted = sorted(combined_candidates_map.keys())\n",
        "    all_candidate_sentences = [combined_candidates_map[idx] for idx in all_candidate_indices_sorted]\n",
        "    all_candidate_embeddings = np.array([embeddings[idx] for idx in all_candidate_indices_sorted])\n",
        "    if not all_candidate_sentences or all_candidate_embeddings.shape[0] == 0:\n",
        "        tqdm.write(\"  No unique candidates found after combining. Cannot generate combined summary.\")\n",
        "        return []\n",
        "    num_sentences_to_extract = min(total_summary_sentences, len(all_candidate_sentences))\n",
        "    document_centroid = np.mean(embeddings, axis=0)\n",
        "    candidate_similarities = cosine_similarity(all_candidate_embeddings, document_centroid.reshape(1, -1)).flatten()\n",
        "    final_summary_sentences = []\n",
        "    selected_candidate_indices = set()\n",
        "    ranked_initial_candidate_indices = np.argsort(candidate_similarities)[::-1]\n",
        "    for _ in range(num_sentences_to_extract):\n",
        "        best_idx_in_candidates = -1\n",
        "        max_mmr_score = -1\n",
        "        for i_candidate in ranked_initial_candidate_indices:\n",
        "            if i_candidate not in selected_candidate_indices:\n",
        "                relevance = candidate_similarities[i_candidate]\n",
        "                if not selected_candidate_indices:\n",
        "                    mmr_score = relevance\n",
        "                else:\n",
        "                    diversity_scores = cosine_similarity(all_candidate_embeddings[i_candidate].reshape(1, -1),\n",
        "                                                         all_candidate_embeddings[list(selected_candidate_indices)])\n",
        "                    redundancy = np.max(diversity_scores)\n",
        "                    mmr_score = lambda_param_mmr * relevance - (1 - lambda_param_mmr) * redundancy\n",
        "                if mmr_score > max_mmr_score:\n",
        "                    max_mmr_score = mmr_score\n",
        "                    best_idx_in_candidates = i_candidate\n",
        "        if best_idx_in_candidates != -1:\n",
        "            final_summary_sentences.append((all_candidate_sentences[best_idx_in_candidates],\n",
        "                                            all_candidate_indices_sorted[best_idx_in_candidates]))\n",
        "            selected_candidate_indices.add(best_idx_in_candidates)\n",
        "            ranked_initial_candidate_indices = ranked_initial_candidate_indices[ranked_initial_candidate_indices != best_idx_in_candidates]\n",
        "        else:\n",
        "            break\n",
        "    final_summary_sentences.sort(key=lambda x: x[1])\n",
        "    final_summary = [s[0] for s in final_summary_sentences]\n",
        "    return final_summary\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        print(f\"Error: The file '{JSON_FILE_PATH}' was not found.\")\n",
        "        print(\"Please ensure the file path is correct and the file exists.\")\n",
        "    else:\n",
        "        all_summaries = []\n",
        "\n",
        "        try:\n",
        "            print(f\"\\nProcessing JSONL file '{JSON_FILE_PATH}'...\")\n",
        "\n",
        "            with open(JSON_FILE_PATH, 'r') as f:\n",
        "                # Read all lines first to get the total count for the progress bar\n",
        "                lines = f.readlines()\n",
        "                total_lines = len(lines)\n",
        "\n",
        "                # --- Iterate through each data point with a progress bar ---\n",
        "                for i, line in enumerate(tqdm(lines, total=total_lines, desc=\"Processing documents\", unit=\"doc\")):\n",
        "                    line = line.strip()\n",
        "                    if not line:\n",
        "                        continue\n",
        "\n",
        "                    data_point = json.loads(line)\n",
        "\n",
        "                    document_id = data_point.get(\"id\", f\"doc_{i+1}\")\n",
        "                    original_document = data_point.get(\"original_text\", \"\")\n",
        "\n",
        "                    if not original_document:\n",
        "                        tqdm.write(f\"  Warning: 'original_text' not found or is empty for data point {i+1}. Skipping.\")\n",
        "                        continue\n",
        "\n",
        "                    # --- Dynamic Summary Length Calculation ---\n",
        "                    num_original_sentences = sum(1 for _ in nlp(original_document).sents)\n",
        "                    total_summary_sentences = calculate_summary_length(num_original_sentences, percentage=0.10)\n",
        "\n",
        "                    # --- OPTIMIZATION: Calculate document embeddings only ONCE ---\n",
        "                    sentences_list, embeddings_array = get_sentence_embeddings(original_document, batch_size=8)\n",
        "\n",
        "                    if not sentences_list:\n",
        "                        tqdm.write(f\"  Warning: No sentences found for document {document_id}. Skipping summary generation.\")\n",
        "                        summary_text = \"\"\n",
        "                        combined_summary = []\n",
        "                    else:\n",
        "                        # --- Combined Extractive Summarization ---\n",
        "                        combined_summary = combined_extractive_summary_optimized(\n",
        "                            sentences_list,\n",
        "                            embeddings_array,\n",
        "                            total_summary_sentences=total_summary_sentences,\n",
        "                            centroid_sentences_to_propose=total_summary_sentences + 2, # Propose more candidates\n",
        "                            kmeans_clusters_to_propose=total_summary_sentences + 2,\n",
        "                            kmeans_sentences_per_cluster_to_propose=1\n",
        "                        )\n",
        "\n",
        "                        summary_text = \" \".join(combined_summary) if combined_summary else \"\"\n",
        "\n",
        "                    summary_entry = {\n",
        "                        \"document_id\": document_id,\n",
        "                        \"summary_text\": summary_text,\n",
        "                        \"summary_sentences\": combined_summary\n",
        "                    }\n",
        "                    all_summaries.append(summary_entry)\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"\\nAll summarization processes complete.\")\n",
        "            print(f\"Writing all {len(all_summaries)} summaries to '{OUTPUT_FILE_PATH}'...\")\n",
        "\n",
        "            try:\n",
        "                with open(OUTPUT_FILE_PATH, 'w') as out_f:\n",
        "                    json.dump(all_summaries, out_f, indent=4)\n",
        "                print(f\"\\nSuccessfully wrote summaries to '{OUTPUT_FILE_PATH}'.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error writing to output JSON file: {e}\")\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error: Failed to decode JSON from '{JSON_FILE_PATH}'. Check for invalid JSON format. Error: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "KwyhnkpGBUg_",
        "outputId": "5c028fb1-34b5-4277-d705-e9d83257ec19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Longformer model and tokenizer...\n",
            "Using device: cuda\n",
            "Longformer model loaded.\n",
            "\n",
            "Processing JSONL file 'govreport_tfidf_vscode2/test.json'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing documents:   0%|          | 4/973 [02:18<9:18:45, 34.60s/doc]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2893408314.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0;31m# --- Combined Extractive Summarization ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                         combined_summary = combined_extractive_summary_optimized(\n\u001b[0m\u001b[1;32m    274\u001b[0m                             \u001b[0msentences_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                             \u001b[0membeddings_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2893408314.py\u001b[0m in \u001b[0;36mcombined_extractive_summary_optimized\u001b[0;34m(sentences, embeddings, total_summary_sentences, centroid_sentences_to_propose, kmeans_clusters_to_propose, kmeans_sentences_per_cluster_to_propose, lambda_param_mmr)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  No sentences or embeddings provided. Cannot generate combined summary.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     centroid_candidates_sents, centroid_candidates_indices = centroid_summarization_optimized(\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcentroid_sentences_to_propose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     )\n",
            "\u001b[0;32m/tmp/ipython-input-2893408314.py\u001b[0m in \u001b[0;36mcentroid_summarization_optimized\u001b[0;34m(sentences, embeddings, num_sentences)\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0mmmr_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelevance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                     diversity_scores = cosine_similarity(embeddings[i].reshape(1, -1),\n\u001b[0m\u001b[1;32m    117\u001b[0m                                                          embeddings[list(selected_indices)])\n\u001b[1;32m    118\u001b[0m                     \u001b[0mredundancy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiversity_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 with config_context(\n\u001b[0m\u001b[1;32m    212\u001b[0m                     skip_parameter_validation=(\n\u001b[1;32m    213\u001b[0m                         \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sumary_list = ['Each cell-cultured meat firm is developing detailed information on its own eventual commercial production methods for making cell-cultured meat.', 'This limitation can affect agencies’ ability to make regulatory and other decisions.', 'Specifically, FDA and USDA officials said they have limited information on cell-cultured meat production methods and products and need more in order to regulate this new food.', 'This lack of information results in unanswered questions about cell- cultured meat as it relates to the eventual technology and commercial production methods to be used and the composition of the final products.', 'According to one firm, if antibiotics are used, the use would be limited both in quantity and duration.', 'According to USDA officials, the composition of edible scaffolding may also create labeling and jurisdictional concerns.', 'Additionally, researchers have commented that a chemical separation technique needed to separate some inedible scaffolds may also need to be evaluated for potential safety concerns.', 'Stakeholders have raised concerns that not having a clear definition of the point of harvest could lead to challenges such as overlapping inspection requirements or a gap in inspection.', 'Similarly, a senior FDA official stated that the capacity of existing production equipment is a challenge for firms seeking to produce cell-cultured meat products at a commercial scale.', 'According to agency officials, cell-cultured meat may present different safety challenges compared to conventional meat.', 'Agency officials told us that without knowing the composition of a cell-cultured meat product, it is impossible to predict how food safety and labeling requirements will apply.', 'Stakeholders told us that until commercial production methods and final products are established, these claims about impacts on the environment, animal welfare, and human health will remain unsubstantiated.', 'Stakeholders give varying estimates for when cell-cultured meat may be commercially available.', 'However, according to agency officials, USDA has committed to a public process, likely rulemaking, for the development of labeling requirements for cell- cultured meat and poultry.', 'It remains unclear whether consumers will embrace and purchase cell-cultured meat products.', 'Stakeholders we interviewed and studies we reviewed cited consumer acceptance as a challenge for commercializing cell-cultured meat.', 'In addition, FDA and USDA have not documented which agency will oversee cell-cultured seafood not covered by the interagency agreement.', 'The written comments the agencies received focused on such topics as environmental considerations, labeling, potential health and safety implications, and potential regulatory and inspection processes.', 'For example, stakeholders expressed different views as to whether cell-cultured meat should be regulated as a food additive, considered a GRAS substance, or whether new regulations were needed.', 'In March 2019, FDA and USDA issued a formal interagency agreement that describes the intended roles and responsibilities of each agency in overseeing cell-cultured meat.', 'Labeling working group.', 'Led by USDA, this group will focus on developing joint principles for product labeling and claims.', 'See appendix II for a full list of the associated issues to consider for each leading practice.', 'However, FDA and USDA have not established methods, such as milestones and metrics, to evaluate the progress of any of the working groups.', 'For example, FDA officials said in December 2019 that their next steps are to conduct a general and qualitative risk assessment of animal cell culture food technology to systematically identify particular areas of interest from a food safety perspective and prepare detailed procedural guidelines for cell-cultured meat firms to follow.', 'FDA and USDA officials said they were considering means to monitor, evaluate, or report on the results of the pre-market assessment working group.', 'These factors contribute to an already complicated system in which the two agencies must coordinate on food safety oversight.', 'According to FDA officials, they have verbally communicated this decision in various meetings with stakeholders.', 'Representatives from one cell-cultured seafood firm said that not being able to rule out oversight by USDA prevented them from making key decisions regarding what direction to pursue in developing their commercial production method.', 'We continue to believe that FDA and USDA should more fully incorporate the seven leading practices for effective collaboration into their interagency agreement for the joint oversight of cell-cultured meat.']\n",
        "\n",
        "summary=\" \".join(sumary_list)\n",
        "summary"
      ],
      "metadata": {
        "id": "AII8PFgoMlvU",
        "outputId": "108d586b-6449-46ba-bb6d-ac7ff6872eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Each cell-cultured meat firm is developing detailed information on its own eventual commercial production methods for making cell-cultured meat. This limitation can affect agencies’ ability to make regulatory and other decisions. Specifically, FDA and USDA officials said they have limited information on cell-cultured meat production methods and products and need more in order to regulate this new food. This lack of information results in unanswered questions about cell- cultured meat as it relates to the eventual technology and commercial production methods to be used and the composition of the final products. According to one firm, if antibiotics are used, the use would be limited both in quantity and duration. According to USDA officials, the composition of edible scaffolding may also create labeling and jurisdictional concerns. Additionally, researchers have commented that a chemical separation technique needed to separate some inedible scaffolds may also need to be evaluated for potential safety concerns. Stakeholders have raised concerns that not having a clear definition of the point of harvest could lead to challenges such as overlapping inspection requirements or a gap in inspection. Similarly, a senior FDA official stated that the capacity of existing production equipment is a challenge for firms seeking to produce cell-cultured meat products at a commercial scale. According to agency officials, cell-cultured meat may present different safety challenges compared to conventional meat. Agency officials told us that without knowing the composition of a cell-cultured meat product, it is impossible to predict how food safety and labeling requirements will apply. Stakeholders told us that until commercial production methods and final products are established, these claims about impacts on the environment, animal welfare, and human health will remain unsubstantiated. Stakeholders give varying estimates for when cell-cultured meat may be commercially available. However, according to agency officials, USDA has committed to a public process, likely rulemaking, for the development of labeling requirements for cell- cultured meat and poultry. It remains unclear whether consumers will embrace and purchase cell-cultured meat products. Stakeholders we interviewed and studies we reviewed cited consumer acceptance as a challenge for commercializing cell-cultured meat. In addition, FDA and USDA have not documented which agency will oversee cell-cultured seafood not covered by the interagency agreement. The written comments the agencies received focused on such topics as environmental considerations, labeling, potential health and safety implications, and potential regulatory and inspection processes. For example, stakeholders expressed different views as to whether cell-cultured meat should be regulated as a food additive, considered a GRAS substance, or whether new regulations were needed. In March 2019, FDA and USDA issued a formal interagency agreement that describes the intended roles and responsibilities of each agency in overseeing cell-cultured meat. Labeling working group. Led by USDA, this group will focus on developing joint principles for product labeling and claims. See appendix II for a full list of the associated issues to consider for each leading practice. However, FDA and USDA have not established methods, such as milestones and metrics, to evaluate the progress of any of the working groups. For example, FDA officials said in December 2019 that their next steps are to conduct a general and qualitative risk assessment of animal cell culture food technology to systematically identify particular areas of interest from a food safety perspective and prepare detailed procedural guidelines for cell-cultured meat firms to follow. FDA and USDA officials said they were considering means to monitor, evaluate, or report on the results of the pre-market assessment working group. These factors contribute to an already complicated system in which the two agencies must coordinate on food safety oversight. According to FDA officials, they have verbally communicated this decision in various meetings with stakeholders. Representatives from one cell-cultured seafood firm said that not being able to rule out oversight by USDA prevented them from making key decisions regarding what direction to pursue in developing their commercial production method. We continue to believe that FDA and USDA should more fully incorporate the seven leading practices for effective collaboration into their interagency agreement for the joint oversight of cell-cultured meat.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BART"
      ],
      "metadata": {
        "id": "_s3CRcmh5ieu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries (only runs if not already installed)\n",
        "#%pip install transformers torch\n",
        "\n",
        "import torch\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "# --- Load BART Model and Tokenizer ---\n",
        "print(\"Loading BART model and tokenizer for abstractive summarization...\")\n",
        "bart_model_name = 'facebook/bart-large-cnn' # This is a good choice for summarization\n",
        "bart_tokenizer = BartTokenizer.from_pretrained(bart_model_name)\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(bart_model_name)\n",
        "\n",
        "# --- Set Device (GPU if available, else CPU) ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "bart_model.eval() # Set to evaluation mode\n",
        "bart_model.to(device)\n",
        "print(f\"BART using device: {device}\")\n",
        "print(\"BART model loaded.\")\n",
        "\n",
        "# --- Abstractive Summarization Function (using BART) ---\n",
        "def bart_abstractive_summary(text_to_summarize, max_length=150, min_length=50, num_beams=4, early_stopping=True):\n",
        "    \"\"\"\n",
        "    Generates an abstractive summary using the pre-loaded BART model.\n",
        "    Assumes bart_tokenizer and bart_model are loaded globally.\n",
        "\n",
        "    Args:\n",
        "        text_to_summarize (str or list of str): The input text (or list of sentences) to summarize.\n",
        "                                                  If a list, it will be joined into a single string.\n",
        "        max_length (int): Maximum length of the generated summary.\n",
        "        min_length (int): Minimum length of the generated summary.\n",
        "        num_beams (int): Number of beams for beam search. Higher values lead to better quality but slower generation.\n",
        "        early_stopping (bool): Whether to stop beam search when all beams have finished their generation.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated abstractive summary.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Starting BART Abstractive Summarization ---\")\n",
        "\n",
        "    if isinstance(text_to_summarize, list):\n",
        "        text_to_summarize = \" \".join(text_to_summarize)\n",
        "\n",
        "    if not text_to_summarize.strip():\n",
        "        print(\"  Input text for abstractive summary is empty. Cannot summarize.\")\n",
        "        return \"\"\n",
        "\n",
        "    inputs = bart_tokenizer( # bart_tokenizer is now accessible globally\n",
        "        [text_to_summarize],\n",
        "        max_length=1024, # BART's typical max input length\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    ).to(device) # device is also globally accessible\n",
        "\n",
        "    summary_ids = bart_model.generate( # bart_model is now accessible globally\n",
        "        inputs[\"input_ids\"],\n",
        "        num_beams=num_beams,\n",
        "        max_length=max_length,\n",
        "        min_length=min_length,\n",
        "        early_stopping=early_stopping\n",
        "    )\n",
        "\n",
        "    summary_text = bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    print(\"--- BART Abstractive Summarization Complete ---\")\n",
        "    return summary_text\n",
        "\n",
        "# --- Example Usage for BART only ---\n",
        "#input_text_for_bart = \" \".join(combined_summary)\n",
        "input_text_for_bart = \"\"\"FDA and USDA have responsibility for overseeing the safety of the food supply. The Federal Food, Drug, and Cosmetic Act prohibits the misbranding of food, which includes food labeling that is false or misleading. General information about the process of making cell-cultured meat is available, but specific information about the technology being used and the eventual commercial production methods as well as the final products is not yet known. However, the technology and methods to commercially produce cell- cultured meat are still in development, and producers, regulators, and consumers do not yet have clarity on what these will entail. The composition of the final product is also not yet known. The general process for making cell-cultured meat contains five phases: biopsy, cell banking, growth, harvest, and food processing. Cell banking. Food processing. The technology to produce cell-cultured meat at a commercial scale is still in development, and information about the methods to be used for commercial production and the composition of the final product are not yet known. Consequently, they have not finalized aspects of the technology and eventual commercial production methods to be used or the composition of the final product. As a result, certain information is not yet available to stakeholders\\u2014including cell-cultured meat firms themselves, regulators, and the public\\u2014about specific aspects of the technology and commercial production methods that will be used, such as the composition of the growth medium and of the final products. This lack of information results in unanswered questions about cell- cultured meat as it relates to the eventual technology and commercial production methods to be used and the composition of the final products. Are potential safety hazards in commercial production methods for cell-cultured meat different from those for conventional meat, and how will eventual commercial production methods affect the overall safety of the product? However, because specific information about commercial production methods and final products is not yet known, it is unclear whether cell-cultured meat produced on a commercial scale will pose any hazards not present in conventional meat. What will be the composition of any eventual products? Some firms have developed prototypes of cell-cultured meat products as part of their research and development. FDA and USDA have established multiple mechanisms to collaborate on regulatory oversight of cell-cultured meat. Specifically, the agencies have collaborated through a joint public meeting, an interagency agreement, and three working groups. However, the interagency agreement and working groups, which are ongoing mechanisms, do not fully incorporate leading practices for interagency collaboration. In addition, FDA and USDA have not documented which agency will oversee cell-cultured seafood not covered by the interagency agreement. In June 2019, FDA and USDA created three working groups to carry out the terms of the interagency agreement. FDA and USDA could more fully incorporate leading practices for collaboration in their interagency agreement and working groups. We compared the agencies\\u2019 interagency agreement and working groups with the seven leading practices to enhance and sustain interagency collaboration that we previously identified. Developing and updating written guidance and agreements. We found that the interagency agreement for oversight of cell-cultured meat partially incorporates all seven leading practices for collaboration. Specifically, the agreement identifies broad outcomes such as the development of labeling principles. However, the agreement does not describe how the agencies will track and monitor progress toward outcomes. Developing and updating written guidance and agreements. This is consistent with our leading collaboration practice to continually update or monitor written agreements. However, the interagency agreement does not document how the agencies will track and monitor progress toward short-term and long-term outcomes. Table 1 provides more detail about the agencies\\u2019 incorporation of these leading collaboration practices in their interagency agreement. As the agencies continue to collaborate on their shared oversight of cell- cultured meat, by more fully incorporating all seven leading practices for collaboration into their interagency agreement, they will be better positioned to address potential fragmentation in their efforts to ensure the safety of the food supply as cell-cultured meat products near commercialization and entry into the marketplace. We found that the pre-market assessment, labeling, and transfer of jurisdiction working groups that FDA and USDA created to carry out the terms of the interagency agreement either partially incorporate or do not incorporate the seven leading practices for interagency collaboration. Developing and updating written guidance and agreements. Developing and updating written guidance and agreements. We have previously reported that fragmentation has caused inconsistent oversight and inefficient use of resources in the federal food safety oversight system. In this context, some industry representatives and other stakeholders have expressed concerns about potential fragmentation or overlap in oversight of cell-cultured meat, such as could occur during the harvest phase of cell-cultured meat production when FDA hands off its oversight to USDA. By more fully incorporating all seven leading practices for interagency collaboration early in the development of the three working groups, FDA and USDA could proactively minimize potential fragmentation and overlap in their oversight of cell-cultured meat, ensure consistency and efficient use of resources, and provide clarity to key stakeholders. While FDA and USDA officials told us they have decided who will oversee cell-cultured seafood, they have not formally announced or documented this decision, and some stakeholders have reported confusion or ambiguity about which agency will oversee cell-cultured seafood other than catfish. FDA and USDA officials told us that FDA will have sole oversight responsibility for cell-cultured seafood other than catfish. While FDA and USDA officials told us they had agreed that FDA would oversee cell-cultured seafood other than catfish, as of December 2019, the agencies had not formally announced or documented this agreement. Developing and updating written guidance and agreements is a leading practice for collaboration, as we have previously reported. By taking steps to document which agency will oversee cell-cultured seafood other than catfish, FDA and USDA will better ensure the public, including key stakeholders such as cell-cultured meat firms, have clarity about the agencies\\u2019 oversight responsibilities in this area. Compounding this challenge is that specific information about key aspects of cell-cultured meat, such as the technology and production methods to be used as well as the composition of the products, is not yet known. However, the interagency agreement only partially incorporates the seven leading collaboration practices that can enhance and sustain agencies\\u2019 collaborative efforts, and the working groups either partially incorporate or do not incorporate these leading practices, which has raised concerns about potential fragmentation or overlap in oversight. By more fully incorporating all seven leading practices for collaboration into their interagency agreement, FDA and USDA could build on their existing efforts and be better positioned to sustain and enhance their collaborative efforts. Moreover, by more fully incorporating all seven leading practices for interagency collaboration early in the development of the working groups, FDA and USDA could proactively minimize potential fragmentation and overlap in their oversight of cell-cultured meat and ensure they are utilizing resources efficiently or effectively. FDA and USDA officials told us they have decided FDA will oversee most cell-cultured seafood, but the agencies have not formally documented this decision. By taking steps to document in their interagency agreement, or other publicly available document, which agency will oversee cell-cultured seafood other than catfish, FDA and USDA could better ensure that members of the public and other key stakeholders such as cell-cultured meat firms have clarity about the agencies\\u2019 oversight responsibilities in this area. We are making a total of six recommendations, three to FDA and three to USDA: The Commissioner of the Food and Drug Administration, in coordination with the Secretary of Agriculture, should more fully incorporate the seven leading practices for effective collaboration in the agencies\\u2019 interagency agreement for the joint oversight of cell-cultured meat. (Recommendation 1) The Secretary of Agriculture, in coordination with the Commissioner of the Food and Drug Administration, should more fully incorporate the seven leading practices for effective collaboration in the agencies\\u2019 interagency agreement for the joint oversight of cell-cultured meat. (Recommendation 2) As the three cell-cultured meat working groups move forward, the Commissioner of the Food and Drug Administration, in coordination with the Secretary of Agriculture, should more fully incorporate the seven leading practices for effective collaboration, such as identifying specific outcomes and a way to monitor and evaluate progress toward outcomes. (Recommendation 3) As the three cell-cultured meat working groups move forward, the Secretary of Agriculture, in coordination with the Commissioner of the Food and Drug Administration, should more fully incorporate the seven leading practices for effective collaboration, such as identifying specific outcomes and a way to monitor and evaluate progress toward outcomes. (Recommendation 4) The Commissioner of the Food and Drug Administration, in coordination with the Secretary of Agriculture, should clearly document in their interagency agreement, or other publicly available document, which agency will oversee cell-cultured seafood other than catfish. (Recommendation 5) The Secretary of Agriculture, in coordination with the Commissioner of the Food and Drug Administration, should clearly document in their interagency agreement, or other publicly available document, which agency will oversee cell-cultured seafood other than catfish. (Recommendation 6) We provided a draft of this report to the Department of Health and Human Services\\u2019 (HHS) Food and Drug Administration (FDA) and the U.S. Department of Agriculture (USDA) for review and comment. We agree that the technology to produce cell-cultured meat is still in development and that information about the commercial production methods and composition of the final product are not yet known, as we state in our report. We recognize that cell-cultured meat is a new food product that raises many new questions and that specific information about key aspects of cell-cultured meat is not yet known. In light of this challenging context, it is all the more important that FDA and USDA more fully incorporate leading practices for collaboration into their joint efforts in order to ensure they are in the best possible position to oversee this new food product. FDA concurred with two recommendations and partially concurred with one. USDA also concurred with two recommendations and partially concurred with one. FDA and USDA partially concurred with our recommendation, directed to each agency, to more fully incorporate the seven leading practices for effective collaboration into the agencies\\u2019 interagency agreement for the joint oversight of cell-cultured meat. We appreciate the agencies\\u2019 willingness to incorporate the leading practices for effective collaboration into their efforts. We continue to believe that FDA and USDA should more fully incorporate the seven leading practices for effective collaboration into their interagency agreement for the joint oversight of cell-cultured meat. Developing a more detailed joint framework or standard operating procedure in accordance with the existing interagency agreement that incorporates those leading practices would meet the intent of our recommendation to improve the effectiveness of the agencies\\u2019 collaboration. GAO staff who made key contributions to this report are listed in appendix V. Our report (1) describes what is known about methods for commercially producing cell-cultured meat and (2) examines the extent to which the Food and Drug Administration (FDA) and U.S. Department of Agriculture (USDA) are collaborating to provide regulatory oversight of cell-cultured meat. We also attended public meetings and conferences and conducted site visits to several locations. To describe what is known about the process for producing cell-cultured meat and potential commercial production methods, we also reviewed two sets of public comments submitted to FDA and USDA in association with the two 2018 public meetings pertaining to cell-cultured meat. To examine the extent to which FDA and USDA are coordinating to provide regulatory oversight of cell-cultured meat, we identified actions they took to coordinate from July 2018 through April 2020. We compared the agencies\\u2019 interagency agreement and working groups with seven leading practices to enhance and sustain interagency collaboration. Developing and updating written guidance and agreements How will the collaborative mechanism be funded?\"\"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Abstractive Summary (using BART directly on the full text):\")\n",
        "bart_only_summary = bart_abstractive_summary(\n",
        "    input_text_for_bart,\n",
        "    max_length=150, # Max length of the final abstractive summary\n",
        "    min_length=50,  # Min length of the final abstractive summary\n",
        "    num_beams=4     # Beam search parameter for quality\n",
        ")\n",
        "print(bart_only_summary)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"\\nBART only summarization complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472,
          "referenced_widgets": [
            "2bdbd6d8eb7541c5975551349618d71e",
            "73715692f36a48c8847b0bd53aaf3f32",
            "1da13682bbc74d88a91d622027e0ee5d",
            "faccbf65ddc941b281d4cbb59aeb70ba",
            "8ecd530cd87d4aedaa6f0ee5be2d696f",
            "64a971614faf493eb95d658b71fe356b",
            "9851bc58b6ac4e37a05efa581651d4f3",
            "d232dcba5d1d4ac18b431612aee72c3a",
            "3dcc5afeaa674454b7648e841a168abf",
            "b637236afdd64beb8d11296a4262696c",
            "7ae74c4cbc8c4108967df576b2432d31",
            "bb6dedb10c3c4d3caf5d205f585c90ed",
            "2b84d435c92b430aac8d4aade0092ff9",
            "046ac3860fe944e0adcb7f7a0f0067f5",
            "3fc3bb5ca2904c84a4b5c07fa3e4c4fe",
            "7ec1301e58e04aa7b8473ab0413abf4d",
            "ce021636f43243a9ac64632e4bea1367",
            "dc824fb3186e471db1603dbe46608b8c",
            "ffe6e6d265e3436eace734d81dbe41a3",
            "69220195cd5447c1bf1b5e647e13abf5",
            "a0009e95d452438aadfea6edd7a0bc0c",
            "5beb847abe5a4e349cb3a58f1148f050",
            "2e58c784360c4f3ab8f956cc6b0c5b29",
            "157a56945292436d992abfaf6ee2df11",
            "6089b16e6510446b9d1feffcbfcd2006",
            "f66f5f28be00475f98c748e7493e0ad6",
            "a56dbca2ffa54f4db0ad6c89c58de485",
            "e743bc2501214d04828d0610b18560a0",
            "a810b7e5de814b9794c1f4c63fa00f24",
            "6152ed74c0724a78b12f4870bc28cb06",
            "d295bedb0bca491c852b556d329fe326",
            "dec4b92e299140bb9e24be14183a7610",
            "4d728483ce2b4b499698bc9eda5d9cd0",
            "66686495cc8847be85dc81b532b2d112",
            "8be2a5f41f5c45eeb3595b84096a69c0",
            "f47181468734442e8675fee0a72bca58",
            "f0e3f975eb47414eb1aba3e284ca91fd",
            "8c464a4c781f46f0b7ce12b1d006d765",
            "dd41339c585640d5b3274d05b41d26b7",
            "fcf614e8b60b4f7fbdd1dc8304223aea",
            "face5a50e61f4d1b846bffea4234fd5f",
            "9f4bcbcb1ca7473fb1b5c3098e014920",
            "752405d45a644374becb7da9f50e92e9",
            "ba80f833c67d419db7534034c1d84528",
            "d7f74057c8834f7ca991deffb86ec368",
            "5555b9830e774ea9897fa063ca71e4da",
            "7848e951443c466886d60d08a66d64d9",
            "54475a8c1abb4fbf825306321ed1b9e7",
            "cac3c4061061473cb9c25fdddfa04b68",
            "874f5ba35bb44ac9bb370dfa445932ae",
            "fd9d2c196dff4920990099bd8ad93bef",
            "ff133a7899f04b0c90770d9a1fb0d459",
            "eaf7feeeec354d0d8fd6df14cf86fb6f",
            "e59b1f0945504a95aa73b96724a44846",
            "ff40b9c78c634885bb1238b70aa1d3b3",
            "a9dd76272d1645cca46f657082447413",
            "10774af1e56342eca5823bf6826cb03f",
            "401cf9f0080745edb3dbd8fa7e9324fa",
            "b27c53dc4b3048b79d6adb63440abd60",
            "1d6e9452b7e04558abbbcce600cb4243",
            "89a221e0db4c4c4c8a26b416ab766446",
            "3335f91528254238b20675bcb6be9f9c",
            "96e7c5515283440f81916bd07bd6fdc9",
            "e0a909221eb945a79e68cba7f7808e03",
            "c4b35222ad484cfb886f66933ef60a7f",
            "9bfe6e34e0af4c20b9e18b40c82fee50"
          ]
        },
        "id": "61J6V9ac5qhw",
        "outputId": "1abd7361-75f7-42d0-d350-61744a471d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BART model and tokenizer for abstractive summarization...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bdbd6d8eb7541c5975551349618d71e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb6dedb10c3c4d3caf5d205f585c90ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e58c784360c4f3ab8f956cc6b0c5b29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66686495cc8847be85dc81b532b2d112"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7f74057c8834f7ca991deffb86ec368"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9dd76272d1645cca46f657082447413"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BART using device: cpu\n",
            "BART model loaded.\n",
            "\n",
            "================================================================================\n",
            "Abstractive Summary (using BART directly on the full text):\n",
            "\n",
            "--- Starting BART Abstractive Summarization ---\n",
            "--- BART Abstractive Summarization Complete ---\n",
            "FDA and USDA have responsibility for overseeing the safety of the food supply. The technology to produce cell-cultured meat at a commercial scale is still in development. Information about the methods to be used for commercial production and the composition of the final product are not yet known.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "BART only summarization complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Full code for Longformer and BART and pipeline"
      ],
      "metadata": {
        "id": "RDWlIx9jB3tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 1: Setup, Model Loading, and Function Definitions\n",
        "\n",
        "# Install necessary libraries (only runs if not already installed)\n",
        "%pip install transformers torch scikit-learn numpy scipy spacy\n",
        "\n",
        "# Download spaCy model (only downloads if not already present)\n",
        "try:\n",
        "    import spacy\n",
        "    # Try to load the model directly without 'download' first\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    print(\"spaCy 'en_core_web_sm' model already loaded.\")\n",
        "except OSError:\n",
        "    print(\"spaCy model 'en_core_web_sm' not found. Downloading...\")\n",
        "    from spacy.cli import download\n",
        "    download(\"en_core_web_sm\")\n",
        "    import spacy\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    print(\"spaCy 'en_core_web_sm' model downloaded and loaded.\")\n",
        "\n",
        "import torch\n",
        "from transformers import LongformerModel, LongformerTokenizer, BartForConditionalGeneration, BartTokenizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cdist\n",
        "import numpy as np\n",
        "\n",
        "# --- Load Longformer Model and Tokenizer (for Extractive) ---\n",
        "print(\"Loading Longformer model and tokenizer...\")\n",
        "longformer_model_name = 'allenai/longformer-base-4096'\n",
        "longformer_tokenizer = LongformerTokenizer.from_pretrained(longformer_model_name)\n",
        "longformer_model = LongformerModel.from_pretrained(longformer_model_name)\n",
        "\n",
        "# --- Load BART Model and Tokenizer (for Abstractive) ---\n",
        "print(\"Loading BART model and tokenizer for abstractive summarization...\")\n",
        "bart_model_name = 'facebook/bart-large-cnn' # This is a good choice for summarization\n",
        "bart_tokenizer = BartTokenizer.from_pretrained(bart_model_name)\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(bart_model_name)\n",
        "\n",
        "\n",
        "# --- Set Device (GPU if available, else CPU) ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "longformer_model.eval() # Set to evaluation mode\n",
        "longformer_model.to(device)\n",
        "print(f\"Longformer using device: {device}\")\n",
        "\n",
        "bart_model.eval() # Set to evaluation mode\n",
        "bart_model.to(device)\n",
        "print(f\"BART using device: {device}\")\n",
        "print(\"All models loaded and moved to device.\")\n",
        "\n",
        "# --- Helper Function for Sentence Embeddings (Longformer) ---\n",
        "def get_sentence_embeddings(text, batch_size=4):\n",
        "    \"\"\"\n",
        "    Splits text into sentences, tokenizes them, and gets Longformer embeddings.\n",
        "    Handles long documents by processing sentences in batches.\n",
        "    Returns:\n",
        "        sentences (list): List of original sentence strings.\n",
        "        sentence_embeddings (np.array): NumPy array of sentence embeddings.\n",
        "    \"\"\"\n",
        "    # nlp, longformer_tokenizer, longformer_model, and device are global here\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
        "\n",
        "    if not sentences:\n",
        "        print(\"Warning: No valid sentences found in the input text.\")\n",
        "        return [], np.array([])\n",
        "\n",
        "    all_sentence_embeddings = []\n",
        "    print(f\"Total sentences to process: {len(sentences)}\")\n",
        "\n",
        "    for i in range(0, len(sentences), batch_size):\n",
        "        batch_sentences = sentences[i:i + batch_size]\n",
        "        try:\n",
        "            inputs = longformer_tokenizer(\n",
        "                batch_sentences,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=longformer_tokenizer.model_max_length\n",
        "            ).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = longformer_model(**inputs)\n",
        "\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            all_sentence_embeddings.extend(cls_embeddings)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing batch of sentences (index {i}-{i+len(batch_sentences)-1}): {e}\")\n",
        "            all_sentence_embeddings.extend([np.zeros(longformer_model.config.hidden_size)] * len(batch_sentences))\n",
        "            continue\n",
        "\n",
        "    return sentences, np.array(all_sentence_embeddings)\n",
        "\n",
        "# --- Centroid-Based Summarization Function (Optimized to accept pre-calculated embeddings) ---\n",
        "def centroid_summarization_optimized(sentences, embeddings, num_sentences=3):\n",
        "    \"\"\"\n",
        "    Generates an extractive summary using a centroid-based approach.\n",
        "    Accepts pre-calculated sentences and embeddings.\n",
        "    \"\"\"\n",
        "    if not sentences or embeddings.shape[0] == 0:\n",
        "        print(\"  No sentences or embeddings provided. Cannot summarize.\")\n",
        "        return [], []\n",
        "\n",
        "    if num_sentences <= 0:\n",
        "        print(\"  Number of sentences for summary must be positive.\")\n",
        "        return [], []\n",
        "\n",
        "    num_sentences_to_extract = min(num_sentences, len(sentences))\n",
        "\n",
        "    document_centroid = np.mean(embeddings, axis=0)\n",
        "    similarities = cosine_similarity(embeddings, document_centroid.reshape(1, -1)).flatten()\n",
        "\n",
        "    summary_sentences_mmr = []\n",
        "    selected_indices = set() # Correctly initialized here\n",
        "    ranked_initial_indices = np.argsort(similarities)[::-1]\n",
        "\n",
        "    for _ in range(num_sentences_to_extract):\n",
        "        best_sentence_idx = -1\n",
        "        max_mmr_score = -1\n",
        "\n",
        "        for i in ranked_initial_indices:\n",
        "            if i not in selected_indices:\n",
        "                relevance = similarities[i]\n",
        "\n",
        "                if not selected_indices: # This check is now safe\n",
        "                    mmr_score = relevance\n",
        "                else:\n",
        "                    diversity_scores = cosine_similarity(embeddings[i].reshape(1, -1),\n",
        "                                                         embeddings[list(selected_indices)])\n",
        "                    redundancy = np.max(diversity_scores)\n",
        "                    lambda_param = 0.7\n",
        "                    mmr_score = lambda_param * relevance - (1 - lambda_param) * redundancy\n",
        "\n",
        "                if mmr_score > max_mmr_score:\n",
        "                    max_mmr_score = mmr_score\n",
        "                    best_sentence_idx = i\n",
        "\n",
        "        if best_sentence_idx != -1:\n",
        "            summary_sentences_mmr.append((sentences[best_sentence_idx], best_sentence_idx))\n",
        "            selected_indices.add(best_sentence_idx)\n",
        "            ranked_initial_indices = ranked_initial_indices[ranked_initial_indices != best_sentence_idx]\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    summary_sentences_mmr.sort(key=lambda x: x[1])\n",
        "    final_summary_sents = [s[0] for s in summary_sentences_mmr]\n",
        "    final_summary_indices = [s[1] for s in summary_sentences_mmr]\n",
        "\n",
        "    return final_summary_sents, final_summary_indices\n",
        "\n",
        "# --- K-Means Based Summarization Function (Optimized to accept pre-calculated embeddings) ---\n",
        "def kmeans_summarization_optimized(sentences, embeddings, num_clusters=5, num_sentences_per_cluster=1):\n",
        "    \"\"\"\n",
        "    Generates an extractive summary using K-Means clustering.\n",
        "    Accepts pre-calculated sentences and embeddings.\n",
        "    \"\"\"\n",
        "    if not sentences or embeddings.shape[0] == 0:\n",
        "        print(\"  No sentences or embeddings provided. Cannot summarize.\")\n",
        "        return [], []\n",
        "\n",
        "    if num_clusters <= 0 or num_sentences_per_cluster <= 0:\n",
        "        print(\"  Number of clusters and sentences per cluster must be positive.\")\n",
        "        return [], []\n",
        "\n",
        "    effective_num_clusters = min(num_clusters, len(sentences))\n",
        "\n",
        "    if effective_num_clusters == 0:\n",
        "        print(\"  Not enough sentences to form clusters.\")\n",
        "        return [], []\n",
        "\n",
        "    kmeans = KMeans(n_clusters=effective_num_clusters, random_state=42, n_init='auto')\n",
        "    kmeans.fit(embeddings)\n",
        "    clusters = kmeans.labels_\n",
        "    centroids = kmeans.cluster_centers_\n",
        "\n",
        "    summary_sentences_with_idx = []\n",
        "    selected_indices = set()\n",
        "\n",
        "    for i in range(effective_num_clusters):\n",
        "        cluster_sentence_indices = np.where(clusters == i)[0]\n",
        "\n",
        "        if len(cluster_sentence_indices) == 0:\n",
        "            continue\n",
        "\n",
        "        distances = cdist(embeddings[cluster_sentence_indices], centroids[i].reshape(1, -1), 'cosine').flatten()\n",
        "        sorted_cluster_indices = cluster_sentence_indices[np.argsort(distances)]\n",
        "\n",
        "        count_selected_from_cluster = 0\n",
        "        for original_idx in sorted_cluster_indices:\n",
        "            if original_idx not in selected_indices:\n",
        "                summary_sentences_with_idx.append((sentences[original_idx], original_idx))\n",
        "                selected_indices.add(original_idx)\n",
        "                count_selected_from_cluster += 1\n",
        "                if count_selected_from_cluster >= num_sentences_per_cluster:\n",
        "                    break\n",
        "\n",
        "    summary_sentences_with_idx.sort(key=lambda x: x[1])\n",
        "    final_summary_sents = [s[0] for s in summary_sentences_with_idx]\n",
        "    final_summary_indices = [s[1] for s in summary_sentences_with_idx]\n",
        "\n",
        "    return final_summary_sents, final_summary_indices\n",
        "\n",
        "# --- Combined Extractive Summarization Function (Optimized) ---\n",
        "def combined_extractive_summary_optimized(sentences, embeddings, total_summary_sentences=7,\n",
        "                                centroid_sentences_to_propose=5,\n",
        "                                kmeans_clusters_to_propose=4,\n",
        "                                kmeans_sentences_per_cluster_to_propose=1,\n",
        "                                lambda_param_mmr=0.7):\n",
        "    \"\"\"\n",
        "    Generates a single extractive summary by combining candidates from\n",
        "    both centroid-based and K-Means approaches, then using MMR for final selection.\n",
        "    Accepts pre-calculated sentences and embeddings.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Starting Combined Extractive Summarization Candidate Generation ---\")\n",
        "    if not sentences or embeddings.shape[0] == 0:\n",
        "        print(\"  No sentences or embeddings provided. Cannot summarize combined.\")\n",
        "        return []\n",
        "\n",
        "    centroid_candidates_sents, centroid_candidates_indices = centroid_summarization_optimized(\n",
        "        sentences, embeddings, num_sentences=centroid_sentences_to_propose\n",
        "    )\n",
        "    print(f\"  Centroid proposed {len(centroid_candidates_sents)} candidates.\")\n",
        "\n",
        "    kmeans_candidates_sents, kmeans_candidates_indices = kmeans_summarization_optimized(\n",
        "        sentences, embeddings, num_clusters=kmeans_clusters_to_propose, num_sentences_per_cluster=kmeans_sentences_per_cluster_to_propose\n",
        "    )\n",
        "    print(f\"  K-Means proposed {len(kmeans_candidates_sents)} candidates.\")\n",
        "\n",
        "    # Combine candidates and their original indices, removing duplicates\n",
        "    combined_candidates_map = {}\n",
        "    for idx, sent in zip(centroid_candidates_indices, centroid_candidates_sents):\n",
        "        combined_candidates_map[idx] = sent\n",
        "    for idx, sent in zip(kmeans_candidates_indices, kmeans_candidates_sents):\n",
        "        combined_candidates_map[idx] = sent\n",
        "\n",
        "    all_candidate_indices_sorted = sorted(combined_candidates_map.keys())\n",
        "    all_candidate_sentences = [combined_candidates_map[idx] for idx in all_candidate_indices_sorted]\n",
        "    all_candidate_embeddings = np.array([embeddings[idx] for idx in all_candidate_indices_sorted])\n",
        "\n",
        "    if not all_candidate_sentences or all_candidate_embeddings.shape[0] == 0:\n",
        "        print(\"  No unique candidates found after combining. Cannot generate combined summary.\")\n",
        "        return []\n",
        "\n",
        "    num_sentences_to_extract = min(total_summary_sentences, len(all_candidate_sentences))\n",
        "    print(f\"  Total unique candidates: {len(all_candidate_sentences)}. Extracting {num_sentences_to_extract} for combined summary.\")\n",
        "\n",
        "    document_centroid = np.mean(embeddings, axis=0)\n",
        "    candidate_similarities = cosine_similarity(all_candidate_embeddings, document_centroid.reshape(1, -1)).flatten()\n",
        "\n",
        "    final_summary_sentences = []\n",
        "    selected_candidate_indices = set() # <-- FIXED: Initialized here\n",
        "\n",
        "    ranked_initial_candidate_indices = np.argsort(candidate_similarities)[::-1]\n",
        "\n",
        "    for _ in range(num_sentences_to_extract):\n",
        "        best_idx_in_candidates = -1\n",
        "        max_mmr_score = -1\n",
        "\n",
        "        for i_candidate in ranked_initial_candidate_indices:\n",
        "            if i_candidate not in selected_candidate_indices:\n",
        "                relevance = candidate_similarities[i_candidate]\n",
        "\n",
        "                if not selected_candidate_indices:\n",
        "                    mmr_score = relevance\n",
        "                else:\n",
        "                    diversity_scores = cosine_similarity(all_candidate_embeddings[i_candidate].reshape(1, -1),\n",
        "                                                         all_candidate_embeddings[list(selected_candidate_indices)])\n",
        "                    redundancy = np.max(diversity_scores)\n",
        "\n",
        "                    mmr_score = lambda_param_mmr * relevance - (1 - lambda_param_mmr) * redundancy\n",
        "\n",
        "                if mmr_score > max_mmr_score:\n",
        "                    max_mmr_score = mmr_score\n",
        "                    best_idx_in_candidates = i_candidate\n",
        "\n",
        "        if best_idx_in_candidates != -1:\n",
        "            final_summary_sentences.append((all_candidate_sentences[best_idx_in_candidates],\n",
        "                                             all_candidate_indices_sorted[best_idx_in_candidates]))\n",
        "            selected_candidate_indices.add(best_idx_in_candidates)\n",
        "            ranked_initial_candidate_indices = ranked_initial_candidate_indices[ranked_initial_candidate_indices != best_idx_in_candidates]\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    final_summary_sentences.sort(key=lambda x: x[1])\n",
        "    final_summary = [s[0] for s in final_summary_sentences]\n",
        "\n",
        "    print(\"--- Combined Extractive Summarization Selection Complete ---\")\n",
        "    return final_summary\n",
        "\n",
        "# --- Abstractive Summarization Function (using BART) ---\n",
        "def bart_abstractive_summary(text_to_summarize, max_length=150, min_length=50, num_beams=4, early_stopping=True):\n",
        "    \"\"\"\n",
        "    Generates an abstractive summary using the pre-loaded BART model.\n",
        "    Assumes bart_tokenizer and bart_model are loaded globally.\n",
        "\n",
        "    Args:\n",
        "        text_to_summarize (str or list of str): The input text (or list of sentences) to summarize.\n",
        "                                                  If a list, it will be joined into a single string.\n",
        "        max_length (int): Maximum length of the generated summary.\n",
        "        min_length (int): Minimum length of the generated summary.\n",
        "        num_beams (int): Number of beams for beam search. Higher values lead to better quality but slower generation.\n",
        "        early_stopping (bool): Whether to stop beam search when all beams have finished their generation.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated abstractive summary.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Starting BART Abstractive Summarization ---\")\n",
        "\n",
        "    if isinstance(text_to_summarize, list):\n",
        "        text_to_summarize = \" \".join(text_to_summarize)\n",
        "\n",
        "    if not text_to_summarize.strip():\n",
        "        print(\"  Input text for abstractive summary is empty. Cannot summarize.\")\n",
        "        return \"\"\n",
        "\n",
        "    inputs = bart_tokenizer(\n",
        "        [text_to_summarize],\n",
        "        max_length=1024, # BART's typical max input length\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    ).to(device)\n",
        "\n",
        "    summary_ids = bart_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        num_beams=num_beams,\n",
        "        max_length=max_length,\n",
        "        min_length=min_length,\n",
        "        early_stopping=early_stopping\n",
        "    )\n",
        "\n",
        "    summary_text = bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    print(\"--- BART Abstractive Summarization Complete ---\")\n",
        "    return summary_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEhKmnvf7L58",
        "outputId": "f3888790-a57b-468b-ddf7-29a2ab2ddaad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.16.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "spaCy 'en_core_web_sm' model already loaded.\n",
            "Loading Longformer model and tokenizer...\n",
            "Loading BART model and tokenizer for abstractive summarization...\n",
            "Longformer using device: cpu\n",
            "BART using device: cpu\n",
            "All models loaded and moved to device.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 2: Your Document Text\n",
        "\n",
        "long_document = \"\"\"\n",
        "Artificial intelligence (AI) has rapidly transformed various sectors, revolutionizing industries from healthcare to finance. In healthcare, AI assists in diagnosing diseases earlier and more accurately, personalizing treatment plans, and accelerating drug discovery. Machine learning algorithms, a subset of AI, analyze vast amounts of patient data to identify patterns that human doctors might miss, leading to more effective interventions. For instance, AI-powered tools can detect subtle signs of retinopathy from eye scans, potentially preventing blindness. The integration of AI into electronic health records is also streamlining administrative tasks, freeing up medical professionals to focus more on patient care. This technological leap promises to enhance diagnostic capabilities and optimize treatment protocols significantly.\n",
        "\n",
        "The financial industry also heavily leverages AI for fraud detection, algorithmic trading, and personalized financial advice. AI systems can monitor transactions in real-time, identifying unusual patterns indicative of fraudulent activity with high precision. Furthermore, robo-advisors powered by AI provide automated, data-driven investment advice tailored to individual risk tolerance and financial goals, making financial planning more accessible to a wider demographic. The use of AI in predicting market trends and managing portfolios is becoming increasingly sophisticated, offering new avenues for investors.\n",
        "\n",
        "Beyond these, AI is deeply embedded in everyday life through virtual assistants like Siri and Alexa, recommendation engines on streaming platforms, and autonomous vehicles. AI's role in natural language processing (NLP) has led to advancements in language translation and sentiment analysis, impacting global communication and customer service. The ethical implications of AI, however, are a growing concern among researchers and policymakers. Issues such as algorithmic bias, job displacement due to automation, and privacy breaches require careful consideration and robust regulation. Ensuring transparency, fairness, and accountability in AI development is paramount to harnessing its benefits responsibly.\n",
        "\n",
        "Research in AI continues to advance at an astonishing pace, focusing on areas like explainable AI (XAI) to make AI decisions more understandable, and robust AI to improve performance in real-world, unpredictable environments. Novel architectures like generative adversarial networks (GANs) and reinforcement learning are pushing the boundaries of what AI can achieve, from creating realistic imagery to mastering complex games. The future of AI promises even more integration into society, with potential breakthroughs in areas like general artificial intelligence (AGI) and enhanced human-computer interaction, leading to smarter cities and more efficient resource management. However, achieving these advancements responsibly will necessitate ongoing collaboration between technologists, policymakers, and ethicists to address the complex challenges that arise. The rapid pace of development means that continuous public discourse and legislative adaptation are critical to navigate the challenges and maximize the societal benefits of AI, ensuring it serves humanity's best interests.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DF25_IWL_8_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 3: The Summarization Pipeline\n",
        "\n",
        "print(\"--- Starting Hybrid Summarization Pipeline ---\")\n",
        "print(\"Original Document Length (sentences):\", sum(1 for _ in nlp(long_document).sents))\n",
        "\n",
        "\n",
        "# Step 1: Generate Sentence Embeddings using Longformer\n",
        "print(\"\\n[Pipeline Step 1/3] Calculating document embeddings with Longformer...\")\n",
        "sentences_list, embeddings_array = get_sentence_embeddings(long_document, batch_size=8)\n",
        "print(\"  Embeddings calculation complete.\")\n",
        "\n",
        "\n",
        "# Step 2: Generate Combined Extractive Summary\n",
        "print(\"\\n[Pipeline Step 2/3] Generating combined extractive summary...\")\n",
        "combined_extractive_summary_sentences = combined_extractive_summary_optimized(\n",
        "    sentences_list,\n",
        "    embeddings_array,\n",
        "    total_summary_sentences=6, # Desired length for the extractive part\n",
        "    centroid_sentences_to_propose=7,\n",
        "    kmeans_clusters_to_propose=5,\n",
        "    kmeans_sentences_per_cluster_to_propose=1\n",
        ")\n",
        "print(f\"  Extracted {len(combined_extractive_summary_sentences)} sentences.\")\n",
        "print(\"\\nExtractive Summary:\")\n",
        "for i, sent in enumerate(combined_extractive_summary_sentences):\n",
        "    print(f\"{i+1}. {sent}\")\n",
        "\n",
        "\n",
        "# Step 3: Generate Abstractive Summary from Extractive Output using BART\n",
        "print(\"\\n[Pipeline Step 3/3] Generating abstractive summary with BART...\")\n",
        "extractive_text_for_abstractive = \" \".join(combined_extractive_summary_sentences)\n",
        "final_abstractive_summary = bart_abstractive_summary(\n",
        "    extractive_text_for_abstractive,\n",
        "    max_length=150, # Max length of the final abstractive summary\n",
        "    min_length=50,  # Min length of the final abstractive summary\n",
        "    num_beams=4     # Beam search parameter for quality\n",
        ")\n",
        "print(\"\\nAbstractive Summary:\")\n",
        "print(final_abstractive_summary)\n",
        "\n",
        "print(\"\\n--- Hybrid Summarization Pipeline Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzc4YCE7ADPZ",
        "outputId": "6d45b1a0-2b16-4607-a33c-b7a87f851c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Hybrid Summarization Pipeline ---\n",
            "Original Document Length (sentences): 20\n",
            "\n",
            "[Pipeline Step 1/3] Calculating document embeddings with Longformer...\n",
            "Total sentences to process: 20\n",
            "  Embeddings calculation complete.\n",
            "\n",
            "[Pipeline Step 2/3] Generating combined extractive summary...\n",
            "\n",
            "--- Starting Combined Extractive Summarization Candidate Generation ---\n",
            "  Centroid proposed 7 candidates.\n",
            "  K-Means proposed 5 candidates.\n",
            "  Total unique candidates: 11. Extracting 6 for combined summary.\n",
            "--- Combined Extractive Summarization Selection Complete ---\n",
            "  Extracted 6 sentences.\n",
            "\n",
            "Extractive Summary:\n",
            "1. Artificial intelligence (AI) has rapidly transformed various sectors, revolutionizing industries from healthcare to finance.\n",
            "2. The integration of AI into electronic health records is also streamlining administrative tasks, freeing up medical professionals to focus more on patient care.\n",
            "3. Furthermore, robo-advisors powered by AI provide automated, data-driven investment advice tailored to individual risk tolerance and financial goals, making financial planning more accessible to a wider demographic.\n",
            "4. Issues such as algorithmic bias, job displacement due to automation, and privacy breaches require careful consideration and robust regulation.\n",
            "5. The future of AI promises even more integration into society, with potential breakthroughs in areas like general artificial intelligence (AGI) and enhanced human-computer interaction, leading to smarter cities and more efficient resource management.\n",
            "6. The rapid pace of development means that continuous public discourse and legislative adaptation are critical to navigate the challenges and maximize the societal benefits of AI, ensuring it serves humanity's best interests.\n",
            "\n",
            "[Pipeline Step 3/3] Generating abstractive summary with BART...\n",
            "\n",
            "--- Starting BART Abstractive Summarization ---\n",
            "--- BART Abstractive Summarization Complete ---\n",
            "\n",
            "Abstractive Summary:\n",
            "Artificial intelligence (AI) has rapidly transformed various sectors. Issues such as algorithmic bias, job displacement due to automation, and privacy breaches require careful consideration and robust regulation. Future of AI promises even more integration into society, with potential breakthroughs in areas like general artificial intelligence.\n",
            "\n",
            "--- Hybrid Summarization Pipeline Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DKbYwP_ilxC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rough\n"
      ],
      "metadata": {
        "id": "d445q_fulxvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "# --- Load BART Model and Tokenizer ---\n",
        "print(\"Loading BART model and tokenizer for abstractive summarization...\")\n",
        "bart_model_name = 'facebook/bart-large-cnn'\n",
        "bart_tokenizer = BartTokenizer.from_pretrained(bart_model_name)\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(bart_model_name)\n",
        "\n",
        "# --- Set Device (GPU if available, else CPU) ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bart_model.eval()\n",
        "bart_model.to(device)\n",
        "print(f\"BART using device: {device}\")\n",
        "print(\"BART model loaded.\")\n",
        "\n",
        "# Load spaCy for fact extraction\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    print(\"spaCy model loaded.\")\n",
        "except:\n",
        "    print(\"Installing spaCy model...\")\n",
        "    import os\n",
        "    os.system(\"python -m spacy download en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    print(\"spaCy model loaded.\")\n",
        "\n",
        "# --- Helper Functions for Constrained Beam Search ---\n",
        "\n",
        "def extract_key_facts(extractive_output, importance_threshold=0.7):\n",
        "    \"\"\"Extract key facts from the extractive summarization output\"\"\"\n",
        "    if isinstance(extractive_output, str):\n",
        "        # If input is a string, treat it as a single sentence with high importance\n",
        "        key_sentences = [extractive_output]\n",
        "    elif isinstance(extractive_output, list) and all(isinstance(item, str) for item in extractive_output):\n",
        "        # If input is a list of strings, use all sentences\n",
        "        key_sentences = extractive_output\n",
        "    else:\n",
        "        # If input is a list of (sentence, score) tuples\n",
        "        key_sentences = [sent for sent, score in extractive_output if score > importance_threshold]\n",
        "\n",
        "    # Process sentences to extract atomic facts\n",
        "    facts = []\n",
        "    for sentence in key_sentences:\n",
        "        # Simple approach: use key noun phrases and entities\n",
        "        doc = nlp(sentence)\n",
        "        for chunk in doc.noun_chunks:\n",
        "            if len(chunk.text.split()) > 1:  # Filter out very short phrases\n",
        "                facts.append(chunk.text)\n",
        "\n",
        "        # Add named entities\n",
        "        for ent in doc.ents:\n",
        "            facts.append(ent.text)\n",
        "\n",
        "    # Deduplicate facts\n",
        "    return list(set(facts))\n",
        "\n",
        "def prepare_constraints(facts, tokenizer):\n",
        "    \"\"\"Convert textual facts to token IDs for constraint checking\"\"\"\n",
        "    constraints = []\n",
        "    for fact in facts:\n",
        "        # Tokenize the fact\n",
        "        fact_tokens = tokenizer.encode(fact, add_special_tokens=False)\n",
        "\n",
        "        # Only use facts that aren't too long or too short\n",
        "        if 2 <= len(fact_tokens) <= 10:\n",
        "            constraints.append(fact_tokens)\n",
        "\n",
        "    return constraints\n",
        "\n",
        "def is_subsequence(smaller, larger):\n",
        "    \"\"\"Check if smaller list appears as a subsequence in larger list\"\"\"\n",
        "    i = j = 0\n",
        "    while i < len(smaller) and j < len(larger):\n",
        "        if smaller[i] == larger[j]:\n",
        "            i += 1\n",
        "        j += 1\n",
        "    return i == len(smaller)\n",
        "\n",
        "def check_constraints(sequence, constraints):\n",
        "    \"\"\"Check which constraints are satisfied by the current sequence\"\"\"\n",
        "    satisfied = []\n",
        "\n",
        "    for i, constraint in enumerate(constraints):\n",
        "        # Check if constraint tokens appear in sequence in the correct order\n",
        "        if is_subsequence(constraint, sequence):\n",
        "            satisfied.append(i)\n",
        "\n",
        "    return satisfied\n",
        "\n",
        "# --- Constrained Beam Search Implementation ---\n",
        "\n",
        "def constrained_beam_search(model, input_ids, attention_mask, constraints,\n",
        "                           num_beams=4, max_length=150, min_length=50,\n",
        "                           constraint_weight=2.0):\n",
        "    \"\"\"\n",
        "    Implements constrained beam search for BART summarization.\n",
        "\n",
        "    Args:\n",
        "        model: The BART model\n",
        "        input_ids: Tokenized input text\n",
        "        attention_mask: Attention mask for input\n",
        "        constraints: List of token sequences that should appear in the output\n",
        "        num_beams: Number of beams for beam search\n",
        "        max_length: Maximum length of the generated summary\n",
        "        min_length: Minimum length of the generated summary\n",
        "        constraint_weight: Weight given to satisfying constraints\n",
        "\n",
        "    Returns:\n",
        "        The generated summary that satisfies the most constraints\n",
        "    \"\"\"\n",
        "    # Get encoder output once\n",
        "    encoder_outputs = model.get_encoder()(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "\n",
        "    # Initialize beams: (tokens, log_prob, satisfied_constraints)\n",
        "    batch_size = input_ids.shape[0]\n",
        "    device = input_ids.device\n",
        "\n",
        "    # Start with the decoder start token\n",
        "    decoder_start_token_id = model.config.decoder_start_token_id\n",
        "    beams = [([decoder_start_token_id], 0.0, set()) for _ in range(num_beams)]\n",
        "\n",
        "    # Track completed sequences\n",
        "    done_beams = []\n",
        "\n",
        "    # Main beam search loop\n",
        "    for step in range(max_length):\n",
        "        all_candidates = []\n",
        "\n",
        "        # Check if all beams are done\n",
        "        if len(done_beams) == num_beams:\n",
        "            break\n",
        "\n",
        "        # Prepare current tokens for all beams\n",
        "        active_beams = [b for b in beams if b[0][-1] != model.config.eos_token_id]\n",
        "        if not active_beams:\n",
        "            break\n",
        "\n",
        "        current_tokens = [beam[0] for beam in active_beams]\n",
        "        max_len = max(len(tokens) for tokens in current_tokens)\n",
        "\n",
        "        # Pad and create tensor\n",
        "        padded_tokens = [tokens + [model.config.pad_token_id] * (max_len - len(tokens)) for tokens in current_tokens]\n",
        "        decoder_input = torch.tensor(padded_tokens, device=device)\n",
        "\n",
        "        # Get next token predictions\n",
        "        with torch.no_grad():\n",
        "            outputs = model.decoder(\n",
        "                input_ids=decoder_input,\n",
        "                encoder_hidden_states=encoder_outputs.last_hidden_state,\n",
        "                encoder_attention_mask=attention_mask\n",
        "            )\n",
        "\n",
        "            logits = outputs[0]  # Get logits\n",
        "\n",
        "            # Process each beam\n",
        "            for beam_idx, (tokens, score, satisfied) in enumerate(active_beams):\n",
        "                # Get logits for the last token\n",
        "                curr_logits = logits[beam_idx, len(tokens)-1, :]\n",
        "\n",
        "                # Apply softmax to get probabilities\n",
        "                probs = torch.nn.functional.softmax(curr_logits, dim=-1)\n",
        "                log_probs = torch.log(probs + 1e-10)  # Add small epsilon to avoid log(0)\n",
        "\n",
        "                # Get top tokens\n",
        "                topk_log_probs, topk_indices = torch.topk(log_probs, num_beams * 2)\n",
        "\n",
        "                # Create new candidates\n",
        "                for log_prob, token_id in zip(topk_log_probs.tolist(), topk_indices.tolist()):\n",
        "                    new_tokens = tokens + [token_id]\n",
        "                    new_score = score + log_prob\n",
        "\n",
        "                    # Check which constraints are newly satisfied\n",
        "                    new_satisfied = set(satisfied)\n",
        "                    for i, constraint in enumerate(constraints):\n",
        "                        if i not in new_satisfied and is_subsequence(constraint, new_tokens):\n",
        "                            new_satisfied.add(i)\n",
        "\n",
        "                    # Apply constraint bonus\n",
        "                    constraint_bonus = len(new_satisfied) * constraint_weight\n",
        "                    adjusted_score = new_score + constraint_bonus\n",
        "\n",
        "                    # Add to candidates\n",
        "                    all_candidates.append((new_tokens, adjusted_score, new_satisfied))\n",
        "\n",
        "                    # Check if this is a completed sequence\n",
        "                    if token_id == model.config.eos_token_id and len(new_tokens) >= min_length:\n",
        "                        done_beams.append((new_tokens, adjusted_score, new_satisfied))\n",
        "\n",
        "        # Select top beams for next iteration\n",
        "        beams = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:num_beams]\n",
        "\n",
        "    # If we have completed sequences, return the best one\n",
        "    if done_beams:\n",
        "        # Sort by number of constraints satisfied, then by score\n",
        "        best_beam = max(done_beams, key=lambda x: (len(x[2]), x[1]))\n",
        "        return best_beam[0]\n",
        "\n",
        "    # If no sequence completed, return the best current beam\n",
        "    best_beam = max(beams, key=lambda x: (len(x[2]), x[1]))\n",
        "    return best_beam[0]\n",
        "\n",
        "# --- Abstractive Summarization with Constrained Beam Search ---\n",
        "\n",
        "def constrained_bart_summary(text_to_summarize, constraint_sentences=None,\n",
        "                            max_length=150, min_length=50, num_beams=4):\n",
        "    \"\"\"\n",
        "    Generates an abstractive summary using BART with constrained beam search.\n",
        "\n",
        "    Args:\n",
        "        text_to_summarize (str): The input text to summarize\n",
        "        constraint_sentences (list): List of sentences containing facts that must be included\n",
        "        max_length (int): Maximum length of the generated summary\n",
        "        min_length (int): Minimum length of the generated summary\n",
        "        num_beams (int): Number of beams for beam search\n",
        "\n",
        "    Returns:\n",
        "        str: The generated abstractive summary that includes the key facts\n",
        "    \"\"\"\n",
        "    print(\"Starting BART Abstractive Summarization with Constrained Beam Search ---\")\n",
        "\n",
        "    if isinstance(text_to_summarize, list):\n",
        "        text_to_summarize = \" \".join(text_to_summarize)\n",
        "\n",
        "    if not text_to_summarize.strip():\n",
        "        print(\"  Input text for abstractive summary is empty. Cannot summarize.\")\n",
        "        return \"\"\n",
        "\n",
        "    # Process input text\n",
        "    inputs = bart_tokenizer(\n",
        "        [text_to_summarize],\n",
        "        max_length=1024,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    ).to(device)\n",
        "\n",
        "    # Extract and prepare constraints if provided\n",
        "    constraints = []\n",
        "    if constraint_sentences:\n",
        "        print(f\"Extracting key facts from {len(constraint_sentences)} constraint sentences...\")\n",
        "        facts = extract_key_facts(constraint_sentences)\n",
        "        print(f\"Extracted {len(facts)} key facts: {facts[:5]}...\")\n",
        "        constraints = prepare_constraints(facts, bart_tokenizer)\n",
        "        print(f\"Prepared {len(constraints)} constraints for beam search\")\n",
        "\n",
        "    # If no constraints or constraint extraction failed, fall back to standard beam search\n",
        "    if not constraints:\n",
        "        print(\"No constraints provided or extracted. Using standard beam search.\")\n",
        "        summary_ids = bart_model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            num_beams=num_beams,\n",
        "            max_length=max_length,\n",
        "            min_length=min_length,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        summary_text = bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    else:\n",
        "        # Use constrained beam search\n",
        "        print(\"Using constrained beam search with extracted facts...\")\n",
        "        output_ids = constrained_beam_search(\n",
        "            model=bart_model,\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            constraints=constraints,\n",
        "            num_beams=num_beams,\n",
        "            max_length=max_length,\n",
        "            min_length=min_length\n",
        "        )\n",
        "        summary_text = bart_tokenizer.decode(output_ids, skip_special_tokens=True)\n",
        "\n",
        "    print(\"--- BART Abstractive Summarization with Constrained Beam Search Complete ---\")\n",
        "    return summary_text\n",
        "\n",
        "# --- Example Usage ---\n",
        "# This is where you would input your text and constraint sentences\n",
        "\n",
        "# Example:\n",
        "\n",
        "input_text = \"\"\"Artificial intelligence (AI) has rapidly become a transformative force across various industries. In healthcare, AI systems assist doctors by analyzing medical images, predicting patient risks, and streamlining administrative tasks through automated electronic health records. Hospitals are increasingly relying on AI tools to optimize patient scheduling and improve diagnostic accuracy. In finance, AI-driven algorithms power fraud detection systems, assess credit risk, and support robo-advisors that provide tailored investment advice based on individual financial goals and risk tolerance.\n",
        "\n",
        "AI is also playing a crucial role in transportation. Self-driving cars and traffic optimization systems use vast amounts of data to reduce accidents and improve traffic flow in urban areas. Meanwhile, the education sector is leveraging AI-powered personalized learning platforms that adapt to students’ strengths and weaknesses, enhancing engagement and learning outcomes.\n",
        "\n",
        "However, the rise of AI comes with challenges. Concerns about algorithmic bias, data privacy, and job displacement are prompting calls for stronger regulations and ethical guidelines. Privacy breaches can occur when sensitive personal data is mishandled by AI systems, while automation threatens certain repetitive or low-skilled jobs.\n",
        "\n",
        "The future of AI looks promising, with ongoing research into general artificial intelligence (AGI) and advanced human-computer interaction. Smarter cities, more efficient energy management, and breakthroughs in medicine are all on the horizon. To ensure AI serves humanity’s best interests, governments, companies, and researchers must engage in continuous public discourse, adapt regulations, and focus on ethical deployment of this powerful technology.\"\"\"\n",
        "\n",
        "# These are the factual and relationship constraint sentences\n",
        "constraint_sentences = [\n",
        "    \"Education uses personalized learning platforms powered by AI.\"\n",
        "]\n",
        "\n",
        "summary = constrained_bart_summary(\n",
        "    input_text,\n",
        "    constraint_sentences=constraint_sentences,\n",
        "    max_length=150,\n",
        "    min_length=50,\n",
        "    num_beams=4\n",
        ")\n",
        "\n",
        "print(\"\" + \"=\"*80)\n",
        "print(\"Constrained Abstractive Summary:\")\n",
        "print(summary)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzGfC1EWl1Kz",
        "outputId": "689a7c00-21f5-47e3-afcd-1d478f5bc5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BART model and tokenizer for abstractive summarization...\n",
            "BART using device: cpu\n",
            "BART model loaded.\n",
            "spaCy model loaded.\n",
            "Starting BART Abstractive Summarization with Constrained Beam Search ---\n",
            "Extracting key facts from 1 constraint sentences...\n",
            "Extracted 3 key facts: ['Education', 'personalized learning platforms', 'AI']...\n",
            "Prepared 1 constraints for beam search\n",
            "Using constrained beam search with extracted facts...\n",
            "--- BART Abstractive Summarization with Constrained Beam Search Complete ---\n",
            "================================================================================\n",
            "Constrained Abstractive Summary:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your beam search still outputs only <\\s> because the first predicted token is EOS.\n",
        "Even with early EOS blocking, this can happen if:\n",
        "\n",
        "Probability of EOS dominates initially, which happens with small batch beam search using custom decoding.\n",
        "\n",
        "No token in the top-k log probs survives filtering because of the early EOS skip.\n",
        "\n",
        "Constraint subsequences are hard to satisfy, and beam scoring leads to pruning all sequences.\n",
        "\n",
        "Why this happens\n",
        "You are starting with decoder_start_token_id = 0 (BART <s>).\n",
        "\n",
        "On the first step, the model often outputs EOS with very high probability.\n",
        "\n",
        "In your beam loop, if EOS is skipped and all candidates are empty, it leads to immediate termination.\n",
        "\n",
        "Robust Fix\n",
        "Instead of hand-rolling beam search, leverage Hugging Face’s generate with force_words_ids, which natively handles constraints and prevents EOS problems.\n",
        "\n",
        "Here’s a simpler and working solution:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n"
      ],
      "metadata": {
        "id": "7ZxC0vpX1VYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "bart_model_name = 'facebook/bart-large-cnn'\n",
        "tokenizer = BartTokenizer.from_pretrained(bart_model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(bart_model_name).eval()\n",
        "\n",
        "text = \"\"\"Artificial intelligence (AI) has rapidly become a transformative force across various industries.\n",
        "In healthcare, AI systems assist doctors by analyzing medical images, predicting patient risks, and streamlining administrative tasks\n",
        "through automated electronic health records. Hospitals are increasingly relying on AI tools to optimize patient scheduling and improve\n",
        "diagnostic accuracy. In finance, AI-driven algorithms power fraud detection systems, assess credit risk, and support robo-advisors\n",
        "that provide tailored investment advice based on individual financial goals and risk tolerance.\n",
        "\n",
        "AI is also playing a crucial role in transportation. Self-driving cars and traffic optimization systems use vast amounts of data\n",
        "to reduce accidents and improve traffic flow in urban areas. Meanwhile, the education sector is leveraging AI-powered personalized\n",
        "learning platforms that adapt to students’ strengths and weaknesses, enhancing engagement and learning outcomes.\n",
        "\n",
        "However, the rise of AI comes with challenges. Concerns about algorithmic bias, data privacy, and job displacement are prompting\n",
        "calls for stronger regulations and ethical guidelines. Privacy breaches can occur when sensitive personal data is mishandled by\n",
        "AI systems, while automation threatens certain repetitive or low-skilled jobs.\n",
        "\n",
        "The future of AI looks promising, with ongoing research into general artificial intelligence (AGI) and advanced human-computer\n",
        "interaction. Smarter cities, more efficient energy management, and breakthroughs in medicine are all on the horizon. To ensure\n",
        "AI serves humanity’s best interests, governments, companies, and researchers must engage in continuous public discourse, adapt\n",
        "regulations, and focus on ethical deployment of this powerful technology.\n",
        "\"\"\"\n",
        "\n",
        "# --- Constraint words ---\n",
        "constraint_words = [\"Education\", \"AI\"]\n",
        "force_words_ids = [tokenizer([w], add_special_tokens=False).input_ids[0] for w in constraint_words]\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
        "\n",
        "summary_ids = model.generate(\n",
        "    **inputs,\n",
        "    max_length=150,\n",
        "    min_length=50,\n",
        "    num_beams=5,\n",
        "    force_words_ids=force_words_ids,\n",
        "    no_repeat_ngram_size=3,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(\"Constrained Abstractive Summary:\")\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPyeUdKEpFNW",
        "outputId": "ae18b73c-e84a-479d-8a5d-cf4531ddfcfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Constrained Beam Search is scheduled to be moved to a `custom_generate` repository in v4.55.0. To prevent loss of backward compatibility, add `trust_remote_code=True` to your `generate` call.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constrained Abstractive Summary:\n",
            "Artificial intelligence (AI) has rapidly become a transformative force across various industries. Concerns about algorithmic bias, data privacy, and job displacement are prompting calls for stronger regulations and ethical guidelines. The future of AI looks promising, with ongoing research into general artificial intelligence (AGI) and advanced human-computer interaction. Smarter cities, more efficient energy management, and breakthroughs in medicine are all on the horizon. To ensure AI serves humanity’s best interests, governments, companies, and researchers must engage in continuous public discourse, adapt  protections, and focus on ethical deployment of this powerful technology. Back to Mail Online home. back to the page you came from.  \"The Future of AI\" is publishedEducation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Siminarity score of 2 paragraphs"
      ],
      "metadata": {
        "id": "XiGkAYW43iTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load models\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Sentence splitter\n",
        "def split_sentences(text):\n",
        "    return [sent.text.strip() for sent in nlp(text).sents]\n",
        "\n",
        "# Similarity score based on sentence coverage\n",
        "def paragraph_similarity(para1, para2, threshold=0.5):\n",
        "    sents1 = split_sentences(para1)\n",
        "    sents2 = split_sentences(para2)\n",
        "\n",
        "    emb1 = model.encode(sents1, convert_to_tensor=True)\n",
        "    emb2 = model.encode(sents2, convert_to_tensor=True)\n",
        "\n",
        "    matched = 0\n",
        "    for i in range(len(sents2)):\n",
        "        sims = util.cos_sim(emb2[i], emb1)[0]\n",
        "        if sims.max().item() >= threshold:\n",
        "            matched += 1\n",
        "\n",
        "    coverage = matched / len(sents2) if sents2 else 0.0\n",
        "    return round(coverage, 3)\n",
        "\n",
        "# Example\n",
        "#para1 = \"\"\"FDA and USDA have responsibility for overseeing the safety of the food supply. General information about the process of making cell-cultured meat is available, but specific information about the technology being used and the eventual commercial production methods as well as the final products is not yet known. However, the technology and methods to commercially produce cell- cultured meat are still in development, and producers, regulators, and consumers do not yet have clarity on what these will entail. The composition of the final product is also not yet known. The general process for making cell-cultured meat contains five phases: biopsy, cell banking, growth, harvest, and food processing. The technology to produce cell-cultured meat at a commercial scale is still in development, and information about the methods to be used for commercial production and the composition of the final product are not yet known. Consequently, they have not finalized aspects of the technology and eventual commercial production methods to be used or the composition of the final product. As a result, certain information is not yet available to stakeholders\\u2014including cell-cultured meat firms themselves, regulators, and the public\\u2014about specific aspects of the technology and commercial production methods that will be used, such as the composition of the growth medium and of the final products. This lack of information results in unanswered questions about cell- cultured meat as it relates to the eventual technology and commercial production methods to be used and the composition of the final products. Some firms have developed prototypes of cell-cultured meat products as part of their research and development. In June 2019, FDA and USDA created three working groups to carry out the terms of the interagency agreement. FDA and USDA could more fully incorporate leading practices for collaboration in their interagency agreement and working groups. Developing and updating written guidance and agreements. However, the agreement does not describe how the agencies will track and monitor progress toward outcomes. Developing and updating written guidance and agreements. Developing and updating written guidance and agreements. Developing and updating written guidance and agreements. By more fully incorporating all seven leading practices for interagency collaboration early in the development of the three working groups, FDA and USDA could proactively minimize potential fragmentation and overlap in their oversight of cell-cultured meat, ensure consistency and efficient use of resources, and provide clarity to key stakeholders. While FDA and USDA officials told us they have decided who will oversee cell-cultured seafood, they have not formally announced or documented this decision, and some stakeholders have reported confusion or ambiguity about which agency will oversee cell-cultured seafood other than catfish. While FDA and USDA officials told us they had agreed that FDA would oversee cell-cultured seafood other than catfish, as of December 2019, the agencies had not formally announced or documented this agreement. Developing and updating written guidance and agreements is a leading practice for collaboration, as we have previously reported. Compounding this challenge is that specific information about key aspects of cell-cultured meat, such as the technology and production methods to be used as well as the composition of the products, is not yet known. FDA and USDA officials told us they have decided FDA will oversee most cell-cultured seafood, but the agencies have not formally documented this decision. We agree that the technology to produce cell-cultured meat is still in development and that information about the commercial production methods and composition of the final product are not yet known, as we state in our report. FDA concurred with two recommendations and partially concurred with one. USDA also concurred with two recommendations and partially concurred with one. FDA and USDA partially concurred with our recommendation, directed to each agency, to more fully incorporate the seven leading practices for effective collaboration into the agencies\\u2019 interagency agreement for the joint oversight of cell-cultured meat. We continue to believe that FDA and USDA should more fully incorporate the seven leading practices for effective collaboration into their interagency agreement for the joint oversight of cell-cultured meat. GAO staff who made key contributions to this report are listed in appendix V. Our report (1) describes what is known about methods for commercially producing cell-cultured meat and (2) examines the extent to which the Food and Drug Administration (FDA) and U.S. Department of Agriculture (USDA) are collaborating to provide regulatory oversight of cell-cultured meat. Developing and updating written guidance and agreements How will the collaborative mechanism be funded?\"\"\"\n",
        "#para2 = \"\"\"Multiple firms have produced cell-cultured meat as part of their research and development. These products appear likely to become available to consumers in coming years. FDA and USDA are the primary agencies responsible for overseeing the safety of the nation's food supply. However, some stakeholders have expressed concern about the agencies' oversight of cell-cultured meat amidst a fragmented federal food safety oversight system. GAO was asked to review federal oversight of cell-cultured meat. This report (1) describes what is known about methods for commercially producing cell-cultured meat, and (2) examines the extent to which FDA and USDA are collaborating to provide regulatory oversight of cell-cultured meat. GAO conducted a literature review; reviewed documentation from FDA, USDA, and stakeholder groups; analyzed public comments submitted to the agencies; compared agency efforts with leading practices for interagency collaboration; and conducted site visits to selected cell-cultured meat firms. General information about the process of making cell-cultured meat\\u2014food products grown from the cells of livestock, poultry, and seafood\\u2014is available. However, no company is commercially producing cell-cultured meat. Specific information about the technology being used, eventual commercial production methods, and composition of the final products is not yet known. The general process contains five phases: biopsy, cell banking, growth, harvest, and food processing (see figure). The technology and methods to be used for commercial production are still in development, and producers, regulators, and consumers do not have clarity about many specifics about the process and final product. For example, it is unclear whether production methods and products will use or contain genetically-engineered cells or medications such as antibiotics. The Food and Drug Administration (FDA) and U.S. Department of Agriculture (USDA) have begun collaborating on regulatory oversight of cell-cultured meat. For example, in 2019, the agencies signed an interagency agreement and created three working groups to carry out the terms of the agreement. However, the agreement and working groups could more fully incorporate practices to enhance and sustain collaboration, such as defining outcomes. For example, the agreement identifies the development of labeling principles as an outcome, but does not describe how the agencies will track and monitor progress toward this outcome, and the working groups identify a lead agency but not members' roles. Also, agency officials said they decided FDA would oversee cell-cultured seafood other than catfish, but they have not formally announced or documented this decision. Developing and updating written guidance and agreements is also a leading practice for interagency collaboration. By fully incorporating leading practices into their efforts to collaborate, the agencies could minimize potential overlap and fragmentation, use resources in a more efficient manner, and better ensure the public and other key stakeholders have clarity about the agencies' oversight responsibilities. GAO recommends that FDA and USDA more fully incorporate leading practices for effective collaboration in the agencies' interagency agreement. FDA and USDA partially concurred and indicated a willingness to incorporate these practices in a more detailed agreement, which would also meet the intent of the recommendations. The agencies concurred with the four other recommendations.\"\"\"\n",
        "\n",
        "similarity_score = paragraph_similarity(original_document, extractive_summary)\n",
        "print(f\"Coverage score: {similarity_score} (out of 1.0)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545,
          "referenced_widgets": [
            "2a2a80c8f5f24b90962dbc9cbdee1713",
            "c8e22cf02a634719a5bedb870cb20ecb",
            "a45f75ac71324ebb80d1d3d96a40398d",
            "f2bf11194a104f3c8c5054017390500d",
            "702500c637134c9e9df5bc8a95306cc2",
            "e0b28d81e2cd410aac01f4b501b13cd3",
            "1d16733b929c4099b9a3423e99fe9eaa",
            "da1188c015174efa9bcaf8f803b52eb1",
            "28abb456e6f647c88c0d9f4c7a1091c0",
            "dc9c0fcd3afc46d88e567a4c5d24b1a8",
            "7efce61a72fd46629cd1abb6e24f4a27",
            "9021a3d0c78d429290703e94154989b7",
            "1f2b247ebf07403bab441c0ea01be0fb",
            "9d004cac89b040c5a3e34709fa22dc30",
            "7bef30519b9c49678b1dd01ee7ed97d6",
            "edc76b4c2ec44cda8037cde790980ac7",
            "0b2c7af41f5241dcaabe405580c6170d",
            "f614eb3cbb6d447e9426429b70ae13bc",
            "79a4c90d209f421c9ee22bc7cd34aa63",
            "cfbad31101a84f7dae49aa4949b8730a",
            "d1d04eab10dd4c9c941dc31e8b2e71fc",
            "a83662f519484c0c81bd726dca3ad5e3",
            "ac17084f442f43e6b6962c0fcff4cedb",
            "b68ea7eb54654b4ab6fb1ac923343f8f",
            "de6c32f64a864198b3bebbd39e2d2c27",
            "9a2b72c991214a9195acdcdaa8265eb0",
            "103bb9066e2f45ac8847c1f08e894392",
            "a5cc8809c81c4b269b97e2eb7a307e5f",
            "705f391447c340b28bd645a81860cac2",
            "5a28860eb2654078ab93593a5548c24f",
            "74bb256ea84e4c49a8343658808cf6da",
            "7226b4c225cf44ecb5e3e0fe7bcaf2e8",
            "3c1233045e0f4f3fb79d2642dc8eb9c5",
            "597de5fbd5a74a50958c676d0785c36a",
            "fbcb4c6eee4c4bad904fb699b7fb2d22",
            "fa4d668a3a4f4f66b7daa93830e8c954",
            "2ca117a519bb480099b4ac9c2178ffe3",
            "bb39145ebf9d460e9c6649afd602295d",
            "35387b5e69c94a058bfcf5f2298e91e3",
            "b20f7d836f8c4fb481849ca6595ed051",
            "bbc4d6e6f024432f859b7d7da8f84326",
            "aadacd9902cc41f9b253be70677f387d",
            "52595b3febee4dfeac0cc7d795bdeeed",
            "ec1115c354714bc9a85e519130a87819",
            "243ea253c9784c4a85f16e4ecb1327f3",
            "29852302d7fa4143adcabb63cd4153f9",
            "96431934d9164993958a25a650c0b551",
            "9158e6d07adb431b9eeefb890dbc6eaf",
            "7924c2ba34424c37bfa004b79b00ad60",
            "dbe1fdd8109b4b07a3b82445f8f1198b",
            "9b4475e05cc140a882f13930d6499de7",
            "3221b016d18144e1bb2a7a1fccbafa99",
            "8479546eebc649a1b478b981a1fe407a",
            "02b5dfa4780544979e52f24da27231be",
            "c9dd868dcf694b87b335535a799b9f9e",
            "7423b50d8a0c43bba8d3a407818ccd16",
            "470062f4359041d09675d23b99939cc8",
            "df9f6a02402545a7a9f5d9864e165913",
            "5fa31f3c7a6d427fa55c639f3832eeb1",
            "d6829027fed647f89dfbd82192ca70f8",
            "cfbd8addb32b4bf6acc04fdbd6454fa2",
            "9e4441c234984f8f8f4ab305ae2ee649",
            "8d658399eaf64bac9c908a050ef9fbf6",
            "4ab5a57648324b24b5460a9c736b4eb2",
            "e8faf98a3a9746f48cdf03ceda15a2d8",
            "0efcf3b142e748e29d525b6e09e79b5f",
            "4fe26e542ca94404ad1449a9eb457daf",
            "5c621267a25547b4b71b5537ed0f5eab",
            "c3178c15bde643c79de03f957e38ea73",
            "0ff0cfb81f3348ceb6542e97fc949e40",
            "89915b778ee541e9b74dc7e182a453b0",
            "5382513ff2294cffa5a679d63effd9d0",
            "40b2770426df4be4a82e4071b5016c01",
            "774dccd0147e4a9f9426de2708e6b80d",
            "3aa263361282439aa17588a0939c4a88",
            "004bac3ab77e4638929e4349e1d3897d",
            "ed94bc2aaa7b44f2ac84cdf8b097708b",
            "46198efeae1446db9d916a02494aba71",
            "0c5c3ba0260e43ae8786c73f8fe828cc",
            "d757a69fb5874c2798d2e0866375ebc5",
            "234145d805a74e18aca5d5bc0200ca92",
            "cfd872b6677b4e84b8645a1bbd36d3fd",
            "1d550b0e77734027a12730e0cd82f3c3",
            "e1e779ff4a104c01a02ee206017d20c8",
            "f77ddced70384fa1aee3c1697323acb3",
            "49b0dce90c214651bfe7ed908f9334c3",
            "1be111dc9e6a4687bd023213eaf4401d",
            "4b28054ad3b946b284a63cb7f0e1801c",
            "39806386824b4bcfa8524156393f3e30",
            "aedb2acce2a544839e13081425428c94",
            "fe30a136718d41658aea61bd4a32457f",
            "18132abd0d88431bbd75796976ed5088",
            "ab4638198ad1489f9f1587780a0bae50",
            "0a472ed9504e40ffa296b460f872e86c",
            "032010fd90854101b2dd4d04b7f8c463",
            "6cb00e1d43814ed8aea3a83e0a82472c",
            "a207a3e49ab74056b64f26e96598e709",
            "0701c7e2439c4c84a56b3cb74aa4fc35",
            "0459ce2e0a1640a290c58dcbdfc6675e",
            "25a64562b8344f6a929897ba88c3ac34",
            "7a5516d48205446da4c7fa349e1a7719",
            "15f89fd7493b443ab80ffc65cb53ee3f",
            "5bfe6ea6905d42a8a1b7b4db48c0c065",
            "c0ce90230f544844be42bca62ec85de2",
            "a35dc2474e0341779b5283ed3f20ef5a",
            "b3e1a371dd7b4901a21dad711f85060b",
            "889718c99e7f4f85bea8ae84bfed7d79",
            "54e8b0da81b1458d893fc5487c0e4eff",
            "199bad31a51646efa4d9921cee8a4098",
            "db4146b184914f6bbe1f9d4efbcb3984",
            "a3568e1d33b44e6ca48d721e9184b491",
            "9c04c324e1cb42ea99a5b8a0d9fc98f6",
            "c441f1741ce8400ba11810c047101320",
            "24096a724d6d43ef803048e4924cfc12",
            "cf3106123ae44809905f14ea5990a64f",
            "1cd9c62238db4b4781f09e988c57e6c4",
            "d38817f5d37d4f0eafaacff84fd511b7",
            "82290315c28e47edac537cb78be8ce9b",
            "473c53521b3b4deca31b0830a41a62db",
            "964326f9e937431ca2aed4928f8f277c",
            "7e272f3412fe4dbdbd1adc3130dc8d07"
          ]
        },
        "id": "A_60cOQi3on-",
        "outputId": "f219334e-34cb-441b-fbac-b5fd243283f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a2a80c8f5f24b90962dbc9cbdee1713"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9021a3d0c78d429290703e94154989b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac17084f442f43e6b6962c0fcff4cedb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "597de5fbd5a74a50958c676d0785c36a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "243ea253c9784c4a85f16e4ecb1327f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7423b50d8a0c43bba8d3a407818ccd16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fe26e542ca94404ad1449a9eb457daf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46198efeae1446db9d916a02494aba71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39806386824b4bcfa8524156393f3e30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25a64562b8344f6a929897ba88c3ac34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3568e1d33b44e6ca48d721e9184b491"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage score: 1.0 (out of 1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "id": "_Ji-MroBaUW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentence similarity score with ROUGE, BERTscore,FACTcc"
      ],
      "metadata": {
        "id": "YmLt0ydL6P0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from rouge_score import rouge_scorer\n",
        "import bert_score\n",
        "\n",
        "# Load models\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Sentence splitter\n",
        "def split_sentences(text):\n",
        "    return [sent.text.strip() for sent in nlp(text).sents]\n",
        "\n",
        "# Coverage score\n",
        "def get_sentence_coverage(para1, para2, threshold=0.5):\n",
        "    sents1 = split_sentences(para1)\n",
        "    sents2 = split_sentences(para2)\n",
        "\n",
        "    emb1 = model.encode(sents1, convert_to_tensor=True)\n",
        "    emb2 = model.encode(sents2, convert_to_tensor=True)\n",
        "\n",
        "    matched = 0\n",
        "    for i in range(len(sents2)):\n",
        "        sims = util.cos_sim(emb2[i], emb1)[0]\n",
        "        if sims.max().item() >= threshold:\n",
        "            matched += 1\n",
        "\n",
        "    coverage = matched / len(sents2) if sents2 else 0.0\n",
        "    return round(coverage, 4)\n",
        "\n",
        "# ROUGE score\n",
        "def get_rouge_score(reference, candidate):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = scorer.score(reference, candidate)\n",
        "    return {\n",
        "        \"rouge1\": round(scores[\"rouge1\"].fmeasure, 4),\n",
        "        \"rouge2\": round(scores[\"rouge2\"].fmeasure, 4),\n",
        "        \"rougeL\": round(scores[\"rougeL\"].fmeasure, 4)\n",
        "    }\n",
        "\n",
        "# BERTScore\n",
        "def get_bert_score(reference, candidate, lang=\"en\"):\n",
        "    P, R, F1 = bert_score.score([candidate], [reference], lang=lang, verbose=False)\n",
        "    return {\n",
        "        \"bertscore_precision\": round(P[0].item(), 4),\n",
        "        \"bertscore_recall\": round(R[0].item(), 4),\n",
        "        \"bertscore_f1\": round(F1[0].item(), 4)\n",
        "    }\n",
        "\n",
        "# Combined comparison\n",
        "def compare_paragraphs(para1, para2):\n",
        "    scores = {\n",
        "        \"coverage_score\": get_sentence_coverage(para1, para2),\n",
        "        **get_rouge_score(para1, para2),\n",
        "        **get_bert_score(para1, para2)\n",
        "    }\n",
        "    return scores\n",
        "\n",
        "results = compare_paragraphs(rephrased_text, abstractive_summary)\n",
        "for k, v in results.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "scores = scorer.score(summary, abstractive_summary)\n",
        "print(\"ROUGE Recall:\", scores['rouge1'].recall)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "mCn_OdBe6fQi",
        "outputId": "28105977-ea70-42ba-b6f2-ff67c463fa10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'rouge_score'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1922707727.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrouge_score\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrouge_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbert_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rouge_score'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert_score"
      ],
      "metadata": {
        "id": "sj3sxGOJXHh_",
        "outputId": "987aeaea-e05d-46e4-96ab-0fcafc8a59cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.54.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.34.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.7.14)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert_score) (1.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m867.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert_score\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bert_score-0.3.13 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "e561d17ef4e14729ae979e912047e67e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#senetence level Rouge recall (not suitable for project"
      ],
      "metadata": {
        "id": "fIz3hc25Fw-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load models\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Function to split text into sentences\n",
        "def split_sentences(text):\n",
        "    return [sent.text.strip() for sent in nlp(text).sents if sent.text.strip()]\n",
        "\n",
        "# Function to compute sentence-level recall\n",
        "def sentence_level_recall(original_text, extractive_summary, threshold=0.75):\n",
        "    original_sents = split_sentences(original_text)\n",
        "    extractive_sents = split_sentences(extractive_summary)\n",
        "\n",
        "    if not original_sents or not extractive_sents:\n",
        "        return 0.0\n",
        "\n",
        "    emb_orig = model.encode(original_sents, convert_to_tensor=True)\n",
        "    emb_ext = model.encode(extractive_sents, convert_to_tensor=True)\n",
        "\n",
        "    matched = 0\n",
        "    for i in range(len(original_sents)):\n",
        "        sims = util.cos_sim(emb_orig[i], emb_ext)[0]\n",
        "        if sims.max().item() >= threshold:\n",
        "            matched += 1\n",
        "\n",
        "    recall = matched / len(original_sents)\n",
        "    return round(recall, 4)\n",
        "\n",
        "# Example usage\n",
        "#original_document = \"\"\"FDA and USDA are responsible for the safety of the food supply. They are overseeing the development of lab-grown meat. However, commercial methods are not finalized. Stakeholders lack clarity on technology, methods, and final products.\"\"\"\n",
        "#extractive_summary = \"\"\"FDA and USDA oversee food safety. They are monitoring lab-grown meat development. Final product composition is unclear.\"\"\"\n",
        "\n",
        "recall_score = sentence_level_recall(original_document, extractive_summary)\n",
        "print(f\"Sentence-level recall: {recall_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_h5BBjYF44s",
        "outputId": "f193da2e-40f1-4f0b-9061-5200dd9c73ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence-level recall: 0.2581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#QA based evaluation metric (Not suitable for our project)"
      ],
      "metadata": {
        "id": "mPPvu6wlILCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load models\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "qg_tokenizer = AutoTokenizer.from_pretrained(\"valhalla/t5-small-qg-hl\")\n",
        "qg_model = AutoModelForSeq2SeqLM.from_pretrained(\"valhalla/t5-small-qg-hl\")\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "qg_model = qg_model.to(device)\n",
        "\n",
        "# Sentence splitter\n",
        "def split_sentences(text):\n",
        "    return [sent.text.strip() for sent in nlp(text).sents if sent.text.strip()]\n",
        "\n",
        "# Chunk sentences to avoid token overflow\n",
        "def chunk_sentences(sentences, max_tokens=512):\n",
        "    chunks, current_chunk, token_count = [], [], 0\n",
        "    for sent in sentences:\n",
        "        sent_tokens = len(qg_tokenizer.tokenize(sent))\n",
        "        if token_count + sent_tokens <= max_tokens:\n",
        "            current_chunk.append(sent)\n",
        "            token_count += sent_tokens\n",
        "        else:\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk)\n",
        "            current_chunk = [sent]\n",
        "            token_count = sent_tokens\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk)\n",
        "    return chunks\n",
        "\n",
        "# Generate QA from a single chunk\n",
        "def generate_qas_from_chunk(chunk_sentences):\n",
        "    qas = []\n",
        "    for sent in tqdm(chunk_sentences, desc=\"Generating QA pairs\"):\n",
        "        input_text = f\"generate question: {sent} </s>\"\n",
        "        inputs = qg_tokenizer(input_text, return_tensors=\"pt\", truncation=True).to(device)\n",
        "        outputs = qg_model.generate(**inputs, max_length=64)\n",
        "        question = qg_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        qas.append({\"question\": question, \"answer\": sent})\n",
        "    return qas\n",
        "\n",
        "# Deduplicate questions\n",
        "def deduplicate_qas(qas):\n",
        "    seen = set()\n",
        "    unique_qas = []\n",
        "    for qa in qas:\n",
        "        q = qa[\"question\"].strip().lower()\n",
        "        if q not in seen:\n",
        "            seen.add(q)\n",
        "            unique_qas.append(qa)\n",
        "    return unique_qas\n",
        "\n",
        "# Rank questions by importance of answer sentences\n",
        "def rank_questions_by_importance(qas, full_text, top_k=10):\n",
        "    doc_embedding = embedding_model.encode(full_text, convert_to_tensor=True)\n",
        "    scores = []\n",
        "    for qa in qas:\n",
        "        ans_embedding = embedding_model.encode(qa[\"answer\"], convert_to_tensor=True)\n",
        "        score = float(util.cos_sim(ans_embedding, doc_embedding))\n",
        "        scores.append((score, qa))\n",
        "    top_qas = sorted(scores, key=lambda x: x[0], reverse=True)[:top_k]\n",
        "    return [qa for _, qa in top_qas]\n",
        "\n",
        "# Full pipeline\n",
        "def generate_top_questions(text, top_k=10):\n",
        "    sentences = split_sentences(text)\n",
        "    chunks = chunk_sentences(sentences)\n",
        "    all_qas = []\n",
        "    for chunk in chunks:\n",
        "        qas = generate_qas_from_chunk(chunk)\n",
        "        all_qas.extend(qas)\n",
        "    deduped = deduplicate_qas(all_qas)\n",
        "    ranked = rank_questions_by_importance(deduped, text, top_k=top_k)\n",
        "    return ranked\n",
        "\n",
        "# Example usage\n",
        "# original_document = \"your long document string here\"\n",
        "qa_pairs = generate_top_questions(extractive_summary, top_k=10)\n",
        "\n",
        "# Print top 10 important QA pairs\n",
        "for i, qa in enumerate(qa_pairs, 1):\n",
        "    print(f\"{i}. Q: {qa['question']}\\n   A: {qa['answer']}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E4My2EiO_-s",
        "outputId": "f9689494-e328-401a-8a3a-184b4ce1c0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating QA pairs: 100%|██████████| 18/18 [00:13<00:00,  1.34it/s]\n",
            "Generating QA pairs: 100%|██████████| 12/12 [00:06<00:00,  1.98it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Q: What is the name of the meat that is produced at a commercial scale?\n",
            "   A: The technology to produce cell-cultured meat at a commercial scale is still in development, and information about the methods to be used for commercial production and the composition of the final product are not yet known.\n",
            "\n",
            "2. Q: What is the name of the meat that is still in development?\n",
            "   A: We agree that the technology to produce cell-cultured meat is still in development and that information about the commercial production methods and composition of the final product are not yet known, as we state in our report.\n",
            "\n",
            "3. Q: What is the process for making cell-cultured meat?\n",
            "   A: The general process for making cell-cultured meat contains five phases: biopsy, cell banking, growth, harvest, and food processing.\n",
            "\n",
            "4. Q: What is not known about the process of making cell-cultured meat?\n",
            "   A: General information about the process of making cell-cultured meat is available, but specific information about the technology being used and the eventual commercial production methods as well as the final products is not yet known.\n",
            "\n",
            "5. Q: What is the main reason for the lack of information about cell cultured meat?\n",
            "   A: This lack of information results in unanswered questions about cell- cultured meat as it relates to the eventual technology and commercial production methods to be used and the composition of the final products.\n",
            "\n",
            "6. Q: What is the main problem with cell-cultured meat?\n",
            "   A: Compounding this challenge is that specific information about key aspects of cell-cultured meat, such as the technology and production methods to be used as well as the composition of the products, is not yet known.\n",
            "\n",
            "7. Q: What is the main reason for the lack of information about the technology and commercial production methods?\n",
            "   A: As a result, certain information is not yet available to stakeholders—including cell-cultured meat firms themselves, regulators, and the public—about specific aspects of the technology and commercial production methods that will be used, such as the composition of the growth medium and of the final products.\n",
            "\n",
            "8. Q: What is the main reason for the development of cell cultured meat?\n",
            "   A: However, the technology and methods to commercially produce cell- cultured meat are still in development, and producers, regulators, and consumers do not yet have clarity on what these will entail.\n",
            "\n",
            "9. Q: What is the name of the company that developed prototypes of cell-cultured meat products?\n",
            "   A: Some firms have developed prototypes of cell-cultured meat products as part of their research and development.\n",
            "\n",
            "10. Q: What is the name of the report that GAO staff contributed to?\n",
            "   A: GAO staff who made key contributions to this report are listed in appendix V. Our report (1) describes what is known about methods for commercially producing cell-cultured meat and (2) examines the extent to which the Food and Drug Administration (FDA) and U.S. Department of Agriculture (USDA) are collaborating to provide regulatory oversight of cell-cultured meat.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "#!pip install transformers rouge-score sentence-transformers --quiet\n",
        "\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Load models\n",
        "qa_model = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "# --- Sample Inputs ---\n",
        "#extractive_summary = \"\"\"FDA and USDA are the two major regulatory bodies overseeing the safety of food products, including cell-cultured meat. These meats are produced from animal cells without slaughtering livestock. In June 2019, FDA and USDA signed an agreement to collaborate on regulating this industry.\"\"\"\n",
        "extractive_summary=extractive_summary\n",
        "qa_pairs = qa_pairs\n",
        "\n",
        "\n",
        "# --- Evaluation ---\n",
        "def evaluate_qa(extractive_summary, qa_pairs):\n",
        "    total = len(qa_pairs)\n",
        "    rouge_scores = []\n",
        "    semantic_scores = []\n",
        "\n",
        "    for pair in qa_pairs:\n",
        "        try:\n",
        "            pred = qa_model(question=pair['question'], context=extractive_summary)\n",
        "            predicted_answer = pred['answer'].strip()\n",
        "\n",
        "            # ROUGE\n",
        "            r_score = rouge.score(pair['answer'], predicted_answer)['rougeL'].fmeasure\n",
        "            rouge_scores.append(r_score)\n",
        "\n",
        "            # Semantic similarity\n",
        "            emb_gt = semantic_model.encode(pair['answer'], convert_to_tensor=True)\n",
        "            emb_pred = semantic_model.encode(predicted_answer, convert_to_tensor=True)\n",
        "            sem_sim = util.cos_sim(emb_gt, emb_pred).item()\n",
        "            semantic_scores.append(sem_sim)\n",
        "\n",
        "            print(f\"Q: {pair['question']}\")\n",
        "            print(f\"GT: {pair['answer']} | Pred: {predicted_answer}\")\n",
        "            print(f\"→ ROUGE-L: {r_score:.4f} | BERTSim: {sem_sim:.4f}\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Failed on: {pair['question']}\\n{e}\\n\")\n",
        "\n",
        "    print(\"=== Overall Evaluation ===\")\n",
        "    print(f\"Avg ROUGE-L: {sum(rouge_scores)/total:.4f}\")\n",
        "    print(f\"Avg Semantic Similarity: {sum(semantic_scores)/total:.4f}\")\n",
        "\n",
        "# --- Run Evaluation ---\n",
        "evaluate_qa(abstractive_summary, qa_pairs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAqLCNJHK1Z5",
        "outputId": "43880dc9-0d00-4334-8cd3-6864a60dff41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What is the name of the meat that is produced at a commercial scale?\n",
            "GT: The technology to produce cell-cultured meat at a commercial scale is still in development, and information about the methods to be used for commercial production and the composition of the final product are not yet known. | Pred: cell-cultured meat\n",
            "→ ROUGE-L: 0.1500 | BERTSim: 0.7800\n",
            "\n",
            "Q: What is the name of the meat that is still in development?\n",
            "GT: We agree that the technology to produce cell-cultured meat is still in development and that information about the commercial production methods and composition of the final product are not yet known, as we state in our report. | Pred: catfish\n",
            "→ ROUGE-L: 0.0000 | BERTSim: 0.0852\n",
            "\n",
            "Q: What is the process for making cell-cultured meat?\n",
            "GT: The general process for making cell-cultured meat contains five phases: biopsy, cell banking, growth, harvest, and food processing. | Pred: interagency collaboration\n",
            "→ ROUGE-L: 0.0000 | BERTSim: 0.0370\n",
            "\n",
            "Q: What is not known about the process of making cell-cultured meat?\n",
            "GT: General information about the process of making cell-cultured meat is available, but specific information about the technology being used and the eventual commercial production methods as well as the final products is not yet known. | Pred: members' roles\n",
            "→ ROUGE-L: 0.0000 | BERTSim: -0.0216\n",
            "\n",
            "Q: What is the main reason for the lack of information about cell cultured meat?\n",
            "GT: This lack of information results in unanswered questions about cell- cultured meat as it relates to the eventual technology and commercial production methods to be used and the composition of the final products. | Pred: fragmented federal food safety oversight system\n",
            "→ ROUGE-L: 0.0000 | BERTSim: 0.2486\n",
            "\n",
            "Q: What is the main problem with cell-cultured meat?\n",
            "GT: Compounding this challenge is that specific information about key aspects of cell-cultured meat, such as the technology and production methods to be used as well as the composition of the products, is not yet known. | Pred: catfish\n",
            "→ ROUGE-L: 0.0000 | BERTSim: 0.1404\n",
            "\n",
            "Q: What is the main reason for the lack of information about the technology and commercial production methods?\n",
            "GT: As a result, certain information is not yet available to stakeholders—including cell-cultured meat firms themselves, regulators, and the public—about specific aspects of the technology and commercial production methods that will be used, such as the composition of the growth medium and of the final products. | Pred: the agencies could minimize potential overlap and fragmentation\n",
            "→ ROUGE-L: 0.0714 | BERTSim: 0.1684\n",
            "\n",
            "Q: What is the main reason for the development of cell cultured meat?\n",
            "GT: However, the technology and methods to commercially produce cell- cultured meat are still in development, and producers, regulators, and consumers do not yet have clarity on what these will entail. | Pred: oversight\n",
            "→ ROUGE-L: 0.0000 | BERTSim: 0.0541\n",
            "\n",
            "Q: What is the name of the company that developed prototypes of cell-cultured meat products?\n",
            "GT: Some firms have developed prototypes of cell-cultured meat products as part of their research and development. | Pred: FDA\n",
            "→ ROUGE-L: 0.0000 | BERTSim: 0.2451\n",
            "\n",
            "Q: What is the name of the report that GAO staff contributed to?\n",
            "GT: GAO staff who made key contributions to this report are listed in appendix V. Our report (1) describes what is known about methods for commercially producing cell-cultured meat and (2) examines the extent to which the Food and Drug Administration (FDA) and U.S. Department of Agriculture (USDA) are collaborating to provide regulatory oversight of cell-cultured meat. | Pred: (1)\n",
            "→ ROUGE-L: 0.0333 | BERTSim: 0.1019\n",
            "\n",
            "=== Overall Evaluation ===\n",
            "Avg ROUGE-L: 0.0255\n",
            "Avg Semantic Similarity: 0.1839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Factual consistency metric - Entailment based evaluation using roberta-large-mnli"
      ],
      "metadata": {
        "id": "xy_fZ4HTaPXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Setup and Imports ---\n",
        "# Make sure you have these installed:\n",
        "# pip install transformers torch spacy\n",
        "# python -m spacy download en_core_web_sm\n",
        "\n",
        "import spacy\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from scipy.special import softmax # Used to convert raw model outputs into probabilities\n",
        "import numpy as np\n",
        "\n",
        "# Load spaCy model for sentence segmentation globally once\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    # This block handles the case where the spaCy model isn't downloaded yet.\n",
        "    # It attempts to download it automatically.\n",
        "    print(\"SpaCy model 'en_core_web_sm' not found. Downloading it...\")\n",
        "    spacy.cli.download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# --- 2. Load Pre-trained NLI Model Globally Once ---\n",
        "# This is the most critical part: loading the NLI model from Hugging Face.\n",
        "# 'roberta-large-mnli' is a powerful NLI model.\n",
        "nli_model_name = \"roberta-large-mnli\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(nli_model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(nli_model_name)\n",
        "\n",
        "# Ensure the model uses the GPU if available for faster processing.\n",
        "# If no GPU, it defaults to CPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval() # Set the model to evaluation mode (important for inference)\n",
        "\n",
        "# This map defines how the model's numerical output labels (0, 1, 2)\n",
        "# correspond to the NLI relationships (contradiction, entailment, neutral).\n",
        "# This order is standard for MNLI models.\n",
        "label_map = {0: \"contradiction\", 1: \"entailment\", 2: \"neutral\"}\n",
        "\n",
        "\n",
        "# --- 3. Helper Function for NLI Prediction ---\n",
        "\n",
        "def get_nli_prediction(premise: str, hypothesis: str) -> dict:\n",
        "    \"\"\"\n",
        "    Performs Natural Language Inference (NLI) using the loaded model.\n",
        "    It takes a premise (source text) and a hypothesis (summary sentence)\n",
        "    and predicts their relationship (entailment, contradiction, neutral).\n",
        "    Includes a warning if the input is truncated.\n",
        "    \"\"\"\n",
        "    # Tokenize the premise and hypothesis separately to get their individual lengths\n",
        "    premise_tokens = tokenizer.tokenize(premise)\n",
        "    hypothesis_tokens = tokenizer.tokenize(hypothesis)\n",
        "\n",
        "    # Calculate total length needed for both, plus special tokens (CLS, SEP, SEP)\n",
        "    # The actual number of special tokens depends on the tokenizer and task,\n",
        "    # but 3 is typical for [CLS] premise [SEP] hypothesis [SEP].\n",
        "    required_length = len(premise_tokens) + len(hypothesis_tokens) + tokenizer.num_special_tokens_to_add(pair=True) # More robust way\n",
        "\n",
        "    truncated_warning = False\n",
        "    if required_length > 512: # Check against the model's max_length\n",
        "        truncated_warning = True\n",
        "\n",
        "    try:\n",
        "        # Tokenize and prepare inputs for the NLI model.\n",
        "        # max_length=512 is the typical limit for BERT/RoBERTa models.\n",
        "        # truncation=True ensures inputs are cut if too long.\n",
        "        inputs = tokenizer.encode_plus(\n",
        "            premise,\n",
        "            hypothesis,\n",
        "            add_special_tokens=True,\n",
        "            max_length=512,\n",
        "            truncation=True, # This will trigger the truncation if needed\n",
        "            return_tensors='pt' # Return PyTorch tensors\n",
        "        )\n",
        "        # Move inputs to the same device as the model (CPU/GPU)\n",
        "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "        with torch.no_grad(): # Disable gradient calculation for faster inference\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits # Raw output scores from the model\n",
        "            # Convert logits to probabilities using softmax\n",
        "            scores = softmax(logits.cpu().numpy(), axis=1)[0]\n",
        "\n",
        "        # Get the label with the highest probability\n",
        "        predicted_label_id = np.argmax(scores)\n",
        "        predicted_label = label_map[predicted_label_id]\n",
        "        confidence_score = scores[predicted_label_id]\n",
        "\n",
        "        return {\n",
        "            \"label\": predicted_label,\n",
        "            \"score\": float(confidence_score),\n",
        "            \"truncated\": truncated_warning # Add the warning flag to the result\n",
        "        }\n",
        "    except Exception as e:\n",
        "        # Error handling for potential issues during prediction\n",
        "        print(f\"Warning: Error during NLI prediction for hypothesis '{hypothesis[:50]}...': {e}\")\n",
        "        return {\"label\": \"error\", \"score\": 0.0, \"truncated\": False} # Default to False on error\n",
        "\n",
        "# --- 4. Main Evaluation Function ---\n",
        "\n",
        "def evaluate_summary_nli(source_document: str, abstractive_summary: str) -> dict:\n",
        "    \"\"\"\n",
        "    Evaluates factual consistency of an abstractive summary against a source document\n",
        "    using an NLI model.\n",
        "    Each sentence in the summary is treated as a hypothesis, and the\n",
        "    entire source document serves as the premise.\n",
        "\n",
        "    Args:\n",
        "        source_document: The full original text (premise for NLI).\n",
        "        abstractive_summary: The generated summary (sentences are hypotheses).\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing metrics (consistency, contradiction, neutrality rates)\n",
        "        and detailed NLI results for each summary sentence.\n",
        "        Returns empty metrics if the summary is empty.\n",
        "    \"\"\"\n",
        "    # 1. Segment summary into sentences using spaCy.\n",
        "    # .strip() removes leading/trailing whitespace, and the filter removes empty sentences.\n",
        "    summary_sentences = [sent.text.strip() for sent in nlp(abstractive_summary).sents if sent.text.strip()]\n",
        "\n",
        "    if not summary_sentences:\n",
        "        print(\"Warning: Summary is empty or contains no valid sentences. Returning empty metrics.\")\n",
        "        return {\n",
        "            \"metrics\": {\n",
        "                \"consistency_rate\": 0.0,\n",
        "                \"contradiction_rate\": 0.0,\n",
        "                \"neutrality_rate\": 0.0,\n",
        "                \"total_sentences\": 0\n",
        "            },\n",
        "            \"details\": []\n",
        "        }\n",
        "\n",
        "    nli_results = []\n",
        "    consistency_count = 0\n",
        "    contradiction_count = 0\n",
        "    neutral_count = 0\n",
        "    error_count = 0\n",
        "    truncated_count = 0 # New counter for truncated inputs\n",
        "\n",
        "    # Print progress for long processes\n",
        "    print(f\"Evaluating {len(summary_sentences)} summary sentences...\")\n",
        "\n",
        "    for i, hypothesis in enumerate(summary_sentences):\n",
        "        # Print progress for long summaries\n",
        "        print(f\"Processing sentence {i+1}/{len(summary_sentences)}: '{hypothesis[:70]}...'\")\n",
        "        result = get_nli_prediction(source_document, hypothesis)\n",
        "        nli_results.append({\n",
        "            \"summary_sentence\": hypothesis,\n",
        "            \"nli_label\": result[\"label\"],\n",
        "            \"nli_score\": result[\"score\"],\n",
        "            \"truncated\": result[\"truncated\"] # Add truncated info to details\n",
        "        })\n",
        "\n",
        "        # Count occurrences of each NLI label.\n",
        "        if result[\"label\"] == \"entailment\":\n",
        "            consistency_count += 1\n",
        "        elif result[\"label\"] == \"contradiction\":\n",
        "            contradiction_count += 1\n",
        "        elif result[\"label\"] == \"neutral\":\n",
        "            neutral_count += 1\n",
        "        else: # Account for any errors during prediction\n",
        "            error_count += 1\n",
        "\n",
        "        if result[\"truncated\"]: # Increment truncated count\n",
        "            truncated_count += 1\n",
        "\n",
        "    total_sentences = len(summary_sentences)\n",
        "    # Calculate rates for each NLI category.\n",
        "    consistency_rate = consistency_count / total_sentences if total_sentences > 0 else 0\n",
        "    contradiction_rate = contradiction_count / total_sentences if total_sentences > 0 else 0\n",
        "    neutrality_rate = neutral_count / total_sentences if total_sentences > 0 else 0\n",
        "\n",
        "    # Print summary of results, including truncation warning\n",
        "    print(\"\\n--- NLI Evaluation Summary ---\")\n",
        "    print(f\"Total Summary Sentences: {total_sentences}\")\n",
        "    print(f\"Entailment (Consistent): {consistency_count} ({consistency_rate:.2%})\")\n",
        "    print(f\"Contradiction (Hallucinated): {contradiction_count} ({contradiction_rate:.2%})\")\n",
        "    print(f\"Neutral (Unsupported/Potential Hallucination): {neutral_count} ({neutrality_rate:.2%})\")\n",
        "    if error_count > 0:\n",
        "        print(f\"Errors during NLI processing: {error_count}\")\n",
        "    if truncated_count > 0:\n",
        "        print(f\"WARNING: {truncated_count} out of {total_sentences} sentences had their source document truncated during NLI input preparation (premise + hypothesis exceeded 512 tokens). This might affect accuracy, especially for 'Neutral' labels.\")\n",
        "\n",
        "\n",
        "    # Return the aggregated metrics and detailed results.\n",
        "    return {\n",
        "        \"metrics\": {\n",
        "            \"consistency_rate\": consistency_rate,\n",
        "            \"contradiction_rate\": contradiction_rate,\n",
        "            \"neutrality_rate\": neutrality_rate,\n",
        "            \"total_sentences\": total_sentences,\n",
        "            \"truncated_inputs_count\": truncated_count # Add this to metrics for easy access\n",
        "        },\n",
        "        \"details\": nli_results\n",
        "    }\n",
        "\n",
        "# How to use these functions in your project:\n",
        "# from your_module_name import evaluate_summary_nli\n",
        "#\n",
        "#source_text = \"Your long source document content goes here.\"\n",
        "# generated_summary = \"The abstractive summary generated by your model.\"\n",
        "#\n",
        "nli_evaluation_results = evaluate_summary_nli(summary, abstractive_summary+\"Cell cultured meat is bad for health according to scientists.\")\n",
        "#\n",
        "# # Access the metrics:\n",
        "# print(f\"Consistency Rate: {nli_evaluation_results['metrics']['consistency_rate']:.4f}\")\n",
        "# print(f\"Contradiction Rate: {nli_evaluation_results['metrics']['contradiction_rate']:.4f}\")\n",
        "# print(f\"Neutrality Rate: {nli_evaluation_results['metrics']['neutrality_rate']:.4f}\")\n",
        "# if nli_evaluation_results['metrics']['truncated_inputs_count'] > 0:\n",
        "#     print(f\"Warning: {nli_evaluation_results['metrics']['truncated_inputs_count']} inputs were truncated.\")\n",
        "#\n",
        "# # Access detailed results for each sentence, including truncation info:\n",
        "# for item in nli_evaluation_results['details']:\n",
        "#     print(f\"Summary Sentence: {item['summary_sentence']}\")\n",
        "#     print(f\"  NLI Label: {item['nli_label']} (Score: {item['nli_score']:.2f})\")\n",
        "#     if item['truncated']:\n",
        "#         print(\"  NOTE: This input was truncated.\")\n",
        "#     print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5_PFrg7f53E",
        "outputId": "affbfe75-fdbe-48ea-b818-28a152d9d619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating 24 summary sentences...\n",
            "Processing sentence 1/24: 'Multiple firms have produced cell-cultured meat as part of their resea...'\n",
            "Processing sentence 2/24: 'These products appear likely to become available to consumers in comin...'\n",
            "Processing sentence 3/24: 'FDA and USDA are the primary agencies responsible for overseeing the s...'\n",
            "Processing sentence 4/24: 'However, some stakeholders have expressed concern about the agencies' ...'\n",
            "Processing sentence 5/24: 'GAO was asked to review federal oversight of cell-cultured meat....'\n",
            "Processing sentence 6/24: 'This report (1) describes what is known about methods for commercially...'\n",
            "Processing sentence 7/24: 'GAO conducted a literature review; reviewed documentation from FDA, US...'\n",
            "Processing sentence 8/24: 'General information about the process of making cell-cultured meat—foo...'\n",
            "Processing sentence 9/24: 'However, no company is commercially producing cell-cultured meat....'\n",
            "Processing sentence 10/24: 'Specific information about the technology being used, eventual commerc...'\n",
            "Processing sentence 11/24: 'The general process contains five phases: biopsy, cell banking, growth...'\n",
            "Processing sentence 12/24: 'The technology and methods to be used for commercial production are st...'\n",
            "Processing sentence 13/24: 'For example, it is unclear whether production methods and products wil...'\n",
            "Processing sentence 14/24: 'The Food and Drug Administration (FDA) and U.S. Department of Agricult...'\n",
            "Processing sentence 15/24: 'For example, in 2019, the agencies signed an interagency agreement and...'\n",
            "Processing sentence 16/24: 'However, the agreement and working groups could more fully incorporate...'\n",
            "Processing sentence 17/24: 'For example, the agreement identifies the development of labeling prin...'\n",
            "Processing sentence 18/24: 'Also, agency officials said they decided FDA would oversee cell-cultur...'\n",
            "Processing sentence 19/24: 'Developing and updating written guidance and agreements is also a lead...'\n",
            "Processing sentence 20/24: 'By fully incorporating leading practices into their efforts to collabo...'\n",
            "Processing sentence 21/24: 'GAO recommends that FDA and USDA more fully incorporate leading practi...'\n",
            "Processing sentence 22/24: 'FDA and USDA partially concurred and indicated a willingness to incorp...'\n",
            "Processing sentence 23/24: 'The agencies concurred with the four other recommendations....'\n",
            "Processing sentence 24/24: 'Cell cultured meat is bad for health according to scientists....'\n",
            "\n",
            "--- NLI Evaluation Summary ---\n",
            "Total Summary Sentences: 24\n",
            "Entailment (Consistent): 23 (95.83%)\n",
            "Contradiction (Hallucinated): 1 (4.17%)\n",
            "Neutral (Unsupported/Potential Hallucination): 0 (0.00%)\n",
            "WARNING: 24 out of 24 sentences had their source document truncated during NLI input preparation (premise + hypothesis exceeded 512 tokens). This might affect accuracy, especially for 'Neutral' labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Factual consistency metric - Entailment based evaluation using roberta-large-mnli ( eliminating truncation problem of 512 tokens"
      ],
      "metadata": {
        "id": "ec3vJdH0FiP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Setup and Imports ---\n",
        "# Make sure you have these installed:\n",
        "# pip install transformers torch spacy sentence-transformers\n",
        "# python -m spacy download en_core_web_sm\n",
        "\n",
        "import spacy\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from scipy.special import softmax # Used to convert raw model outputs into probabilities\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util # NEW: for semantic retrieval\n",
        "\n",
        "# Load spaCy model for sentence segmentation globally once\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    # This block handles the case where the spaCy model isn't downloaded yet.\n",
        "    # It attempts to download it automatically.\n",
        "    print(\"SpaCy model 'en_core_web_sm' not found. Downloading it...\")\n",
        "    spacy.cli.download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# --- 2. Load Pre-trained NLI Model Globally Once ---\n",
        "# This is the most critical part: loading the NLI model from Hugging Face.\n",
        "# 'roberta-large-mnli' is a powerful NLI model.\n",
        "nli_model_name = \"roberta-large-mnli\"\n",
        "nli_tokenizer = AutoTokenizer.from_pretrained(nli_model_name) # Renamed to nli_tokenizer\n",
        "nli_model = AutoModelForSequenceClassification.from_pretrained(nli_model_name) # Renamed to nli_model\n",
        "\n",
        "# NEW: Load Sentence Transformer Model for semantic similarity\n",
        "embedding_model_name = 'all-MiniLM-L6-v2' # Good balance of speed and performance.\n",
        "embedding_model = SentenceTransformer(embedding_model_name)\n",
        "\n",
        "# Ensure the models use the GPU if available for faster processing.\n",
        "# If no GPU, it defaults to CPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "nli_model.to(device)\n",
        "embedding_model.to(device) # Move embedding model to device\n",
        "nli_model.eval() # Set the model to evaluation mode (important for inference)\n",
        "embedding_model.eval() # Set embedding model to evaluation mode\n",
        "\n",
        "# This map defines how the model's numerical output labels (0, 1, 2)\n",
        "# correspond to the NLI relationships (contradiction, entailment, neutral).\n",
        "# This order is standard for MNLI models.\n",
        "label_map = {0: \"contradiction\", 1: \"entailment\", 2: \"neutral\"}\n",
        "\n",
        "# Configuration for retrieval and re-evaluation:\n",
        "NUM_RETRIEVED_CHUNKS = 5 # Number of top similar sentences to retrieve in the first pass\n",
        "HARD_CHUNK_SIZE_TOKENS = 400 # Token size for brute-force chunking in the second pass\n",
        "\n",
        "# --- 3. Helper Functions ---\n",
        "# (Modified get_nli_prediction, and added chunk_document_by_sentences, chunk_text_by_tokens, retrieve_relevant_chunks)\n",
        "\n",
        "def chunk_document_by_sentences(document: str) -> list[str]:\n",
        "    \"\"\"Splits a document into a list of sentences.\"\"\"\n",
        "    return [sent.text.strip() for sent in nlp(document).sents if sent.text.strip()]\n",
        "\n",
        "def chunk_text_by_tokens(text: str, max_chunk_tokens: int, overlap: int = 50) -> list[str]:\n",
        "    \"\"\"\n",
        "    Splits a long text into chunks of a maximum token size with optional overlap.\n",
        "    Useful for brute-force checking.\n",
        "    \"\"\"\n",
        "    tokenized_text = nli_tokenizer.encode(text, add_special_tokens=False)\n",
        "    chunks = []\n",
        "    start_index = 0\n",
        "    while start_index < len(tokenized_text):\n",
        "        end_index = min(start_index + max_chunk_tokens, len(tokenized_text))\n",
        "        chunk_tokens = tokenized_text[start_index:end_index]\n",
        "        chunk_text = nli_tokenizer.decode(chunk_tokens, skip_special_tokens=True)\n",
        "        chunks.append(chunk_text)\n",
        "        if end_index == len(tokenized_text):\n",
        "            break\n",
        "        start_index += max_chunk_tokens - overlap # Move to the next chunk with overlap\n",
        "    return chunks\n",
        "\n",
        "def retrieve_relevant_chunks(\n",
        "    summary_sentence: str,\n",
        "    source_sentences: list[str],\n",
        "    num_chunks: int = NUM_RETRIEVED_CHUNKS\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Retrieves the most semantically relevant chunks (sentences) from the source\n",
        "    document for a given summary sentence.\n",
        "    \"\"\"\n",
        "    if not source_sentences:\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        summary_embedding = embedding_model.encode(summary_sentence, convert_to_tensor=True, device=device)\n",
        "        source_embeddings = embedding_model.encode(source_sentences, convert_to_tensor=True, device=device)\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Warning: Sentence embedding failed, likely due to device memory. Falling back to CPU. Error: {e}\")\n",
        "        summary_embedding = embedding_model.encode(summary_sentence, convert_to_tensor=True, device='cpu')\n",
        "        source_embeddings = embedding_model.encode(source_sentences, convert_to_tensor=True, device='cpu')\n",
        "\n",
        "\n",
        "    # Calculate cosine similarities\n",
        "    cosine_scores = util.cos_sim(summary_embedding, source_embeddings)[0]\n",
        "\n",
        "    # Get the indices of the top N most similar source sentences\n",
        "    top_results_indices = torch.topk(cosine_scores, k=min(num_chunks, len(source_sentences)))[1].cpu().numpy()\n",
        "\n",
        "    # Concatenate the retrieved sentences to form the premise\n",
        "    # Sort indices to maintain original document order for retrieved chunks, which can be important for NLI\n",
        "    top_results_indices.sort()\n",
        "    retrieved_premise = \" \".join([source_sentences[i] for i in top_results_indices])\n",
        "\n",
        "    return retrieved_premise\n",
        "\n",
        "def get_nli_prediction(premise: str, hypothesis: str) -> dict:\n",
        "    \"\"\"\n",
        "    Performs Natural Language Inference (NLI) using the loaded model.\n",
        "    It takes a premise (source text) and a hypothesis (summary sentence)\n",
        "    and predicts their relationship (entailment, contradiction, neutral).\n",
        "    Includes a warning if the input is truncated.\n",
        "    \"\"\"\n",
        "    truncated_warning = False\n",
        "    # Check if combined length might exceed model's max_length\n",
        "    # Rough estimate to trigger warning early based on tokenization\n",
        "    # More robust check is inside tokenizer.encode_plus (truncation=True)\n",
        "    if len(nli_tokenizer.tokenize(premise)) + len(nli_tokenizer.tokenize(hypothesis)) + nli_tokenizer.num_special_tokens_to_add(pair=True) > nli_tokenizer.model_max_length:\n",
        "         truncated_warning = True\n",
        "\n",
        "    try:\n",
        "        # Tokenize and prepare inputs for the NLI model.\n",
        "        inputs = nli_tokenizer.encode_plus( # Using nli_tokenizer\n",
        "            premise,\n",
        "            hypothesis,\n",
        "            add_special_tokens=True,\n",
        "            max_length=nli_tokenizer.model_max_length, # Using nli_tokenizer's max_length property (typically 512)\n",
        "            truncation=True, # This will trigger the truncation if needed\n",
        "            return_tensors='pt' # Return PyTorch tensors\n",
        "        )\n",
        "        # Move inputs to the same device as the model (CPU/GPU)\n",
        "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "        with torch.no_grad(): # Disable gradient calculation for faster inference\n",
        "            outputs = nli_model(**inputs) # Using nli_model\n",
        "            logits = outputs.logits # Raw output scores from the model\n",
        "            # Convert logits to probabilities using softmax\n",
        "            scores = softmax(logits.cpu().numpy(), axis=1)[0]\n",
        "\n",
        "        # Get the label with the highest probability\n",
        "        predicted_label_id = np.argmax(scores)\n",
        "        predicted_label = label_map[predicted_label_id]\n",
        "        confidence_score = scores[predicted_label_id]\n",
        "\n",
        "        return {\n",
        "            \"label\": predicted_label,\n",
        "            \"score\": float(confidence_score),\n",
        "            \"truncated\": truncated_warning # Add the warning flag to the result\n",
        "        }\n",
        "    except Exception as e:\n",
        "        # Error handling for potential issues during prediction\n",
        "        print(f\"Warning: Error during NLI prediction for hypothesis '{hypothesis[:50]}...': {e}\")\n",
        "        return {\"label\": \"error\", \"score\": 0.0, \"truncated\": False} # Default to False on error\n",
        "\n",
        "# --- 4. Main Evaluation Function ---\n",
        "\n",
        "def evaluate_summary_nli(source_document: str, abstractive_summary: str) -> dict:\n",
        "    \"\"\"\n",
        "    Evaluates factual consistency of an abstractive summary against a source document\n",
        "    using an NLI model, incorporating semantic retrieval (first pass) and\n",
        "    brute-force chunking (second pass for Neutral/Contradiction).\n",
        "    \"\"\"\n",
        "    summary_sentences = chunk_document_by_sentences(abstractive_summary)\n",
        "    source_sentences_for_retrieval = chunk_document_by_sentences(source_document) # For first pass retrieval\n",
        "    source_chunks_for_brute_force = chunk_text_by_tokens(source_document, HARD_CHUNK_SIZE_TOKENS) # For second pass\n",
        "\n",
        "    if not summary_sentences:\n",
        "        print(\"Warning: Summary is empty or contains no valid sentences. Returning empty metrics.\")\n",
        "        return {\n",
        "            \"metrics\": {\n",
        "                \"consistency_rate\": 0.0, \"contradiction_rate\": 0.0,\n",
        "                \"neutrality_rate\": 0.0, \"total_sentences\": 0, \"truncated_inputs_count\": 0\n",
        "            },\n",
        "            \"details\": [], \"categorized_sentences\": {}\n",
        "        }\n",
        "\n",
        "    # Store results from the first pass\n",
        "    first_pass_results = []\n",
        "\n",
        "    # Store final aggregated results\n",
        "    final_nli_results = []\n",
        "    consistency_count = 0\n",
        "    contradiction_count = 0\n",
        "    neutral_count = 0\n",
        "    error_count = 0\n",
        "    truncated_count = 0 # Truncation count (mainly for first pass, less common in second)\n",
        "\n",
        "    entailment_sentences = []\n",
        "    contradiction_sentences = []\n",
        "    neutral_sentences = []\n",
        "    error_sentences = []\n",
        "\n",
        "    print(f\"\\n--- Starting NLI Evaluation (Two-Pass with Semantic Retrieval) ---\")\n",
        "    print(f\"Total Summary Sentences to Process: {len(summary_sentences)}\")\n",
        "    print(f\"Source Document broken into {len(source_sentences_for_retrieval)} sentences for retrieval.\")\n",
        "    print(f\"Source Document also broken into {len(source_chunks_for_brute_force)} token chunks for brute-force re-evaluation.\")\n",
        "    print(f\"First Pass: Retrieving top {NUM_RETRIEVED_CHUNKS} relevant source sentences for each summary sentence.\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # --- FIRST PASS: Semantic Retrieval ---\n",
        "    print(\"\\n--- FIRST PASS: Evaluating all sentences with semantic retrieval ---\")\n",
        "    for i, hypothesis in enumerate(summary_sentences):\n",
        "        print(f\"\\nProcessing Sentence {i+1}/{len(summary_sentences)} (First Pass):\")\n",
        "        print(f\"  Summary Sentence: \\\"{hypothesis}\\\"\")\n",
        "\n",
        "        retrieved_premise = retrieve_relevant_chunks(\n",
        "            summary_sentence=hypothesis,\n",
        "            source_sentences=source_sentences_for_retrieval,\n",
        "            num_chunks=NUM_RETRIEVED_CHUNKS\n",
        "        )\n",
        "\n",
        "        if not retrieved_premise:\n",
        "            print(\"  Warning: No relevant source chunks found for this summary sentence. Defaulting to Neutral.\")\n",
        "            result = {\"label\": \"neutral\", \"score\": 0.0, \"truncated\": False}\n",
        "        else:\n",
        "            result = get_nli_prediction(retrieved_premise, hypothesis)\n",
        "\n",
        "\n",
        "        first_pass_results.append({\n",
        "            \"summary_sentence\": hypothesis,\n",
        "            \"nli_label\": result[\"label\"],\n",
        "            \"nli_score\": result[\"score\"],\n",
        "            \"truncated\": result[\"truncated\"]\n",
        "        })\n",
        "\n",
        "        if result[\"truncated\"]:\n",
        "            truncated_count += 1\n",
        "            print(\"  WARNING: The RETRIEVED PREMISE + hypothesis still exceeded 512 tokens and was truncated in First Pass.\")\n",
        "\n",
        "        print(f\"  First Pass NLI Result: {result['label'].upper()} (Confidence: {result['score']:.2f})\")\n",
        "\n",
        "    print(\"\\n--- FIRST PASS COMPLETE ---\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # --- SECOND PASS: Brute-force for Neutral/Contradiction ---\n",
        "    print(\"\\n--- SECOND PASS: Re-evaluating Neutral/Contradiction sentences with full source chunking ---\")\n",
        "    re_evaluated_count = 0\n",
        "    for i, first_pass_result in enumerate(first_pass_results):\n",
        "        hypothesis = first_pass_result[\"summary_sentence\"]\n",
        "        initial_label = first_pass_result[\"nli_label\"]\n",
        "        final_label = initial_label # Assume initial label is final until re-evaluated\n",
        "\n",
        "        if initial_label in [\"neutral\", \"contradiction\"]:\n",
        "            re_evaluated_count += 1\n",
        "            print(f\"\\nRe-evaluating Sentence {i+1}/{len(summary_sentences)} (Initial Label: {initial_label.upper()}):\")\n",
        "            print(f\"  Summary Sentence: \\\"{hypothesis}\\\"\")\n",
        "\n",
        "            found_entailment_in_second_pass = False\n",
        "            best_contradiction_score = 0.0\n",
        "            second_pass_contradiction_count = 0\n",
        "            second_pass_neutral_count = 0\n",
        "\n",
        "            # Iterate through all source chunks\n",
        "            for chunk_idx, source_chunk in enumerate(source_chunks_for_brute_force):\n",
        "                print(f\"    Checking against source chunk {chunk_idx+1}/{len(source_chunks_for_brute_force)}...\")\n",
        "                chunk_result = get_nli_prediction(source_chunk, hypothesis)\n",
        "\n",
        "                # Check for truncation in the second pass (should be rare if HARD_CHUNK_SIZE_TOKENS is chosen well)\n",
        "                if chunk_result[\"truncated\"]:\n",
        "                     print(f\"    WARNING: Chunk {chunk_idx+1} + hypothesis truncated in second pass.\")\n",
        "\n",
        "\n",
        "                if chunk_result[\"label\"] == \"entailment\":\n",
        "                    found_entailment_in_second_pass = True\n",
        "                    final_label = \"entailment\"\n",
        "                    print(f\"    -> Found ENTAILMENT with chunk {chunk_idx+1}. Bypassing further checks for this sentence.\")\n",
        "                    break # Stop processing chunks for this hypothesis if entailment is found\n",
        "                elif chunk_result[\"label\"] == \"contradiction\":\n",
        "                    second_pass_contradiction_count += 1\n",
        "                    if chunk_result[\"score\"] > best_contradiction_score:\n",
        "                        best_contradiction_score = chunk_result[\"score\"]\n",
        "                elif chunk_result[\"label\"] == \"neutral\":\n",
        "                    second_pass_neutral_count += 1\n",
        "\n",
        "            if found_entailment_in_second_pass:\n",
        "                # Label is already \"entailment\"\n",
        "                pass # The final_label was already set to \"entailment\"\n",
        "            elif second_pass_contradiction_count > 0 and second_pass_neutral_count == 0:\n",
        "                # If only contradictions or primarily strong contradictions found and no entailment\n",
        "                final_label = \"contradiction\" # Keep as contradiction if it was contradiction, or upgrade from neutral\n",
        "                print(f\"    -> Aggregated: Final label is CONTRADICTION (found {second_pass_contradiction_count} contradictions).\")\n",
        "            else:\n",
        "                # If no entailment was found across all chunks, and not overwhelmingly contradictory, it remains neutral.\n",
        "                # Or, if it was initially contradiction but found some neutral in 2nd pass, keep as contradiction if stronger.\n",
        "                print(f\"    -> Aggregated: No ENTAILMENT found. Retaining initial label as {initial_label.upper()}.\")\n",
        "                final_label = initial_label # Revert to initial_label if no stronger evidence\n",
        "\n",
        "        # Add the final label to the final results list\n",
        "        final_nli_results.append({\n",
        "            \"summary_sentence\": hypothesis,\n",
        "            \"nli_label\": final_label,\n",
        "            \"nli_score\": first_pass_result[\"nli_score\"], # Keeping first pass score for now, could average or take best of 2nd pass\n",
        "            \"truncated_first_pass\": first_pass_result[\"truncated\"] # Keep track of original truncation warning\n",
        "        })\n",
        "\n",
        "        # Update global counts based on FINAL labels\n",
        "        if final_label == \"entailment\":\n",
        "            consistency_count += 1\n",
        "            entailment_sentences.append(hypothesis)\n",
        "        elif final_label == \"contradiction\":\n",
        "            contradiction_count += 1\n",
        "            contradiction_sentences.append(hypothesis)\n",
        "        elif final_label == \"neutral\":\n",
        "            neutral_count += 1\n",
        "            neutral_sentences.append(hypothesis)\n",
        "        elif final_label == \"error\": # Errors should ideally be handled within get_nli_prediction\n",
        "            error_count += 1\n",
        "            error_sentences.append(hypothesis)\n",
        "\n",
        "    print(\"\\n--- SECOND PASS COMPLETE ---\")\n",
        "    print(f\"Total sentences re-evaluated in second pass: {re_evaluated_count}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "\n",
        "    total_sentences = len(summary_sentences)\n",
        "    consistency_rate = consistency_count / total_sentences if total_sentences > 0 else 0\n",
        "    contradiction_rate = contradiction_count / total_sentences if total_sentences > 0 else 0\n",
        "    neutrality_rate = neutral_count / total_sentences if total_sentences > 0 else 0\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"--- FINAL NLI Evaluation Summary (Aggregated Two-Pass Results) ---\")\n",
        "    print(f\"Total Summary Sentences Evaluated: {total_sentences}\")\n",
        "    print(f\"Entailment (Consistent): {consistency_count} ({consistency_rate:.2%})\")\n",
        "    print(f\"Contradiction (Hallucinated): {contradiction_count} ({contradiction_rate:.2%})\")\n",
        "    print(f\"Neutral (Unsupported/Potential Hallucination): {neutral_count} ({neutrality_rate:.2%})\")\n",
        "    if error_count > 0:\n",
        "        print(f\"Errors during NLI processing: {error_count}\")\n",
        "    if truncated_count > 0:\n",
        "        print(f\"GLOBAL WARNING: {truncated_count} inputs were truncated in the FIRST PASS (semantic retrieval). This is less likely in the second pass if HARD_CHUNK_SIZE_TOKENS is small enough.\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\n--- Detailed Sentence Categorization (Final Labels) ---\")\n",
        "\n",
        "    if entailment_sentences:\n",
        "        print(\"\\n--- Entailed (Consistent) Sentences ---\")\n",
        "        for i, sentence in enumerate(entailment_sentences):\n",
        "            print(f\"{i+1}. \\\"{sentence}\\\"\")\n",
        "    else:\n",
        "        print(\"\\nNo Entailed (Consistent) Sentences found.\")\n",
        "\n",
        "    if contradiction_sentences:\n",
        "        print(\"\\n--- Contradictory (Hallucinated) Sentences ---\")\n",
        "        for i, sentence in enumerate(contradiction_sentences):\n",
        "            print(f\"{i+1}. \\\"{sentence}\\\"\")\n",
        "    else:\n",
        "        print(\"\\nNo Contradictory (Hallucinated) Sentences found.\")\n",
        "\n",
        "    if neutral_sentences:\n",
        "        print(\"\\n--- Neutral (Unsupported/Potential Hallucination) Sentences ---\")\n",
        "        for i, sentence in enumerate(neutral_sentences):\n",
        "            print(f\"{i+1}. \\\"{sentence}\\\"\")\n",
        "    else:\n",
        "        print(\"\\nNo Neutral (Unsupported/Potential Hallucination) Sentences found.\")\n",
        "\n",
        "    if error_sentences:\n",
        "        print(\"\\n--- Error Processing Sentences ---\")\n",
        "        for i, sentence in enumerate(error_sentences):\n",
        "            print(f\"{i+1}. \\\"{sentence}\\\"\")\n",
        "    else:\n",
        "        print(\"\\nNo Error Processing Sentences.\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "\n",
        "    return {\n",
        "        \"metrics\": {\n",
        "            \"consistency_rate\": consistency_rate,\n",
        "            \"contradiction_rate\": contradiction_rate,\n",
        "            \"neutrality_rate\": neutrality_rate,\n",
        "            \"total_sentences\": total_sentences,\n",
        "            \"truncated_inputs_count\": truncated_count # This reflects first pass truncation\n",
        "        },\n",
        "        \"details\": final_nli_results, # This now contains final labels\n",
        "        \"categorized_sentences\": {\n",
        "            \"entailment\": entailment_sentences,\n",
        "            \"contradiction\": contradiction_sentences,\n",
        "            \"neutral\": neutral_sentences,\n",
        "            \"error\": error_sentences\n",
        "        }\n",
        "    }\n",
        "\n",
        "print(\"\\n--- Evaluating ABSTRACTIVE Summary ---\")\n",
        "evaluation_results_abstractive = evaluate_summary_nli(summary, abstractive_summary+\"Cell cultured meat is bad for health according to scientists.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqH2lbVaF0Hi",
        "outputId": "c3d49842-f54b-4171-f977-d7620e097a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating ABSTRACTIVE Summary ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting NLI Evaluation (Two-Pass with Semantic Retrieval) ---\n",
            "Total Summary Sentences to Process: 24\n",
            "Source Document broken into 30 sentences for retrieval.\n",
            "Source Document also broken into 3 token chunks for brute-force re-evaluation.\n",
            "First Pass: Retrieving top 5 relevant source sentences for each summary sentence.\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "--- FIRST PASS: Evaluating all sentences with semantic retrieval ---\n",
            "\n",
            "Processing Sentence 1/24 (First Pass):\n",
            "  Summary Sentence: \"Multiple firms have produced cell-cultured meat as part of their research and development.\"\n",
            "  First Pass NLI Result: NEUTRAL (Confidence: 0.56)\n",
            "\n",
            "Processing Sentence 2/24 (First Pass):\n",
            "  Summary Sentence: \"These products appear likely to become available to consumers in coming years.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.83)\n",
            "\n",
            "Processing Sentence 3/24 (First Pass):\n",
            "  Summary Sentence: \"FDA and USDA are the primary agencies responsible for overseeing the safety of the nation's food supply.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.99)\n",
            "\n",
            "Processing Sentence 4/24 (First Pass):\n",
            "  Summary Sentence: \"However, some stakeholders have expressed concern about the agencies' oversight of cell-cultured meat amidst a fragmented federal food safety oversight system.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.99)\n",
            "\n",
            "Processing Sentence 5/24 (First Pass):\n",
            "  Summary Sentence: \"GAO was asked to review federal oversight of cell-cultured meat.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.55)\n",
            "\n",
            "Processing Sentence 6/24 (First Pass):\n",
            "  Summary Sentence: \"This report (1) describes what is known about methods for commercially producing cell-cultured meat, and (2) examines the extent to which FDA and USDA are collaborating to provide regulatory oversight of cell-cultured meat.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.88)\n",
            "\n",
            "Processing Sentence 7/24 (First Pass):\n",
            "  Summary Sentence: \"GAO conducted a literature review; reviewed documentation from FDA, USDA, and stakeholder groups; analyzed public comments submitted to the agencies; compared agency efforts with leading practices for interagency collaboration; and conducted site visits to selected cell-cultured meat firms.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.99)\n",
            "\n",
            "Processing Sentence 8/24 (First Pass):\n",
            "  Summary Sentence: \"General information about the process of making cell-cultured meat—food products grown from the cells of livestock, poultry, and seafood—is available.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.60)\n",
            "\n",
            "Processing Sentence 9/24 (First Pass):\n",
            "  Summary Sentence: \"However, no company is commercially producing cell-cultured meat.\"\n",
            "  First Pass NLI Result: CONTRADICTION (Confidence: 0.97)\n",
            "\n",
            "Processing Sentence 10/24 (First Pass):\n",
            "  Summary Sentence: \"Specific information about the technology being used, eventual commercial production methods, and composition of the final products is not yet known.\"\n",
            "  First Pass NLI Result: NEUTRAL (Confidence: 0.96)\n",
            "\n",
            "Processing Sentence 11/24 (First Pass):\n",
            "  Summary Sentence: \"The general process contains five phases: biopsy, cell banking, growth, harvest, and food processing (see figure).\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.99)\n",
            "\n",
            "Processing Sentence 12/24 (First Pass):\n",
            "  Summary Sentence: \"The technology and methods to be used for commercial production are still in development, and producers, regulators, and consumers do not have clarity about many specifics about the process and final product.\"\n",
            "  First Pass NLI Result: NEUTRAL (Confidence: 0.52)\n",
            "\n",
            "Processing Sentence 13/24 (First Pass):\n",
            "  Summary Sentence: \"For example, it is unclear whether production methods and products will use or contain genetically-engineered cells or medications such as antibiotics.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 1.00)\n",
            "\n",
            "Processing Sentence 14/24 (First Pass):\n",
            "  Summary Sentence: \"The Food and Drug Administration (FDA) and U.S. Department of Agriculture (USDA) have begun collaborating on regulatory oversight of cell-cultured meat.\"\n",
            "  First Pass NLI Result: NEUTRAL (Confidence: 0.95)\n",
            "\n",
            "Processing Sentence 15/24 (First Pass):\n",
            "  Summary Sentence: \"For example, in 2019, the agencies signed an interagency agreement and created three working groups to carry out the terms of the agreement.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.99)\n",
            "\n",
            "Processing Sentence 16/24 (First Pass):\n",
            "  Summary Sentence: \"However, the agreement and working groups could more fully incorporate practices to enhance and sustain collaboration, such as defining outcomes.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.98)\n",
            "\n",
            "Processing Sentence 17/24 (First Pass):\n",
            "  Summary Sentence: \"For example, the agreement identifies the development of labeling principles as an outcome, but does not describe how the agencies will track and monitor progress toward this outcome, and the working groups identify a lead agency but not members' roles.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.91)\n",
            "\n",
            "Processing Sentence 18/24 (First Pass):\n",
            "  Summary Sentence: \"Also, agency officials said they decided FDA would oversee cell-cultured seafood other than catfish, but they have not formally announced or documented this decision.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.93)\n",
            "\n",
            "Processing Sentence 19/24 (First Pass):\n",
            "  Summary Sentence: \"Developing and updating written guidance and agreements is also a leading practice for interagency collaboration.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 1.00)\n",
            "\n",
            "Processing Sentence 20/24 (First Pass):\n",
            "  Summary Sentence: \"By fully incorporating leading practices into their efforts to collaborate, the agencies could minimize potential overlap and fragmentation, use resources in a more efficient manner, and better ensure the public and other key stakeholders have clarity about the agencies' oversight responsibilities.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.98)\n",
            "\n",
            "Processing Sentence 21/24 (First Pass):\n",
            "  Summary Sentence: \"GAO recommends that FDA and USDA more fully incorporate leading practices for effective collaboration in the agencies' interagency agreement.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.93)\n",
            "\n",
            "Processing Sentence 22/24 (First Pass):\n",
            "  Summary Sentence: \"FDA and USDA partially concurred and indicated a willingness to incorporate these practices in a more detailed agreement, which would also meet the intent of the recommendations.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.98)\n",
            "\n",
            "Processing Sentence 23/24 (First Pass):\n",
            "  Summary Sentence: \"The agencies concurred with the four other recommendations.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.99)\n",
            "\n",
            "Processing Sentence 24/24 (First Pass):\n",
            "  Summary Sentence: \"Cell cultured meat is bad for health according to scientists.\"\n",
            "  First Pass NLI Result: ENTAILMENT (Confidence: 0.91)\n",
            "\n",
            "--- FIRST PASS COMPLETE ---\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "--- SECOND PASS: Re-evaluating Neutral/Contradiction sentences with full source chunking ---\n",
            "\n",
            "Re-evaluating Sentence 1/24 (Initial Label: NEUTRAL):\n",
            "  Summary Sentence: \"Multiple firms have produced cell-cultured meat as part of their research and development.\"\n",
            "    Checking against source chunk 1/3...\n",
            "    -> Found ENTAILMENT with chunk 1. Bypassing further checks for this sentence.\n",
            "\n",
            "Re-evaluating Sentence 9/24 (Initial Label: CONTRADICTION):\n",
            "  Summary Sentence: \"However, no company is commercially producing cell-cultured meat.\"\n",
            "    Checking against source chunk 1/3...\n",
            "    -> Found ENTAILMENT with chunk 1. Bypassing further checks for this sentence.\n",
            "\n",
            "Re-evaluating Sentence 10/24 (Initial Label: NEUTRAL):\n",
            "  Summary Sentence: \"Specific information about the technology being used, eventual commercial production methods, and composition of the final products is not yet known.\"\n",
            "    Checking against source chunk 1/3...\n",
            "    -> Found ENTAILMENT with chunk 1. Bypassing further checks for this sentence.\n",
            "\n",
            "Re-evaluating Sentence 12/24 (Initial Label: NEUTRAL):\n",
            "  Summary Sentence: \"The technology and methods to be used for commercial production are still in development, and producers, regulators, and consumers do not have clarity about many specifics about the process and final product.\"\n",
            "    Checking against source chunk 1/3...\n",
            "    -> Found ENTAILMENT with chunk 1. Bypassing further checks for this sentence.\n",
            "\n",
            "Re-evaluating Sentence 14/24 (Initial Label: NEUTRAL):\n",
            "  Summary Sentence: \"The Food and Drug Administration (FDA) and U.S. Department of Agriculture (USDA) have begun collaborating on regulatory oversight of cell-cultured meat.\"\n",
            "    Checking against source chunk 1/3...\n",
            "    -> Found ENTAILMENT with chunk 1. Bypassing further checks for this sentence.\n",
            "\n",
            "--- SECOND PASS COMPLETE ---\n",
            "Total sentences re-evaluated in second pass: 5\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "======================================================================\n",
            "--- FINAL NLI Evaluation Summary (Aggregated Two-Pass Results) ---\n",
            "Total Summary Sentences Evaluated: 24\n",
            "Entailment (Consistent): 24 (100.00%)\n",
            "Contradiction (Hallucinated): 0 (0.00%)\n",
            "Neutral (Unsupported/Potential Hallucination): 0 (0.00%)\n",
            "======================================================================\n",
            "\n",
            "--- Detailed Sentence Categorization (Final Labels) ---\n",
            "\n",
            "--- Entailed (Consistent) Sentences ---\n",
            "1. \"Multiple firms have produced cell-cultured meat as part of their research and development.\"\n",
            "2. \"These products appear likely to become available to consumers in coming years.\"\n",
            "3. \"FDA and USDA are the primary agencies responsible for overseeing the safety of the nation's food supply.\"\n",
            "4. \"However, some stakeholders have expressed concern about the agencies' oversight of cell-cultured meat amidst a fragmented federal food safety oversight system.\"\n",
            "5. \"GAO was asked to review federal oversight of cell-cultured meat.\"\n",
            "6. \"This report (1) describes what is known about methods for commercially producing cell-cultured meat, and (2) examines the extent to which FDA and USDA are collaborating to provide regulatory oversight of cell-cultured meat.\"\n",
            "7. \"GAO conducted a literature review; reviewed documentation from FDA, USDA, and stakeholder groups; analyzed public comments submitted to the agencies; compared agency efforts with leading practices for interagency collaboration; and conducted site visits to selected cell-cultured meat firms.\"\n",
            "8. \"General information about the process of making cell-cultured meat—food products grown from the cells of livestock, poultry, and seafood—is available.\"\n",
            "9. \"However, no company is commercially producing cell-cultured meat.\"\n",
            "10. \"Specific information about the technology being used, eventual commercial production methods, and composition of the final products is not yet known.\"\n",
            "11. \"The general process contains five phases: biopsy, cell banking, growth, harvest, and food processing (see figure).\"\n",
            "12. \"The technology and methods to be used for commercial production are still in development, and producers, regulators, and consumers do not have clarity about many specifics about the process and final product.\"\n",
            "13. \"For example, it is unclear whether production methods and products will use or contain genetically-engineered cells or medications such as antibiotics.\"\n",
            "14. \"The Food and Drug Administration (FDA) and U.S. Department of Agriculture (USDA) have begun collaborating on regulatory oversight of cell-cultured meat.\"\n",
            "15. \"For example, in 2019, the agencies signed an interagency agreement and created three working groups to carry out the terms of the agreement.\"\n",
            "16. \"However, the agreement and working groups could more fully incorporate practices to enhance and sustain collaboration, such as defining outcomes.\"\n",
            "17. \"For example, the agreement identifies the development of labeling principles as an outcome, but does not describe how the agencies will track and monitor progress toward this outcome, and the working groups identify a lead agency but not members' roles.\"\n",
            "18. \"Also, agency officials said they decided FDA would oversee cell-cultured seafood other than catfish, but they have not formally announced or documented this decision.\"\n",
            "19. \"Developing and updating written guidance and agreements is also a leading practice for interagency collaboration.\"\n",
            "20. \"By fully incorporating leading practices into their efforts to collaborate, the agencies could minimize potential overlap and fragmentation, use resources in a more efficient manner, and better ensure the public and other key stakeholders have clarity about the agencies' oversight responsibilities.\"\n",
            "21. \"GAO recommends that FDA and USDA more fully incorporate leading practices for effective collaboration in the agencies' interagency agreement.\"\n",
            "22. \"FDA and USDA partially concurred and indicated a willingness to incorporate these practices in a more detailed agreement, which would also meet the intent of the recommendations.\"\n",
            "23. \"The agencies concurred with the four other recommendations.\"\n",
            "24. \"Cell cultured meat is bad for health according to scientists.\"\n",
            "\n",
            "No Contradictory (Hallucinated) Sentences found.\n",
            "\n",
            "No Neutral (Unsupported/Potential Hallucination) Sentences found.\n",
            "\n",
            "No Error Processing Sentences.\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NLI based factual consistency metric"
      ],
      "metadata": {
        "id": "-5Sc5kT5QbiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import spacy\n",
        "from tqdm.notebook import tqdm as tqdm_colab\n",
        "\n",
        "# --- Load Spacy model for sentence splitting ---\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    print(\"Downloading 'en_core_web_sm' model. This will happen only once.\")\n",
        "    spacy.cli.download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# --- Load Factual Consistency Model (FactCC) ---\n",
        "print(\"Loading FactCC model from Hugging Face using Auto classes...\")\n",
        "factcc_model_path = 'manueldeprada/FactCC'\n",
        "factcc_tokenizer = AutoTokenizer.from_pretrained(factcc_model_path)\n",
        "factcc_model = AutoModelForSequenceClassification.from_pretrained(factcc_model_path)\n",
        "\n",
        "# --- Set Device (GPU if available, else CPU) ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "factcc_model.eval()\n",
        "factcc_model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "print(\"FactCC model loaded successfully.\")\n",
        "\n",
        "# --- Helper Function for Sentence Splitting ---\n",
        "def split_sentences(text):\n",
        "    return [sent.text.strip() for sent in nlp(text).sents if sent.text.strip()]\n",
        "\n",
        "# --- Factual Consistency Evaluation Function ---\n",
        "def calculate_factcc_score(original_document, summary):\n",
        "    \"\"\"\n",
        "    Calculates the factual consistency score of a summary against its source document using FactCC.\n",
        "    The score is the average of consistency probabilities for each sentence in the summary.\n",
        "    \"\"\"\n",
        "    summary_sentences = split_sentences(summary)\n",
        "    if not summary_sentences:\n",
        "        return 0.0\n",
        "\n",
        "    consistency_scores = []\n",
        "    with torch.no_grad():\n",
        "        for sentence in tqdm_colab(summary_sentences, desc=\"Evaluating sentences\", leave=False):\n",
        "            inputs = factcc_tokenizer(original_document, sentence, return_tensors='pt', padding=True, truncation='only_first', max_length=512).to(device)\n",
        "            outputs = factcc_model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            probs = torch.nn.functional.softmax(logits, dim=1)\n",
        "            # The 'correct' label is at index 0\n",
        "            correct_score = probs[0][0].item()\n",
        "            consistency_scores.append(correct_score)\n",
        "\n",
        "    if not consistency_scores:\n",
        "        return 0.0\n",
        "\n",
        "    average_score = sum(consistency_scores) / len(consistency_scores)\n",
        "    return round(average_score, 4)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # --- Define manual test strings ---\n",
        "    original_document_test = \"The Amazon rainforest is the world's largest tropical rainforest. It is home to a vast diversity of species. The rainforest is located in South America and covers a massive area of about 5.5 million square kilometers.\"\n",
        "\n",
        "    # Example 1: A factually consistent summary\n",
        "    summary_test_consistent = \"The Amazon is the world's largest tropical rainforest in South America, covering 5.5 million square kilometers.\"\n",
        "\n",
        "    # Example 2: A factually inconsistent summary\n",
        "    summary_test_inconsistent = \"The Amazon rainforest is the world's largest tropical rainforest, located in Africa. It is home to a vast diversity of species.\"\n",
        "\n",
        "    print(\"--- Testing Factually Consistent Summary ---\")\n",
        "    print(f\"Original Document: {original_document_test}\\n\")\n",
        "    print(f\"Summary to Test: {summary_test_consistent}\\n\")\n",
        "\n",
        "    factcc_score_consistent = calculate_factcc_score(original_document, rephrased_text)\n",
        "\n",
        "    print(f\"\\nFinal FactCC Score for Consistent Summary: {factcc_score_consistent}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"--- Testing Factually Inconsistent Summary ---\")\n",
        "    print(f\"Original Document: {original_document_test}\\n\")\n",
        "    print(f\"Summary to Test: {summary_test_inconsistent}\\n\")\n",
        "\n",
        "    factcc_score_inconsistent = calculate_factcc_score(original_document, abstractive_summary)\n",
        "\n",
        "    print(f\"\\nFinal FactCC Score for Inconsistent Summary: {factcc_score_inconsistent}\")\n",
        "    print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402,
          "referenced_widgets": [
            "9bda06ce543648c9a4a66eadede1d357",
            "d2d62f629df44bf5ac320c30a2fd2324",
            "a06f3f2528e5414a934e58eb820aaa9e",
            "b09f624ee90e4cb6ab30203d306df210",
            "926d3acb405645de850d114a280ff26e",
            "25a54270fe42432a97b4ab5956011de0",
            "3f50358d833f48379349dd92badaa419",
            "4da878febe9448bd8d17929c4a58e45e",
            "8e7f7810b6f54b218a1bce7baf5403c8",
            "bfb572e6a05b4a75b2e6fb6a772a5365",
            "73d0621770344bd3aa0eff467b335b99",
            "a6d6db55cdd545d4aa41a00d6efec3d3",
            "211e5e658d22426bb78bb1fb462aecd1",
            "e4e9dc8c62be4e9594a8312b5ae229c7",
            "f29d576c8dca4f9ba1fe9e7112d3149a",
            "03ac61c0cf604d0ba95ccd7aa7fcee5b",
            "ff6a3d52b30b4e1da26f19c4b5857ecd",
            "ead05daeb26a4a45b4d8d05f84f976be",
            "0d5ea08a37bf4988884a1c9f3125e3a3",
            "d792524051e842c78251872c72910d8d",
            "4eb9dbba91aa428fad57388cf2c53d71",
            "0553c93c74b6455fad78a75f35bca672"
          ]
        },
        "id": "jr3ArsweQfjw",
        "outputId": "036ba0fb-01a5-40e9-8db3-9b01ed218f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading FactCC model from Hugging Face using Auto classes...\n",
            "Using device: cuda\n",
            "FactCC model loaded successfully.\n",
            "--- Testing Factually Consistent Summary ---\n",
            "Original Document: The Amazon rainforest is the world's largest tropical rainforest. It is home to a vast diversity of species. The rainforest is located in South America and covers a massive area of about 5.5 million square kilometers.\n",
            "\n",
            "Summary to Test: The Amazon is the world's largest tropical rainforest in South America, covering 5.5 million square kilometers.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating sentences:   0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bda06ce543648c9a4a66eadede1d357"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final FactCC Score for Consistent Summary: 0.5791\n",
            "============================================================\n",
            "--- Testing Factually Inconsistent Summary ---\n",
            "Original Document: The Amazon rainforest is the world's largest tropical rainforest. It is home to a vast diversity of species. The rainforest is located in South America and covers a massive area of about 5.5 million square kilometers.\n",
            "\n",
            "Summary to Test: The Amazon rainforest is the world's largest tropical rainforest, located in Africa. It is home to a vast diversity of species.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating sentences:   0%|          | 0/23 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6d6db55cdd545d4aa41a00d6efec3d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final FactCC Score for Inconsistent Summary: 0.6949\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Factcc"
      ],
      "metadata": {
        "id": "99PHP1K-A7sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import spacy\n",
        "from tqdm.notebook import tqdm as tqdm_colab\n",
        "\n",
        "# --- Load Spacy model for sentence splitting ---\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    print(\"Downloading 'en_core_web_sm' model. This will happen only once.\")\n",
        "    spacy.cli.download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# --- Load Factual Consistency Model (FactCC) ---\n",
        "print(\"Loading FactCC model from Hugging Face...\")\n",
        "factcc_model_path = 'manueldeprada/FactCC'\n",
        "factcc_tokenizer = AutoTokenizer.from_pretrained(factcc_model_path)\n",
        "factcc_model = AutoModelForSequenceClassification.from_pretrained(factcc_model_path)\n",
        "\n",
        "# --- Set Device (GPU if available, else CPU) ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "factcc_model.eval()\n",
        "factcc_model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "print(\"FactCC model loaded successfully.\")\n",
        "\n",
        "\n",
        "# --- Helper Function for Sentence Splitting ---\n",
        "def split_sentences(text):\n",
        "    return [sent.text.strip() for sent in nlp(text).sents if sent.text.strip()]\n",
        "\n",
        "# --- Helper function to create overlapping document chunks ---\n",
        "def create_document_chunks(document, tokenizer, max_length=512, overlap=50):\n",
        "    tokens = tokenizer.tokenize(document)\n",
        "    chunks = []\n",
        "\n",
        "    # Calculate the max length for the document part of the input\n",
        "    # 512 - (summary_tokens + CLS + SEP + SEP)\n",
        "    doc_max_length = max_length - 50\n",
        "\n",
        "    start = 0\n",
        "    while start < len(tokens):\n",
        "        end = min(start + doc_max_length, len(tokens))\n",
        "        chunk_tokens = tokens[start:end]\n",
        "        chunks.append(tokenizer.convert_tokens_to_string(chunk_tokens))\n",
        "\n",
        "        if end == len(tokens):\n",
        "            break\n",
        "\n",
        "        start += (doc_max_length - overlap)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# --- Factual Consistency Evaluation Function with Sliding Window ---\n",
        "def calculate_factcc_score(original_document, summary):\n",
        "    \"\"\"\n",
        "    Calculates the factual consistency score of a summary against its source document\n",
        "    using a sliding window approach for large documents.\n",
        "    \"\"\"\n",
        "    summary_sentences = split_sentences(summary)\n",
        "    if not summary_sentences:\n",
        "        return 0.0\n",
        "\n",
        "    document_chunks = create_document_chunks(original_document, factcc_tokenizer)\n",
        "\n",
        "    consistency_scores = []\n",
        "\n",
        "    print(f\"Original document split into {len(document_chunks)} chunks.\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sentence in tqdm_colab(summary_sentences, desc=\"Evaluating summary sentences\", leave=False):\n",
        "            max_sentence_score = 0.0\n",
        "\n",
        "            # Check the summary sentence against every chunk\n",
        "            for chunk in document_chunks:\n",
        "                inputs = factcc_tokenizer(chunk, sentence, return_tensors='pt', padding=True, truncation='only_first', max_length=512).to(device)\n",
        "                outputs = factcc_model(**inputs)\n",
        "                logits = outputs.logits\n",
        "                probs = torch.nn.functional.softmax(logits, dim=1)\n",
        "\n",
        "                # The 'correct' label is at index 0\n",
        "                correct_score = probs[0][0].item()\n",
        "\n",
        "                # We take the max score across all chunks\n",
        "                if correct_score > max_sentence_score:\n",
        "                    max_sentence_score = correct_score\n",
        "\n",
        "            consistency_scores.append(max_sentence_score)\n",
        "\n",
        "    if not consistency_scores:\n",
        "        return 0.0\n",
        "\n",
        "    average_score = sum(consistency_scores) / len(consistency_scores)\n",
        "    return round(average_score, 4)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # --- Define a large document and a small summary ---\n",
        "    # We will make the document larger than the 512 token limit\n",
        "    long_document = \"The sun is the star at the center of the Solar System. It is a nearly perfect ball of hot plasma, heated to incandescence by nuclear fusion reactions in its core. The sun radiates this energy mainly as visible light, ultraviolet light, and infrared radiation. It is the most important source of energy for life on Earth. The sun's mass is about 333,000 times that of Earth. This massive star, at the heart of our planetary system, is a G-type main-sequence star. It has an age of approximately 4.6 billion years. This immense celestial body has a diameter of about 1.39 million kilometers. It is composed of roughly three-quarters hydrogen and one-quarter helium. The sun's gravity holds the Solar System together, keeping everything from the biggest planets to the smallest debris in orbit around it. A light year is the distance light travels in one year. It is about 9.46 trillion kilometers. This unit is used to measure vast distances in space. The sun is approximately 8 light-minutes away from Earth. This is a very large distance, even though it takes light a relatively short time to travel. The moon is Earth's only natural satellite. It is the fifth-largest satellite in the Solar System. The moon's diameter is about 3,474 kilometers. It is believed to have formed about 4.5 billion years ago, not long after Earth. The moon has no atmosphere, which means there is no air to breathe. Its surface is covered with craters from asteroid impacts. The sun is a star, but the moon is a satellite. The sun provides light, but the moon reflects it. The moon causes tides on Earth due to its gravitational pull. The sun is essential for photosynthesis. The moon has phases, such as new moon, first quarter, full moon, and last quarter. These phases are caused by the changing angles at which we see the sunlit part of the moon.\"\n",
        "\n",
        "    small_summary_consistent = \"The sun, which is a star, has a diameter of about 1.39 million kilometers. Its gravity holds the Solar System together.\"\n",
        "\n",
        "    small_summary_inconsistent = \"The sun is approximately 8 light-years away from Earth. The moon is a G-type main-sequence star.\"\n",
        "\n",
        "    print(\"--- Testing with a large document and small summaries ---\")\n",
        "\n",
        "    print(\"\\n--- Consistent Summary Test ---\")\n",
        "    factcc_score_consistent = calculate_factcc_score(original_document, rephrased_text)\n",
        "    print(f\"\\nFinal FactCC Score for Consistent Summary: {factcc_score_consistent}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"\\n--- Inconsistent Summary Test ---\")\n",
        "    #factcc_score_inconsistent = calculate_factcc_score(original_document, abstractive_summary)\n",
        "    print(f\"\\nFinal FactCC Score for Inconsistent Summary: {factcc_score_inconsistent}\")\n",
        "    print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315,
          "referenced_widgets": [
            "4f001aff0c904052ad51e53adb41899b",
            "634a91a0b919458b810041973130a442",
            "871ef31c31314986b6f899a66c889500",
            "48cf7f8ab1d44b099a29a4cf3b2d30d6",
            "38c5d31498c64671971a42931ba05304",
            "7b9eb2ae340742edb1423105fa13520e",
            "8c1a636462354c96aee7522f1e4eab86",
            "5ee7359d73c648afb82cd7fb72308c1e",
            "e63e9f3b10b3470a9a79b4b44af138c2",
            "88c310391a4a4a98aa18fe96abdeff3b",
            "fbd216299dd244008209ad8cf1e3428b"
          ]
        },
        "id": "J6NTHbDSA-IP",
        "outputId": "19a016db-0841-40be-f0b4-e24f30aaab6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading FactCC model from Hugging Face...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (11708 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "FactCC model loaded successfully.\n",
            "--- Testing with a large document and small summaries ---\n",
            "\n",
            "--- Consistent Summary Test ---\n",
            "Original document split into 29 chunks.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating summary sentences:   0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f001aff0c904052ad51e53adb41899b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final FactCC Score for Consistent Summary: 0.8565\n",
            "============================================================\n",
            "\n",
            "--- Inconsistent Summary Test ---\n",
            "\n",
            "Final FactCC Score for Inconsistent Summary: 0.9556\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#installation of libraries"
      ],
      "metadata": {
        "id": "zK5ulh3waJQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install rouge_score\n",
        "#!pip install bert_score"
      ],
      "metadata": {
        "id": "b3VK2XWr6iCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generating extractive summaries for 1000 data points(test.json) using longformer"
      ],
      "metadata": {
        "id": "Vz7ELTm7UKVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LongformerModel, LongformerTokenizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cdist\n",
        "import numpy as np\n",
        "import spacy\n",
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Constants ---\n",
        "JSON_FILE_PATH = \"govreport_tfidf_vscode2/test.json\"\n",
        "OUTPUT_FILE_PATH = \"summaries_output.json\"\n",
        "\n",
        "# --- Load Spacy model ---\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    print(\"Downloading 'en_core_web_sm' model. This will happen only once.\")\n",
        "    spacy.cli.download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# --- Load Longformer Model and Tokenizer ---\n",
        "print(\"Loading Longformer model and tokenizer...\")\n",
        "model_name = 'allenai/longformer-base-4096'\n",
        "tokenizer = LongformerTokenizer.from_pretrained(model_name)\n",
        "model = LongformerModel.from_pretrained(model_name)\n",
        "\n",
        "# --- Set Device (GPU if available, else CPU) ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.eval()\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "print(\"Longformer model loaded.\")\n",
        "\n",
        "# --- Helper Function for Sentence Embeddings ---\n",
        "def get_sentence_embeddings(text, batch_size=4):\n",
        "    \"\"\"\n",
        "    Splits text into sentences, tokenizes them, and gets Longformer embeddings.\n",
        "    Handles long documents by processing sentences in batches.\n",
        "    Returns:\n",
        "        sentences (list): List of original sentence strings.\n",
        "        sentence_embeddings (np.array): NumPy array of sentence embeddings.\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
        "\n",
        "    if not sentences:\n",
        "        return [], np.array([])\n",
        "\n",
        "    all_sentence_embeddings = []\n",
        "\n",
        "    # Add a tqdm progress bar for the batch processing\n",
        "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"  Embedding sentences\", leave=False):\n",
        "        batch_sentences = sentences[i:i + batch_size]\n",
        "        try:\n",
        "            inputs = tokenizer(\n",
        "                batch_sentences,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=tokenizer.model_max_length\n",
        "            ).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            all_sentence_embeddings.extend(cls_embeddings)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing batch of sentences (index {i}-{i+len(batch_sentences)-1}): {e}\")\n",
        "            all_sentence_embeddings.extend([np.zeros(model.config.hidden_size)] * len(batch_sentences))\n",
        "            continue\n",
        "\n",
        "    return sentences, np.array(all_sentence_embeddings)\n",
        "\n",
        "# --- Summarization functions (rest of the code is unchanged) ---\n",
        "# ... (all summarization functions are the same as before) ...\n",
        "def centroid_summarization_optimized(sentences, embeddings, num_sentences=3):\n",
        "    print(\"\\n--- Starting Centroid-Based Summarization ---\")\n",
        "    if not sentences or embeddings.shape[0] == 0:\n",
        "        print(\"  No sentences or embeddings provided. Cannot summarize.\")\n",
        "        return [], []\n",
        "    if num_sentences <= 0:\n",
        "        print(\"  Number of sentences for summary must be positive.\")\n",
        "        return [], []\n",
        "    num_sentences_to_extract = min(num_sentences, len(sentences))\n",
        "    document_centroid = np.mean(embeddings, axis=0)\n",
        "    similarities = cosine_similarity(embeddings, document_centroid.reshape(1, -1)).flatten()\n",
        "    summary_sentences_mmr = []\n",
        "    selected_indices = set()\n",
        "    ranked_initial_indices = np.argsort(similarities)[::-1]\n",
        "    for _ in range(num_sentences_to_extract):\n",
        "        best_sentence_idx = -1\n",
        "        max_mmr_score = -1\n",
        "        for i in ranked_initial_indices:\n",
        "            if i not in selected_indices:\n",
        "                relevance = similarities[i]\n",
        "                if not selected_indices:\n",
        "                    mmr_score = relevance\n",
        "                else:\n",
        "                    diversity_scores = cosine_similarity(embeddings[i].reshape(1, -1),\n",
        "                                                         embeddings[list(selected_indices)])\n",
        "                    redundancy = np.max(diversity_scores)\n",
        "                    lambda_param = 0.5\n",
        "                    mmr_score = lambda_param * relevance - (1 - lambda_param) * redundancy\n",
        "                if mmr_score > max_mmr_score:\n",
        "                    max_mmr_score = mmr_score\n",
        "                    best_sentence_idx = i\n",
        "        if best_sentence_idx != -1:\n",
        "            summary_sentences_mmr.append((sentences[best_sentence_idx], best_sentence_idx))\n",
        "            selected_indices.add(best_sentence_idx)\n",
        "            ranked_initial_indices = ranked_initial_indices[ranked_initial_indices != best_sentence_idx]\n",
        "        else:\n",
        "            break\n",
        "    summary_sentences_mmr.sort(key=lambda x: x[1])\n",
        "    final_summary_sents = [s[0] for s in summary_sentences_mmr]\n",
        "    final_summary_indices = [s[1] for s in summary_sentences_mmr]\n",
        "    print(\"--- Centroid-Based Summarization Complete ---\")\n",
        "    return final_summary_sents, final_summary_indices\n",
        "\n",
        "def kmeans_summarization_optimized(sentences, embeddings, num_clusters=25, num_sentences_per_cluster=1):\n",
        "    print(\"\\n--- Starting K-Means Based Summarization ---\")\n",
        "    if not sentences or embeddings.shape[0] == 0:\n",
        "        print(\"  No sentences or embeddings provided. Cannot summarize.\")\n",
        "        return [], []\n",
        "    if num_clusters <= 0 or num_sentences_per_cluster <= 0:\n",
        "        print(\"  Number of clusters and sentences per cluster must be positive.\")\n",
        "        return [], []\n",
        "    effective_num_clusters = min(num_clusters, len(sentences))\n",
        "    if effective_num_clusters == 0:\n",
        "        print(\"  Not enough sentences to form clusters.\")\n",
        "        return [], []\n",
        "    kmeans = KMeans(n_clusters=effective_num_clusters, random_state=42, n_init='auto')\n",
        "    kmeans.fit(embeddings)\n",
        "    clusters = kmeans.labels_\n",
        "    centroids = kmeans.cluster_centers_\n",
        "    summary_sentences_with_idx = []\n",
        "    selected_indices = set()\n",
        "    for i in range(effective_num_clusters):\n",
        "        cluster_sentence_indices = np.where(clusters == i)[0]\n",
        "        if len(cluster_sentence_indices) == 0:\n",
        "            continue\n",
        "        distances = cdist(embeddings[cluster_sentence_indices], centroids[i].reshape(1, -1), 'cosine').flatten()\n",
        "        sorted_cluster_indices = cluster_sentence_indices[np.argsort(distances)]\n",
        "        count_selected_from_cluster = 0\n",
        "        for original_idx in sorted_cluster_indices:\n",
        "            if original_idx not in selected_indices:\n",
        "                summary_sentences_with_idx.append((sentences[original_idx], original_idx))\n",
        "                selected_indices.add(original_idx)\n",
        "                count_selected_from_cluster += 1\n",
        "                if count_selected_from_cluster >= num_sentences_per_cluster:\n",
        "                    break\n",
        "    summary_sentences_with_idx.sort(key=lambda x: x[1])\n",
        "    final_summary_sents = [s[0] for s in summary_sentences_with_idx]\n",
        "    final_summary_indices = [s[1] for s in summary_sentences_with_idx]\n",
        "    print(\"--- K-Means Based Summarization Complete ---\")\n",
        "    return final_summary_sents, final_summary_indices\n",
        "\n",
        "def combined_extractive_summary_optimized(sentences, embeddings, total_summary_sentences=7,\n",
        "                                          centroid_sentences_to_propose=5,\n",
        "                                          kmeans_clusters_to_propose=4,\n",
        "                                          kmeans_sentences_per_cluster_to_propose=1,\n",
        "                                          lambda_param_mmr=0.7):\n",
        "    print(\"\\n--- Starting Combined Extractive Summarization ---\")\n",
        "    if not sentences or embeddings.shape[0] == 0:\n",
        "        print(\"  No sentences or embeddings provided. Cannot generate combined summary.\")\n",
        "        return []\n",
        "    centroid_candidates_sents, centroid_candidates_indices = centroid_summarization_optimized(\n",
        "        sentences, embeddings, num_sentences=centroid_sentences_to_propose\n",
        "    )\n",
        "    print(f\"  Centroid proposed {len(centroid_candidates_sents)} candidates.\")\n",
        "    kmeans_candidates_sents, kmeans_candidates_indices = kmeans_summarization_optimized(\n",
        "        sentences, embeddings, num_clusters=kmeans_clusters_to_propose, num_sentences_per_cluster=kmeans_sentences_per_cluster_to_propose\n",
        "    )\n",
        "    print(f\"  K-Means proposed {len(kmeans_candidates_sents)} candidates.\")\n",
        "    combined_candidates_map = {}\n",
        "    for idx, sent in zip(centroid_candidates_indices, centroid_candidates_sents):\n",
        "        combined_candidates_map[idx] = sent\n",
        "    for idx, sent in zip(kmeans_candidates_indices, kmeans_candidates_sents):\n",
        "        combined_candidates_map[idx] = sent\n",
        "    all_candidate_indices_sorted = sorted(combined_candidates_map.keys())\n",
        "    all_candidate_sentences = [combined_candidates_map[idx] for idx in all_candidate_indices_sorted]\n",
        "    all_candidate_embeddings = np.array([embeddings[idx] for idx in all_candidate_indices_sorted])\n",
        "    if not all_candidate_sentences or all_candidate_embeddings.shape[0] == 0:\n",
        "        print(\"  No unique candidates found after combining. Cannot generate combined summary.\")\n",
        "        return []\n",
        "    num_sentences_to_extract = min(total_summary_sentences, len(all_candidate_sentences))\n",
        "    print(f\"  Total unique candidates: {len(all_candidate_sentences)}. Extracting {num_sentences_to_extract} for combined summary.\")\n",
        "    document_centroid = np.mean(embeddings, axis=0)\n",
        "    candidate_similarities = cosine_similarity(all_candidate_embeddings, document_centroid.reshape(1, -1)).flatten()\n",
        "    final_summary_sentences = []\n",
        "    selected_candidate_indices = set()\n",
        "    ranked_initial_candidate_indices = np.argsort(candidate_similarities)[::-1]\n",
        "    for _ in range(num_sentences_to_extract):\n",
        "        best_idx_in_candidates = -1\n",
        "        max_mmr_score = -1\n",
        "        for i_candidate in ranked_initial_candidate_indices:\n",
        "            if i_candidate not in selected_candidate_indices:\n",
        "                relevance = candidate_similarities[i_candidate]\n",
        "                if not selected_candidate_indices:\n",
        "                    mmr_score = relevance\n",
        "                else:\n",
        "                    diversity_scores = cosine_similarity(all_candidate_embeddings[i_candidate].reshape(1, -1),\n",
        "                                                         all_candidate_embeddings[list(selected_candidate_indices)])\n",
        "                    redundancy = np.max(diversity_scores)\n",
        "                    mmr_score = lambda_param_mmr * relevance - (1 - lambda_param_mmr) * redundancy\n",
        "                if mmr_score > max_mmr_score:\n",
        "                    max_mmr_score = mmr_score\n",
        "                    best_idx_in_candidates = i_candidate\n",
        "        if best_idx_in_candidates != -1:\n",
        "            final_summary_sentences.append((all_candidate_sentences[best_idx_in_candidates],\n",
        "                                            all_candidate_indices_sorted[best_idx_in_candidates]))\n",
        "            selected_candidate_indices.add(best_idx_in_candidates)\n",
        "            ranked_initial_candidate_indices = ranked_initial_candidate_indices[ranked_initial_candidate_indices != best_idx_in_candidates]\n",
        "        else:\n",
        "            break\n",
        "    final_summary_sentences.sort(key=lambda x: x[1])\n",
        "    final_summary = [s[0] for s in final_summary_sentences]\n",
        "    print(\"--- Combined Extractive Summarization Complete ---\")\n",
        "    return final_summary\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # --- Check if the JSON file exists ---\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        print(f\"Error: The file '{JSON_FILE_PATH}' was not found.\")\n",
        "        print(\"Please ensure the file path is correct and the file exists.\")\n",
        "    else:\n",
        "        # List to store all generated summaries\n",
        "        all_summaries = []\n",
        "\n",
        "        # --- Load the JSONL file and process it line by line ---\n",
        "        try:\n",
        "            # We don't load the entire file into memory as one object.\n",
        "            # We'll read and process it line by line.\n",
        "            print(f\"\\nProcessing JSONL file '{JSON_FILE_PATH}'...\")\n",
        "\n",
        "            with open(JSON_FILE_PATH, 'r') as f:\n",
        "                # Count the total number of lines to set up the progress bar correctly\n",
        "                total_lines = sum(1 for line in f)\n",
        "                f.seek(0)  # Rewind the file to the beginning\n",
        "\n",
        "                # --- Iterate through each data point with a progress bar ---\n",
        "                for i, line in enumerate(tqdm(f, total=total_lines, desc=\"Processing documents\", unit=\"doc\")):\n",
        "                    line = line.strip()\n",
        "                    if not line:\n",
        "                        continue # Skip blank lines\n",
        "\n",
        "                    data_point = json.loads(line)\n",
        "\n",
        "                    # Extract the 'original_text' and other metadata from the data point\n",
        "                    document_id = data_point.get(\"id\", f\"doc_{i+1}\")\n",
        "                    original_document = data_point.get(\"original_text\", \"\")\n",
        "\n",
        "                    if not original_document:\n",
        "                        tqdm.write(f\"  Warning: 'original_text' not found or is empty for data point {i+1}. Skipping.\")\n",
        "                        continue\n",
        "\n",
        "                    # --- OPTIMIZATION: Calculate document embeddings only ONCE ---\n",
        "                    sentences_list, embeddings_array = get_sentence_embeddings(original_document, batch_size=8)\n",
        "\n",
        "                    # --- Combined Extractive Summarization ---\n",
        "                    combined_summary = combined_extractive_summary_optimized(\n",
        "                        sentences_list,\n",
        "                        embeddings_array,\n",
        "                        total_summary_sentences=6,\n",
        "                        centroid_sentences_to_propose=7,\n",
        "                        kmeans_clusters_to_propose=5,\n",
        "                        kmeans_sentences_per_cluster_to_propose=1\n",
        "                    )\n",
        "\n",
        "                    if combined_summary:\n",
        "                        summary_text = \" \".join(combined_summary)\n",
        "                    else:\n",
        "                        summary_text = \"\"\n",
        "\n",
        "                    # Append the result to the list of all summaries\n",
        "                    summary_entry = {\n",
        "                        \"document_id\": document_id,\n",
        "                        \"summary_text\": summary_text,\n",
        "                        \"summary_sentences\": combined_summary\n",
        "                    }\n",
        "                    all_summaries.append(summary_entry)\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"\\nAll summarization processes complete.\")\n",
        "            print(f\"Writing all {len(all_summaries)} summaries to '{OUTPUT_FILE_PATH}'...\")\n",
        "\n",
        "            # --- Store all summaries in a new JSON file ---\n",
        "            try:\n",
        "                with open(OUTPUT_FILE_PATH, 'w') as out_f:\n",
        "                    json.dump(all_summaries, out_f, indent=4)\n",
        "                print(f\"\\nSuccessfully wrote summaries to '{OUTPUT_FILE_PATH}'.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error writing to output JSON file: {e}\")\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error: Failed to decode JSON from '{JSON_FILE_PATH}'. Check line {i+1} for invalid JSON format. Error: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FV-jZARlVL2e",
        "outputId": "85d619e2-b62f-47ae-cf42-e62872655dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Longformer model and tokenizer...\n",
            "Using device: cuda\n",
            "Longformer model loaded.\n",
            "\n",
            "Processing JSONL file 'govreport_tfidf_vscode2/test.json'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing documents:   0%|          | 0/973 [00:00<?, ?doc/s]\n",
            "  Embedding sentences:   0%|          | 0/54 [00:00<?, ?it/s]\u001b[AInput ids are automatically padded to be a multiple of `config.attention_window`: 512\n",
            "\n",
            "  Embedding sentences:   2%|▏         | 1/54 [00:01<00:55,  1.05s/it]\u001b[A\n",
            "  Embedding sentences:   4%|▎         | 2/54 [00:01<00:32,  1.58it/s]\u001b[A\n",
            "  Embedding sentences:   6%|▌         | 3/54 [00:01<00:25,  2.00it/s]\u001b[A\n",
            "  Embedding sentences:   7%|▋         | 4/54 [00:02<00:22,  2.26it/s]\u001b[A\n",
            "  Embedding sentences:   9%|▉         | 5/54 [00:02<00:19,  2.46it/s]\u001b[A\n",
            "  Embedding sentences:  11%|█         | 6/54 [00:02<00:18,  2.60it/s]\u001b[A\n",
            "  Embedding sentences:  13%|█▎        | 7/54 [00:03<00:17,  2.68it/s]\u001b[A\n",
            "  Embedding sentences:  15%|█▍        | 8/54 [00:03<00:16,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  17%|█▋        | 9/54 [00:03<00:16,  2.79it/s]\u001b[A\n",
            "  Embedding sentences:  19%|█▊        | 10/54 [00:04<00:15,  2.80it/s]\u001b[A\n",
            "  Embedding sentences:  20%|██        | 11/54 [00:04<00:15,  2.82it/s]\u001b[A\n",
            "  Embedding sentences:  22%|██▏       | 12/54 [00:04<00:14,  2.84it/s]\u001b[A\n",
            "  Embedding sentences:  24%|██▍       | 13/54 [00:05<00:14,  2.85it/s]\u001b[A\n",
            "  Embedding sentences:  26%|██▌       | 14/54 [00:05<00:13,  2.86it/s]\u001b[A\n",
            "  Embedding sentences:  28%|██▊       | 15/54 [00:05<00:13,  2.86it/s]\u001b[A\n",
            "  Embedding sentences:  30%|██▉       | 16/54 [00:06<00:13,  2.87it/s]\u001b[A\n",
            "  Embedding sentences:  31%|███▏      | 17/54 [00:06<00:12,  2.87it/s]\u001b[A\n",
            "  Embedding sentences:  33%|███▎      | 18/54 [00:06<00:12,  2.88it/s]\u001b[A\n",
            "  Embedding sentences:  35%|███▌      | 19/54 [00:07<00:12,  2.89it/s]\u001b[A\n",
            "  Embedding sentences:  37%|███▋      | 20/54 [00:07<00:11,  2.89it/s]\u001b[A\n",
            "  Embedding sentences:  39%|███▉      | 21/54 [00:07<00:11,  2.89it/s]\u001b[A\n",
            "  Embedding sentences:  41%|████      | 22/54 [00:08<00:11,  2.89it/s]\u001b[A\n",
            "  Embedding sentences:  43%|████▎     | 23/54 [00:08<00:10,  2.88it/s]\u001b[A\n",
            "  Embedding sentences:  44%|████▍     | 24/54 [00:09<00:10,  2.88it/s]\u001b[A\n",
            "  Embedding sentences:  46%|████▋     | 25/54 [00:09<00:10,  2.88it/s]\u001b[A\n",
            "  Embedding sentences:  48%|████▊     | 26/54 [00:09<00:09,  2.88it/s]\u001b[A\n",
            "  Embedding sentences:  50%|█████     | 27/54 [00:10<00:09,  2.89it/s]\u001b[A\n",
            "  Embedding sentences:  52%|█████▏    | 28/54 [00:10<00:09,  2.89it/s]\u001b[A\n",
            "  Embedding sentences:  54%|█████▎    | 29/54 [00:10<00:08,  2.89it/s]\u001b[A\n",
            "  Embedding sentences:  56%|█████▌    | 30/54 [00:11<00:08,  2.89it/s]\u001b[A\n",
            "  Embedding sentences:  57%|█████▋    | 31/54 [00:11<00:07,  2.89it/s]\u001b[A\n",
            "  Embedding sentences:  59%|█████▉    | 32/54 [00:11<00:07,  2.89it/s]\u001b[A\n",
            "  Embedding sentences:  61%|██████    | 33/54 [00:12<00:07,  2.88it/s]\u001b[A\n",
            "  Embedding sentences:  63%|██████▎   | 34/54 [00:12<00:06,  2.88it/s]\u001b[A\n",
            "  Embedding sentences:  65%|██████▍   | 35/54 [00:12<00:06,  2.87it/s]\u001b[A\n",
            "  Embedding sentences:  67%|██████▋   | 36/54 [00:13<00:06,  2.88it/s]\u001b[A\n",
            "  Embedding sentences:  69%|██████▊   | 37/54 [00:13<00:05,  2.88it/s]\u001b[A\n",
            "  Embedding sentences:  70%|███████   | 38/54 [00:13<00:05,  2.87it/s]\u001b[A\n",
            "  Embedding sentences:  72%|███████▏  | 39/54 [00:14<00:05,  2.86it/s]\u001b[A\n",
            "  Embedding sentences:  74%|███████▍  | 40/54 [00:14<00:04,  2.87it/s]\u001b[A\n",
            "  Embedding sentences:  76%|███████▌  | 41/54 [00:14<00:04,  2.87it/s]\u001b[A\n",
            "  Embedding sentences:  78%|███████▊  | 42/54 [00:15<00:04,  2.87it/s]\u001b[A\n",
            "  Embedding sentences:  80%|███████▉  | 43/54 [00:15<00:03,  2.86it/s]\u001b[A\n",
            "  Embedding sentences:  81%|████████▏ | 44/54 [00:15<00:03,  2.86it/s]\u001b[A\n",
            "  Embedding sentences:  83%|████████▎ | 45/54 [00:16<00:03,  2.86it/s]\u001b[A\n",
            "  Embedding sentences:  85%|████████▌ | 46/54 [00:16<00:02,  2.84it/s]\u001b[A\n",
            "  Embedding sentences:  87%|████████▋ | 47/54 [00:17<00:02,  2.84it/s]\u001b[A\n",
            "  Embedding sentences:  89%|████████▉ | 48/54 [00:17<00:02,  2.82it/s]\u001b[A\n",
            "  Embedding sentences:  91%|█████████ | 49/54 [00:17<00:01,  2.83it/s]\u001b[A\n",
            "  Embedding sentences:  93%|█████████▎| 50/54 [00:18<00:01,  2.82it/s]\u001b[A\n",
            "  Embedding sentences:  94%|█████████▍| 51/54 [00:18<00:01,  2.82it/s]\u001b[A\n",
            "  Embedding sentences:  96%|█████████▋| 52/54 [00:18<00:00,  2.82it/s]\u001b[A\n",
            "  Embedding sentences:  98%|█████████▊| 53/54 [00:19<00:00,  2.83it/s]\u001b[A\n",
            "  Embedding sentences: 100%|██████████| 54/54 [00:19<00:00,  3.03it/s]\u001b[A\n",
            "                                                                      \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Combined Extractive Summarization ---\n",
            "\n",
            "--- Starting Centroid-Based Summarization ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing documents:   0%|          | 1/973 [00:22<6:03:40, 22.45s/doc]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Centroid-Based Summarization Complete ---\n",
            "  Centroid proposed 7 candidates.\n",
            "\n",
            "--- Starting K-Means Based Summarization ---\n",
            "--- K-Means Based Summarization Complete ---\n",
            "  K-Means proposed 5 candidates.\n",
            "  Total unique candidates: 12. Extracting 6 for combined summary.\n",
            "--- Combined Extractive Summarization Complete ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  Embedding sentences:   0%|          | 0/44 [00:00<?, ?it/s]\u001b[A\n",
            "  Embedding sentences:   2%|▏         | 1/44 [00:00<00:17,  2.42it/s]\u001b[A\n",
            "  Embedding sentences:   5%|▍         | 2/44 [00:00<00:15,  2.65it/s]\u001b[A\n",
            "  Embedding sentences:   7%|▋         | 3/44 [00:01<00:14,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:   9%|▉         | 4/44 [00:01<00:14,  2.76it/s]\u001b[A\n",
            "  Embedding sentences:  11%|█▏        | 5/44 [00:01<00:13,  2.79it/s]\u001b[A\n",
            "  Embedding sentences:  14%|█▎        | 6/44 [00:02<00:13,  2.81it/s]\u001b[A\n",
            "  Embedding sentences:  16%|█▌        | 7/44 [00:02<00:13,  2.81it/s]\u001b[A\n",
            "  Embedding sentences:  18%|█▊        | 8/44 [00:02<00:12,  2.82it/s]\u001b[A\n",
            "  Embedding sentences:  20%|██        | 9/44 [00:03<00:12,  2.83it/s]\u001b[A\n",
            "  Embedding sentences:  23%|██▎       | 10/44 [00:03<00:12,  2.83it/s]\u001b[A\n",
            "  Embedding sentences:  25%|██▌       | 11/44 [00:03<00:11,  2.83it/s]\u001b[A\n",
            "  Embedding sentences:  27%|██▋       | 12/44 [00:04<00:11,  2.83it/s]\u001b[A\n",
            "  Embedding sentences:  30%|██▉       | 13/44 [00:04<00:10,  2.83it/s]\u001b[A\n",
            "  Embedding sentences:  32%|███▏      | 14/44 [00:05<00:10,  2.83it/s]\u001b[A\n",
            "  Embedding sentences:  34%|███▍      | 15/44 [00:05<00:10,  2.83it/s]\u001b[A\n",
            "  Embedding sentences:  36%|███▋      | 16/44 [00:05<00:09,  2.82it/s]\u001b[A\n",
            "  Embedding sentences:  39%|███▊      | 17/44 [00:06<00:09,  2.82it/s]\u001b[A\n",
            "  Embedding sentences:  41%|████      | 18/44 [00:06<00:09,  2.82it/s]\u001b[A\n",
            "  Embedding sentences:  43%|████▎     | 19/44 [00:06<00:08,  2.81it/s]\u001b[A\n",
            "  Embedding sentences:  45%|████▌     | 20/44 [00:07<00:08,  2.82it/s]\u001b[A\n",
            "  Embedding sentences:  48%|████▊     | 21/44 [00:07<00:08,  2.81it/s]\u001b[A\n",
            "  Embedding sentences:  50%|█████     | 22/44 [00:07<00:07,  2.81it/s]\u001b[A\n",
            "  Embedding sentences:  52%|█████▏    | 23/44 [00:08<00:07,  2.80it/s]\u001b[A\n",
            "  Embedding sentences:  55%|█████▍    | 24/44 [00:08<00:07,  2.79it/s]\u001b[A\n",
            "  Embedding sentences:  57%|█████▋    | 25/44 [00:08<00:06,  2.79it/s]\u001b[A\n",
            "  Embedding sentences:  59%|█████▉    | 26/44 [00:09<00:06,  2.79it/s]\u001b[A\n",
            "  Embedding sentences:  61%|██████▏   | 27/44 [00:09<00:06,  2.80it/s]\u001b[A\n",
            "  Embedding sentences:  64%|██████▎   | 28/44 [00:10<00:05,  2.79it/s]\u001b[A\n",
            "  Embedding sentences:  66%|██████▌   | 29/44 [00:10<00:05,  2.80it/s]\u001b[A\n",
            "  Embedding sentences:  68%|██████▊   | 30/44 [00:10<00:04,  2.81it/s]\u001b[A\n",
            "  Embedding sentences:  70%|███████   | 31/44 [00:11<00:04,  2.80it/s]\u001b[A\n",
            "  Embedding sentences:  73%|███████▎  | 32/44 [00:11<00:04,  2.80it/s]\u001b[A\n",
            "  Embedding sentences:  75%|███████▌  | 33/44 [00:11<00:03,  2.80it/s]\u001b[A\n",
            "  Embedding sentences:  77%|███████▋  | 34/44 [00:12<00:03,  2.80it/s]\u001b[A\n",
            "  Embedding sentences:  80%|███████▉  | 35/44 [00:12<00:03,  2.81it/s]\u001b[A\n",
            "  Embedding sentences:  82%|████████▏ | 36/44 [00:12<00:02,  2.80it/s]\u001b[A\n",
            "  Embedding sentences:  84%|████████▍ | 37/44 [00:13<00:02,  2.80it/s]\u001b[A\n",
            "  Embedding sentences:  86%|████████▋ | 38/44 [00:13<00:02,  2.81it/s]\u001b[A\n",
            "  Embedding sentences:  89%|████████▊ | 39/44 [00:13<00:01,  2.80it/s]\u001b[A\n",
            "  Embedding sentences:  91%|█████████ | 40/44 [00:14<00:01,  2.80it/s]\u001b[A\n",
            "  Embedding sentences:  93%|█████████▎| 41/44 [00:14<00:01,  2.80it/s]\u001b[A\n",
            "  Embedding sentences:  95%|█████████▌| 42/44 [00:14<00:00,  2.79it/s]\u001b[A\n",
            "  Embedding sentences:  98%|█████████▊| 43/44 [00:15<00:00,  2.80it/s]\u001b[A\n",
            "                                                                      \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Combined Extractive Summarization ---\n",
            "\n",
            "--- Starting Centroid-Based Summarization ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing documents:   0%|          | 2/973 [00:40<5:19:56, 19.77s/doc]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Centroid-Based Summarization Complete ---\n",
            "  Centroid proposed 7 candidates.\n",
            "\n",
            "--- Starting K-Means Based Summarization ---\n",
            "--- K-Means Based Summarization Complete ---\n",
            "  K-Means proposed 5 candidates.\n",
            "  Total unique candidates: 11. Extracting 6 for combined summary.\n",
            "--- Combined Extractive Summarization Complete ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  Embedding sentences:   0%|          | 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "  Embedding sentences:   2%|▏         | 1/45 [00:00<00:17,  2.51it/s]\u001b[A\n",
            "  Embedding sentences:   4%|▍         | 2/45 [00:00<00:16,  2.68it/s]\u001b[A\n",
            "  Embedding sentences:   7%|▋         | 3/45 [00:01<00:15,  2.72it/s]\u001b[A\n",
            "  Embedding sentences:   9%|▉         | 4/45 [00:01<00:15,  2.73it/s]\u001b[A\n",
            "  Embedding sentences:  11%|█         | 5/45 [00:01<00:14,  2.76it/s]\u001b[A\n",
            "  Embedding sentences:  13%|█▎        | 6/45 [00:02<00:14,  2.76it/s]\u001b[A\n",
            "  Embedding sentences:  16%|█▌        | 7/45 [00:02<00:13,  2.77it/s]\u001b[A\n",
            "  Embedding sentences:  18%|█▊        | 8/45 [00:02<00:13,  2.76it/s]\u001b[A\n",
            "  Embedding sentences:  20%|██        | 9/45 [00:03<00:13,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  22%|██▏       | 10/45 [00:03<00:12,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  24%|██▍       | 11/45 [00:04<00:12,  2.76it/s]\u001b[A\n",
            "  Embedding sentences:  27%|██▋       | 12/45 [00:04<00:11,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  29%|██▉       | 13/45 [00:04<00:11,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  31%|███       | 14/45 [00:05<00:11,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  33%|███▎      | 15/45 [00:05<00:10,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  36%|███▌      | 16/45 [00:05<00:10,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  38%|███▊      | 17/45 [00:06<00:10,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  40%|████      | 18/45 [00:06<00:09,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  42%|████▏     | 19/45 [00:06<00:09,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  44%|████▍     | 20/45 [00:07<00:09,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  47%|████▋     | 21/45 [00:07<00:08,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  49%|████▉     | 22/45 [00:08<00:08,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  51%|█████     | 23/45 [00:08<00:08,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  53%|█████▎    | 24/45 [00:08<00:07,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  56%|█████▌    | 25/45 [00:09<00:07,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  58%|█████▊    | 26/45 [00:09<00:06,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  60%|██████    | 27/45 [00:09<00:06,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  62%|██████▏   | 28/45 [00:10<00:06,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  64%|██████▍   | 29/45 [00:10<00:05,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  67%|██████▋   | 30/45 [00:10<00:05,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  69%|██████▉   | 31/45 [00:11<00:05,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  71%|███████   | 32/45 [00:11<00:04,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  73%|███████▎  | 33/45 [00:12<00:04,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  76%|███████▌  | 34/45 [00:12<00:04,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  78%|███████▊  | 35/45 [00:12<00:03,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  80%|████████  | 36/45 [00:13<00:03,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  82%|████████▏ | 37/45 [00:13<00:02,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  84%|████████▍ | 38/45 [00:13<00:02,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  87%|████████▋ | 39/45 [00:14<00:02,  2.68it/s]\u001b[A\n",
            "  Embedding sentences:  89%|████████▉ | 40/45 [00:14<00:01,  2.67it/s]\u001b[A\n",
            "  Embedding sentences:  91%|█████████ | 41/45 [00:15<00:01,  2.64it/s]\u001b[A\n",
            "  Embedding sentences:  93%|█████████▎| 42/45 [00:15<00:01,  2.65it/s]\u001b[A\n",
            "  Embedding sentences:  96%|█████████▌| 43/45 [00:15<00:00,  2.62it/s]\u001b[A\n",
            "  Embedding sentences:  98%|█████████▊| 44/45 [00:16<00:00,  2.63it/s]\u001b[A\n",
            "  Embedding sentences: 100%|██████████| 45/45 [00:16<00:00,  2.74it/s]\u001b[A\n",
            "                                                                      \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Combined Extractive Summarization ---\n",
            "\n",
            "--- Starting Centroid-Based Summarization ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing documents:   0%|          | 3/973 [01:01<5:27:48, 20.28s/doc]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Centroid-Based Summarization Complete ---\n",
            "  Centroid proposed 7 candidates.\n",
            "\n",
            "--- Starting K-Means Based Summarization ---\n",
            "--- K-Means Based Summarization Complete ---\n",
            "  K-Means proposed 5 candidates.\n",
            "  Total unique candidates: 11. Extracting 6 for combined summary.\n",
            "--- Combined Extractive Summarization Complete ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  Embedding sentences:   0%|          | 0/43 [00:00<?, ?it/s]\u001b[A\n",
            "  Embedding sentences:   2%|▏         | 1/43 [00:00<00:17,  2.36it/s]\u001b[A\n",
            "  Embedding sentences:   5%|▍         | 2/43 [00:00<00:15,  2.59it/s]\u001b[A\n",
            "  Embedding sentences:   7%|▋         | 3/43 [00:01<00:15,  2.66it/s]\u001b[A\n",
            "  Embedding sentences:   9%|▉         | 4/43 [00:01<00:14,  2.68it/s]\u001b[A\n",
            "  Embedding sentences:  12%|█▏        | 5/43 [00:01<00:14,  2.71it/s]\u001b[A\n",
            "  Embedding sentences:  14%|█▍        | 6/43 [00:02<00:13,  2.71it/s]\u001b[A\n",
            "  Embedding sentences:  16%|█▋        | 7/43 [00:02<00:13,  2.72it/s]\u001b[A\n",
            "  Embedding sentences:  19%|█▊        | 8/43 [00:02<00:12,  2.73it/s]\u001b[A\n",
            "  Embedding sentences:  21%|██        | 9/43 [00:03<00:12,  2.73it/s]\u001b[A\n",
            "  Embedding sentences:  23%|██▎       | 10/43 [00:03<00:12,  2.73it/s]\u001b[A\n",
            "  Embedding sentences:  26%|██▌       | 11/43 [00:04<00:11,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  28%|██▊       | 12/43 [00:04<00:11,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  30%|███       | 13/43 [00:04<00:10,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  33%|███▎      | 14/43 [00:05<00:10,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  35%|███▍      | 15/43 [00:05<00:10,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  37%|███▋      | 16/43 [00:05<00:09,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  40%|███▉      | 17/43 [00:06<00:09,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  42%|████▏     | 18/43 [00:06<00:09,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  44%|████▍     | 19/43 [00:06<00:08,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  47%|████▋     | 20/43 [00:07<00:08,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  49%|████▉     | 21/43 [00:07<00:08,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  51%|█████     | 22/43 [00:08<00:07,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  53%|█████▎    | 23/43 [00:08<00:07,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  56%|█████▌    | 24/43 [00:08<00:06,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  58%|█████▊    | 25/43 [00:09<00:06,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  60%|██████    | 26/43 [00:09<00:06,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  63%|██████▎   | 27/43 [00:09<00:05,  2.73it/s]\u001b[A\n",
            "  Embedding sentences:  65%|██████▌   | 28/43 [00:10<00:05,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  67%|██████▋   | 29/43 [00:10<00:05,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  70%|██████▉   | 30/43 [00:11<00:04,  2.72it/s]\u001b[A\n",
            "  Embedding sentences:  72%|███████▏  | 31/43 [00:11<00:04,  2.72it/s]\u001b[A\n",
            "  Embedding sentences:  74%|███████▍  | 32/43 [00:11<00:04,  2.72it/s]\u001b[A\n",
            "  Embedding sentences:  77%|███████▋  | 33/43 [00:12<00:03,  2.73it/s]\u001b[A\n",
            "  Embedding sentences:  79%|███████▉  | 34/43 [00:12<00:03,  2.73it/s]\u001b[A\n",
            "  Embedding sentences:  81%|████████▏ | 35/43 [00:12<00:02,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  84%|████████▎ | 36/43 [00:13<00:02,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  86%|████████▌ | 37/43 [00:13<00:02,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  88%|████████▊ | 38/43 [00:13<00:01,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  91%|█████████ | 39/43 [00:14<00:01,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  93%|█████████▎| 40/43 [00:14<00:01,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  95%|█████████▌| 41/43 [00:15<00:00,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  98%|█████████▊| 42/43 [00:15<00:00,  2.75it/s]\u001b[A\n",
            "  Embedding sentences: 100%|██████████| 43/43 [00:15<00:00,  2.75it/s]\u001b[A\n",
            "                                                                      \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Combined Extractive Summarization ---\n",
            "\n",
            "--- Starting Centroid-Based Summarization ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing documents:   0%|          | 4/973 [01:19<5:14:37, 19.48s/doc]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Centroid-Based Summarization Complete ---\n",
            "  Centroid proposed 7 candidates.\n",
            "\n",
            "--- Starting K-Means Based Summarization ---\n",
            "--- K-Means Based Summarization Complete ---\n",
            "  K-Means proposed 5 candidates.\n",
            "  Total unique candidates: 12. Extracting 6 for combined summary.\n",
            "--- Combined Extractive Summarization Complete ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  Embedding sentences:   0%|          | 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "  Embedding sentences:   2%|▏         | 1/48 [00:00<00:19,  2.43it/s]\u001b[A\n",
            "  Embedding sentences:   4%|▍         | 2/48 [00:00<00:17,  2.64it/s]\u001b[A\n",
            "  Embedding sentences:   6%|▋         | 3/48 [00:01<00:16,  2.69it/s]\u001b[A\n",
            "  Embedding sentences:   8%|▊         | 4/48 [00:01<00:16,  2.72it/s]\u001b[A\n",
            "  Embedding sentences:  10%|█         | 5/48 [00:01<00:15,  2.74it/s]\u001b[A\n",
            "  Embedding sentences:  12%|█▎        | 6/48 [00:02<00:15,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  15%|█▍        | 7/48 [00:02<00:14,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  17%|█▋        | 8/48 [00:02<00:14,  2.77it/s]\u001b[A\n",
            "  Embedding sentences:  19%|█▉        | 9/48 [00:03<00:14,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  21%|██        | 10/48 [00:03<00:13,  2.76it/s]\u001b[A\n",
            "  Embedding sentences:  23%|██▎       | 11/48 [00:04<00:13,  2.76it/s]\u001b[A\n",
            "  Embedding sentences:  25%|██▌       | 12/48 [00:04<00:13,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  27%|██▋       | 13/48 [00:04<00:12,  2.76it/s]\u001b[A\n",
            "  Embedding sentences:  29%|██▉       | 14/48 [00:05<00:12,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  31%|███▏      | 15/48 [00:05<00:11,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  33%|███▎      | 16/48 [00:05<00:11,  2.76it/s]\u001b[A\n",
            "  Embedding sentences:  35%|███▌      | 17/48 [00:06<00:11,  2.75it/s]\u001b[A\n",
            "  Embedding sentences:  38%|███▊      | 18/48 [00:06<00:10,  2.75it/s]\u001b[A\n",
            "Processing documents:   0%|          | 4/973 [01:28<5:56:03, 22.05s/doc]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3913815244.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                     \u001b[0;31m# --- OPTIMIZATION: Calculate document embeddings only ONCE ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                     \u001b[0msentences_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sentence_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_document\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0;31m# --- Combined Extractive Summarization ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3913815244.py\u001b[0m in \u001b[0;36mget_sentence_embeddings\u001b[0;34m(text, batch_size)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mcls_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mall_sentence_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generating extractive summay for 100 samples along with scores"
      ],
      "metadata": {
        "id": "FV34p1aibc_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LongformerModel, LongformerTokenizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cdist\n",
        "import numpy as np\n",
        "import spacy\n",
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "# --- Evaluation libraries for ROUGE and BERTScore ---\n",
        "import evaluate\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Install these if you haven't already:\n",
        "# pip install evaluate\n",
        "# pip install rouge_score\n",
        "# pip install bert-score\n",
        "# pip install sentence-transformers\n",
        "# pip install spacy && python -m spacy download en_core_web_sm\n",
        "\n",
        "# --- Constants ---\n",
        "JSON_FILE_PATH = \"govreport_tfidf_vscode2/test.json\"\n",
        "OUTPUT_FILE_PATH = \"summaries_with_scores_100_samples.json\"\n",
        "SAMPLES_TO_PROCESS = 100\n",
        "\n",
        "# --- Load NLP and Evaluation Models ---\n",
        "print(\"Loading Spacy, Sentence-BERT, ROUGE, and BERTScore models...\")\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    print(\"Downloading 'en_core_web_sm' model. This will happen only once.\")\n",
        "    spacy.cli.download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sentence-BERT model for similarity\n",
        "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# ROUGE and BERTScore evaluators\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "bertscore = evaluate.load(\"bertscore\")\n",
        "print(\"Evaluation models loaded.\")\n",
        "\n",
        "# --- Load Longformer Model and Tokenizer ---\n",
        "print(\"Loading Longformer model and tokenizer...\")\n",
        "model_name = 'allenai/longformer-base-4096'\n",
        "tokenizer = LongformerTokenizer.from_pretrained(model_name)\n",
        "model = LongformerModel.from_pretrained(model_name)\n",
        "\n",
        "# --- Set Device (GPU if available, else CPU) ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.eval()\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "print(\"Longformer model loaded.\")\n",
        "\n",
        "# --- Helper Function to calculate summary length ---\n",
        "def calculate_summary_length(num_original_sentences, percentage=0.10):\n",
        "    if num_original_sentences <= 0:\n",
        "        return 1\n",
        "    summary_len = math.ceil(num_original_sentences * percentage)\n",
        "    return max(1, int(summary_len))\n",
        "\n",
        "# --- Helper Function for Sentence Embeddings ---\n",
        "def get_sentence_embeddings(text, batch_size=4):\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
        "    if not sentences:\n",
        "        return [], np.array([])\n",
        "    all_sentence_embeddings = []\n",
        "    for i in range(0, len(sentences), batch_size):\n",
        "        batch_sentences = sentences[i:i + batch_size]\n",
        "        try:\n",
        "            inputs = tokenizer(\n",
        "                batch_sentences,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=tokenizer.model_max_length\n",
        "            ).to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            all_sentence_embeddings.extend(cls_embeddings)\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"Error processing batch of sentences (index {i}-{i+len(batch_sentences)-1}): {e}\")\n",
        "            all_sentence_embeddings.extend([np.zeros(model.config.hidden_size)] * len(batch_sentences))\n",
        "            continue\n",
        "    return sentences, np.array(all_sentence_embeddings)\n",
        "\n",
        "# --- Evaluation Functions ---\n",
        "def split_sentences_eval(text):\n",
        "    return [sent.text.strip() for sent in nlp(text).sents]\n",
        "\n",
        "def calculate_paragraph_similarity(generated_summary, reference_summary, threshold=0.5):\n",
        "    sents_gen = split_sentences_eval(generated_summary)\n",
        "    sents_ref = split_sentences_eval(reference_summary)\n",
        "    if not sents_gen or not sents_ref:\n",
        "        return 0.0\n",
        "\n",
        "    emb_gen = sbert_model.encode(sents_gen, convert_to_tensor=True)\n",
        "    emb_ref = sbert_model.encode(sents_ref, convert_to_tensor=True)\n",
        "\n",
        "    matched = 0\n",
        "    for i in range(len(sents_ref)):\n",
        "        sims = util.cos_sim(emb_ref[i], emb_gen)[0]\n",
        "        if sims.max().item() >= threshold:\n",
        "            matched += 1\n",
        "\n",
        "    coverage = matched / len(sents_ref)\n",
        "    return round(coverage, 3)\n",
        "\n",
        "def calculate_rouge_scores(generated_summary, reference_summary):\n",
        "    if not generated_summary or not reference_summary:\n",
        "        return {}\n",
        "    results = rouge.compute(predictions=[generated_summary], references=[reference_summary])\n",
        "    return {k: round(v, 4) for k, v in results.items()}\n",
        "\n",
        "def calculate_bert_scores(generated_summary, reference_summary):\n",
        "    if not generated_summary or not reference_summary:\n",
        "        return {}\n",
        "    results = bertscore.compute(predictions=[generated_summary], references=[reference_summary], lang=\"en\", model_type=\"distilbert-base-uncased\")\n",
        "    return {\n",
        "        'bertscore_precision': round(results['precision'][0], 4),\n",
        "        'bertscore_recall': round(results['recall'][0], 4),\n",
        "        'bertscore_f1': round(results['f1'][0], 4)\n",
        "    }\n",
        "\n",
        "# --- Summarization functions (rest of the code is unchanged) ---\n",
        "def centroid_summarization_optimized(sentences, embeddings, num_sentences=3):\n",
        "    if not sentences or embeddings.shape[0] == 0:\n",
        "        tqdm.write(\"  No sentences or embeddings provided. Cannot summarize.\")\n",
        "        return [], []\n",
        "    if num_sentences <= 0:\n",
        "        tqdm.write(\"  Number of sentences for summary must be positive.\")\n",
        "        return [], []\n",
        "    num_sentences_to_extract = min(num_sentences, len(sentences))\n",
        "    document_centroid = np.mean(embeddings, axis=0)\n",
        "    similarities = cosine_similarity(embeddings, document_centroid.reshape(1, -1)).flatten()\n",
        "    summary_sentences_mmr = []\n",
        "    selected_indices = set()\n",
        "    ranked_initial_indices = np.argsort(similarities)[::-1]\n",
        "    for _ in range(num_sentences_to_extract):\n",
        "        best_sentence_idx = -1\n",
        "        max_mmr_score = -1\n",
        "        for i in ranked_initial_indices:\n",
        "            if i not in selected_indices:\n",
        "                relevance = similarities[i]\n",
        "                if not selected_indices:\n",
        "                    mmr_score = relevance\n",
        "                else:\n",
        "                    diversity_scores = cosine_similarity(embeddings[i].reshape(1, -1), embeddings[list(selected_indices)])\n",
        "                    redundancy = np.max(diversity_scores)\n",
        "                    lambda_param = 0.5\n",
        "                    mmr_score = lambda_param * relevance - (1 - lambda_param) * redundancy\n",
        "                if mmr_score > max_mmr_score:\n",
        "                    max_mmr_score = mmr_score\n",
        "                    best_sentence_idx = i\n",
        "        if best_sentence_idx != -1:\n",
        "            summary_sentences_mmr.append((sentences[best_sentence_idx], best_sentence_idx))\n",
        "            selected_indices.add(best_sentence_idx)\n",
        "            ranked_initial_indices = ranked_initial_indices[ranked_initial_indices != best_sentence_idx]\n",
        "        else:\n",
        "            break\n",
        "    summary_sentences_mmr.sort(key=lambda x: x[1])\n",
        "    final_summary_sents = [s[0] for s in summary_sentences_mmr]\n",
        "    final_summary_indices = [s[1] for s in summary_sentences_mmr]\n",
        "    return final_summary_sents, final_summary_indices\n",
        "\n",
        "def kmeans_summarization_optimized(sentences, embeddings, num_clusters=25, num_sentences_per_cluster=1):\n",
        "    if not sentences or embeddings.shape[0] == 0:\n",
        "        tqdm.write(\"  No sentences or embeddings provided. Cannot summarize.\")\n",
        "        return [], []\n",
        "    if num_clusters <= 0 or num_sentences_per_cluster <= 0:\n",
        "        tqdm.write(\"  Number of clusters and sentences per cluster must be positive.\")\n",
        "        return [], []\n",
        "    effective_num_clusters = min(num_clusters, len(sentences))\n",
        "    if effective_num_clusters == 0:\n",
        "        tqdm.write(\"  Not enough sentences to form clusters.\")\n",
        "        return [], []\n",
        "    kmeans = KMeans(n_clusters=effective_num_clusters, random_state=42, n_init='auto')\n",
        "    kmeans.fit(embeddings)\n",
        "    clusters = kmeans.labels_\n",
        "    centroids = kmeans.cluster_centers_\n",
        "    summary_sentences_with_idx = []\n",
        "    selected_indices = set()\n",
        "    for i in range(effective_num_clusters):\n",
        "        cluster_sentence_indices = np.where(clusters == i)[0]\n",
        "        if len(cluster_sentence_indices) == 0:\n",
        "            continue\n",
        "        distances = cdist(embeddings[cluster_sentence_indices], centroids[i].reshape(1, -1), 'cosine').flatten()\n",
        "        sorted_cluster_indices = cluster_sentence_indices[np.argsort(distances)]\n",
        "        count_selected_from_cluster = 0\n",
        "        for original_idx in sorted_cluster_indices:\n",
        "            if original_idx not in selected_indices:\n",
        "                summary_sentences_with_idx.append((sentences[original_idx], original_idx))\n",
        "                selected_indices.add(original_idx)\n",
        "                count_selected_from_cluster += 1\n",
        "                if count_selected_from_cluster >= num_sentences_per_cluster:\n",
        "                    break\n",
        "    summary_sentences_with_idx.sort(key=lambda x: x[1])\n",
        "    final_summary_sents = [s[0] for s in summary_sentences_with_idx]\n",
        "    final_summary_indices = [s[1] for s in summary_sentences_with_idx]\n",
        "    return final_summary_sents, final_summary_indices\n",
        "\n",
        "def combined_extractive_summary_optimized(sentences, embeddings, total_summary_sentences=7,\n",
        "                                          centroid_sentences_to_propose=5,\n",
        "                                          kmeans_clusters_to_propose=4,\n",
        "                                          kmeans_sentences_per_cluster_to_propose=1,\n",
        "                                          lambda_param_mmr=0.7):\n",
        "    if not sentences or embeddings.shape[0] == 0:\n",
        "        tqdm.write(\"  No sentences or embeddings provided. Cannot generate combined summary.\")\n",
        "        return []\n",
        "    centroid_candidates_sents, centroid_candidates_indices = centroid_summarization_optimized(\n",
        "        sentences, embeddings, num_sentences=centroid_sentences_to_propose\n",
        "    )\n",
        "    kmeans_candidates_sents, kmeans_candidates_indices = kmeans_summarization_optimized(\n",
        "        sentences, embeddings, num_clusters=kmeans_clusters_to_propose, num_sentences_per_cluster=kmeans_sentences_per_cluster_to_propose\n",
        "    )\n",
        "    combined_candidates_map = {}\n",
        "    for idx, sent in zip(centroid_candidates_indices, centroid_candidates_sents):\n",
        "        combined_candidates_map[idx] = sent\n",
        "    for idx, sent in zip(kmeans_candidates_indices, kmeans_candidates_sents):\n",
        "        combined_candidates_map[idx] = sent\n",
        "    all_candidate_indices_sorted = sorted(combined_candidates_map.keys())\n",
        "    all_candidate_sentences = [combined_candidates_map[idx] for idx in all_candidate_indices_sorted]\n",
        "    all_candidate_embeddings = np.array([embeddings[idx] for idx in all_candidate_indices_sorted])\n",
        "    if not all_candidate_sentences or all_candidate_embeddings.shape[0] == 0:\n",
        "        tqdm.write(\"  No unique candidates found after combining. Cannot generate combined summary.\")\n",
        "        return []\n",
        "    num_sentences_to_extract = min(total_summary_sentences, len(all_candidate_sentences))\n",
        "    document_centroid = np.mean(embeddings, axis=0)\n",
        "    candidate_similarities = cosine_similarity(all_candidate_embeddings, document_centroid.reshape(1, -1)).flatten()\n",
        "    final_summary_sentences = []\n",
        "    selected_candidate_indices = set()\n",
        "    ranked_initial_candidate_indices = np.argsort(candidate_similarities)[::-1]\n",
        "    for _ in range(num_sentences_to_extract):\n",
        "        best_idx_in_candidates = -1\n",
        "        max_mmr_score = -1\n",
        "        for i_candidate in ranked_initial_candidate_indices:\n",
        "            if i_candidate not in selected_candidate_indices:\n",
        "                relevance = candidate_similarities[i_candidate]\n",
        "                if not selected_candidate_indices:\n",
        "                    mmr_score = relevance\n",
        "                else:\n",
        "                    diversity_scores = cosine_similarity(all_candidate_embeddings[i_candidate].reshape(1, -1),\n",
        "                                                         all_candidate_embeddings[list(selected_candidate_indices)])\n",
        "                    redundancy = np.max(diversity_scores)\n",
        "                    mmr_score = lambda_param_mmr * relevance - (1 - lambda_param_mmr) * redundancy\n",
        "                if mmr_score > max_mmr_score:\n",
        "                    max_mmr_score = mmr_score\n",
        "                    best_idx_in_candidates = i_candidate\n",
        "        if best_idx_in_candidates != -1:\n",
        "            final_summary_sentences.append((all_candidate_sentences[best_idx_in_candidates],\n",
        "                                            all_candidate_indices_sorted[best_idx_in_candidates]))\n",
        "            selected_candidate_indices.add(best_idx_in_candidates)\n",
        "            ranked_initial_candidate_indices = ranked_initial_candidate_indices[ranked_initial_candidate_indices != best_idx_in_candidates]\n",
        "        else:\n",
        "            break\n",
        "    final_summary_sentences.sort(key=lambda x: x[1])\n",
        "    final_summary = [s[0] for s in final_summary_sentences]\n",
        "    return final_summary\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        print(f\"Error: The file '{JSON_FILE_PATH}' was not found.\")\n",
        "        print(\"Please ensure the file path is correct and the file exists.\")\n",
        "    else:\n",
        "        all_summaries = []\n",
        "        try:\n",
        "            print(f\"\\nProcessing JSONL file '{JSON_FILE_PATH}' for the first {SAMPLES_TO_PROCESS} samples...\")\n",
        "\n",
        "            with open(JSON_FILE_PATH, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "                lines_to_process = lines[:SAMPLES_TO_PROCESS]\n",
        "                total_to_process = len(lines_to_process)\n",
        "\n",
        "                for i, line in enumerate(tqdm(lines_to_process, total=total_to_process, desc=\"Processing documents\", unit=\"doc\")):\n",
        "                    line = line.strip()\n",
        "                    if not line:\n",
        "                        continue\n",
        "\n",
        "                    data_point = json.loads(line)\n",
        "\n",
        "                    document_id = data_point.get(\"id\", f\"doc_{i+1}\")\n",
        "                    original_document = data_point.get(\"original_text\", \"\")\n",
        "                    reference_summary = data_point.get(\"extractive_summary\", \"\")\n",
        "\n",
        "                    if not original_document:\n",
        "                        tqdm.write(f\"  Warning: 'original_text' not found or is empty for data point {i+1}. Skipping.\")\n",
        "                        continue\n",
        "\n",
        "                    num_original_sentences = sum(1 for _ in nlp(original_document).sents)\n",
        "                    total_summary_sentences = calculate_summary_length(num_original_sentences, percentage=0.10)\n",
        "\n",
        "                    sentences_list, embeddings_array = get_sentence_embeddings(original_document, batch_size=8)\n",
        "\n",
        "                    if not sentences_list:\n",
        "                        tqdm.write(f\"  Warning: No sentences found for document {document_id}. Skipping summary generation.\")\n",
        "                        summary_text = \"\"\n",
        "                        combined_summary = []\n",
        "                    else:\n",
        "                        combined_summary = combined_extractive_summary_optimized(\n",
        "                            sentences_list,\n",
        "                            embeddings_array,\n",
        "                            total_summary_sentences=total_summary_sentences,\n",
        "                            centroid_sentences_to_propose=total_summary_sentences + 2,\n",
        "                            kmeans_clusters_to_propose=total_summary_sentences + 2,\n",
        "                            kmeans_sentences_per_cluster_to_propose=1\n",
        "                        )\n",
        "                        summary_text = \" \".join(combined_summary) if combined_summary else \"\"\n",
        "\n",
        "                    # --- Run Evaluation ---\n",
        "                    scores = {}\n",
        "                    if summary_text and reference_summary:\n",
        "                        # 1. Similarity Score\n",
        "                        scores['paragraph_similarity'] = calculate_paragraph_similarity(summary_text, reference_summary)\n",
        "                        # 2. ROUGE Scores\n",
        "                        scores['rouge'] = calculate_rouge_scores(summary_text, reference_summary)\n",
        "                        # 3. BERTScore\n",
        "                        scores['bertscore'] = calculate_bert_scores(summary_text, reference_summary)\n",
        "\n",
        "                    summary_entry = {\n",
        "                        \"document_id\": document_id,\n",
        "                        \"generated_summary_text\": summary_text,\n",
        "                        \"generated_summary_sentences\": combined_summary,\n",
        "                        \"reference_summary_text\": reference_summary,\n",
        "                        \"evaluation_scores\": scores\n",
        "                    }\n",
        "                    all_summaries.append(summary_entry)\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"\\nAll summarization and evaluation processes complete.\")\n",
        "            print(f\"Writing all {len(all_summaries)} summaries to '{OUTPUT_FILE_PATH}'...\")\n",
        "\n",
        "            try:\n",
        "                with open(OUTPUT_FILE_PATH, 'w') as out_f:\n",
        "                    json.dump(all_summaries, out_f, indent=4)\n",
        "                print(f\"\\nSuccessfully wrote summaries and scores to '{OUTPUT_FILE_PATH}'.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error writing to output JSON file: {e}\")\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error: Failed to decode JSON from '{JSON_FILE_PATH}'. Check for invalid JSON format. Error: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "lmBAUn6GbjCn",
        "outputId": "5de23290-b577-4fca-c65b-a63dd708740b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2867238283.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLongformerModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLongformerTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[0;31m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2108\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_VF\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfunctional\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2109\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# usort: skip # noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_add_docstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mUninitializedParameter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mUninitializedParameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# usort: skip # noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from torch.nn import (\n\u001b[1;32m     10\u001b[0m     \u001b[0mattention\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mThreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0madaptive\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdaptiveLogSoftmaxWithLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m from .batchnorm import (\n\u001b[1;32m     36\u001b[0m     \u001b[0mBatchNorm1d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/adaptive.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModuleList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_get_module_lock\u001b[0;34m(name)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P1sI9n_IW7Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##average scores of 100 samples of extractive summaries"
      ],
      "metadata": {
        "id": "3UToFhUw8qJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Define the path to the output file\n",
        "SCORES_FILE_PATH = \"summaries_with_scores_100_samples.json\"\n",
        "\n",
        "def calculate_average_scores(file_path):\n",
        "    \"\"\"\n",
        "    Reads a JSON file containing summary evaluation scores and calculates the average\n",
        "    for each metric across all samples.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Error: The file '{file_path}' was not found.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Failed to decode JSON from '{file_path}'. Please check the file format.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while reading the file: {e}\")\n",
        "        return\n",
        "\n",
        "    total_samples = len(data)\n",
        "    if total_samples == 0:\n",
        "        print(\"The file contains no samples to process.\")\n",
        "        return\n",
        "\n",
        "    # Initialize accumulators for all scores\n",
        "    total_scores = {\n",
        "        'paragraph_similarity': 0.0,\n",
        "        'rouge': {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0},\n",
        "        'bertscore': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}\n",
        "    }\n",
        "\n",
        "    # Counter for samples with valid scores\n",
        "    valid_samples_count = 0\n",
        "\n",
        "    print(f\"Processing {total_samples} samples from '{file_path}'...\")\n",
        "\n",
        "    # Iterate through each sample and accumulate the scores\n",
        "    for sample in data:\n",
        "        scores = sample.get('evaluation_scores')\n",
        "\n",
        "        if scores and scores.get('paragraph_similarity') is not None:\n",
        "            valid_samples_count += 1\n",
        "\n",
        "            # Accumulate paragraph similarity score\n",
        "            total_scores['paragraph_similarity'] += scores.get('paragraph_similarity', 0.0)\n",
        "\n",
        "            # Accumulate ROUGE scores\n",
        "            rouge_scores = scores.get('rouge', {})\n",
        "            total_scores['rouge']['rouge1'] += rouge_scores.get('rouge1', 0.0)\n",
        "            total_scores['rouge']['rouge2'] += rouge_scores.get('rouge2', 0.0)\n",
        "            total_scores['rouge']['rougeL'] += rouge_scores.get('rougeL', 0.0)\n",
        "\n",
        "            # Accumulate BERTScore scores\n",
        "            bert_scores = scores.get('bertscore', {})\n",
        "            total_scores['bertscore']['precision'] += bert_scores.get('bertscore_precision', 0.0)\n",
        "            total_scores['bertscore']['recall'] += bert_scores.get('bertscore_recall', 0.0)\n",
        "            total_scores['bertscore']['f1'] += bert_scores.get('bertscore_f1', 0.0)\n",
        "\n",
        "    if valid_samples_count == 0:\n",
        "        print(\"No valid evaluation scores found in the file.\")\n",
        "        return\n",
        "\n",
        "    # Calculate the average for each score\n",
        "    average_scores = {\n",
        "        'paragraph_similarity': round(total_scores['paragraph_similarity'] / valid_samples_count, 4),\n",
        "        'rouge': {\n",
        "            'rouge1': round(total_scores['rouge']['rouge1'] / valid_samples_count, 4),\n",
        "            'rouge2': round(total_scores['rouge']['rouge2'] / valid_samples_count, 4),\n",
        "            'rougeL': round(total_scores['rouge']['rougeL'] / valid_samples_count, 4)\n",
        "        },\n",
        "        'bertscore': {\n",
        "            'precision': round(total_scores['bertscore']['precision'] / valid_samples_count, 4),\n",
        "            'recall': round(total_scores['bertscore']['recall'] / valid_samples_count, 4),\n",
        "            'f1': round(total_scores['bertscore']['f1'] / valid_samples_count, 4)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Print the final results\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"           Average Evaluation Scores\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Number of samples with scores: {valid_samples_count}\")\n",
        "    print(\"\\n--- Paragraph Similarity ---\")\n",
        "    print(f\"Average Similarity Score: {average_scores['paragraph_similarity']:.4f}\")\n",
        "\n",
        "    print(\"\\n--- ROUGE Scores ---\")\n",
        "    print(f\"Average ROUGE-1:         {average_scores['rouge']['rouge1']:.4f}\")\n",
        "    print(f\"Average ROUGE-2:         {average_scores['rouge']['rouge2']:.4f}\")\n",
        "    print(f\"Average ROUGE-L:         {average_scores['rouge']['rougeL']:.4f}\")\n",
        "\n",
        "    print(\"\\n--- BERTScore ---\")\n",
        "    print(f\"Average BERTScore Precision: {average_scores['bertscore']['precision']:.4f}\")\n",
        "    print(f\"Average BERTScore Recall:    {average_scores['bertscore']['recall']:.4f}\")\n",
        "    print(f\"Average BERTScore F1:        {average_scores['bertscore']['f1']:.4f}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    calculate_average_scores(SCORES_FILE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_wgb-N28miQ",
        "outputId": "b758c468-e4bf-464c-b7ee-6712076214c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 100 samples from 'summaries_with_scores_100_samples.json'...\n",
            "\n",
            "========================================\n",
            "           Average Evaluation Scores\n",
            "========================================\n",
            "Number of samples with scores: 100\n",
            "\n",
            "--- Paragraph Similarity ---\n",
            "Average Similarity Score: 0.8766\n",
            "\n",
            "--- ROUGE Scores ---\n",
            "Average ROUGE-1:         0.4256\n",
            "Average ROUGE-2:         0.1889\n",
            "Average ROUGE-L:         0.2182\n",
            "\n",
            "--- BERTScore ---\n",
            "Average BERTScore Precision: 0.8049\n",
            "Average BERTScore Recall:    0.8284\n",
            "Average BERTScore F1:        0.8162\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of scores by Gemini ---\n",
        "\n",
        "Those are some very good scores! They indicate that the summarization model is performing quite well.\n",
        "\n",
        "Let's break down what each of those scores means:\n",
        "\n",
        "Paragraph Similarity\n",
        "Average Similarity Score: 0.8766\n",
        "This score, based on Sentence-BERT, is a measure of semantic overlap. A score of 0.8766 is exceptionally high and suggests that your generated summaries are very close in meaning and content to the reference extractive summaries. This is a great sign that your summarization logic is selecting sentences that are highly relevant to the source text.\n",
        "\n",
        "BERTScore\n",
        "Average BERTScore Precision: 0.8049\n",
        "\n",
        "Average BERTScore Recall: 0.8284\n",
        "\n",
        "Average BERTScore F1: 0.8162\n",
        "BERTScore measures the similarity between generated and reference sentences using contextual embeddings from a BERT model.\n",
        "\n",
        "Precision (0.8049): This indicates that around 80% of the sentences in your generated summaries are semantically relevant to the reference summary.\n",
        "\n",
        "Recall (0.8284): This suggests that your generated summaries cover about 83% of the important information present in the reference summary.\n",
        "\n",
        "F1 (0.8162): This is the harmonic mean of precision and recall. An F1 score of 0.8162 is a strong result, showing a good balance between generating relevant content and covering the key points from the reference.\n",
        "\n",
        "In summary, your model is performing very effectively.\n",
        "\n",
        "The high Paragraph Similarity score confirms that the generated summaries are semantically aligned with the reference.\n",
        "\n",
        "The strong BERTScore indicates a robust performance, with a good balance of relevance (Precision) and completeness (Recall).\n",
        "\n",
        "You can be confident that the summarization pipeline you've built is a very solid performer on this dataset."
      ],
      "metadata": {
        "id": "JvgIPGTJ-ifW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Abstractive summary using BART with rephrase guidance"
      ],
      "metadata": {
        "id": "3HarvI_vWzoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries (only runs if not already installed)\n",
        "#%pip install transformers torch\n",
        "\n",
        "import torch\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "# --- Load BART Model and Tokenizer ---\n",
        "print(\"Loading BART model and tokenizer for fluent rephrasing...\")\n",
        "bart_model_name = 'facebook/bart-large-cnn' # A good choice for this task\n",
        "bart_tokenizer = BartTokenizer.from_pretrained(bart_model_name)\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(bart_model_name)\n",
        "\n",
        "# --- Set Device (GPU if available, else CPU) ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bart_model.eval() # Set to evaluation mode\n",
        "bart_model.to(device)\n",
        "print(f\"BART using device: {device}\")\n",
        "print(\"BART model loaded.\")\n",
        "\n",
        "def bart_fluent_rephrase(text_to_rephrase, num_beams=4):\n",
        "    \"\"\"\n",
        "    Rephrases a text for fluency without heavy compression,\n",
        "    using the pre-loaded BART model.\n",
        "\n",
        "    This function attempts to use most of the original sentences\n",
        "    but rephrases them for better flow and coherence.\n",
        "\n",
        "    Args:\n",
        "        text_to_rephrase (str or list of str): The input text to rephrase.\n",
        "                                               If a list, it will be joined.\n",
        "        num_beams (int): Number of beams for beam search. Higher values\n",
        "                         lead to better quality but slower generation.\n",
        "\n",
        "    Returns:\n",
        "        str: The rephrased and fluent text.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Starting BART Fluent Rephrasing ---\")\n",
        "\n",
        "    if isinstance(text_to_rephrase, list):\n",
        "        text_to_rephrase = \" \".join(text_to_rephrase)\n",
        "\n",
        "    if not text_to_rephrase.strip():\n",
        "        print(\"Input text for rephrasing is empty. Cannot rephrase.\")\n",
        "        return \"\"\n",
        "\n",
        "    # Get input length to set an appropriate max output length\n",
        "    input_ids = bart_tokenizer(\n",
        "        [text_to_rephrase],\n",
        "        max_length=1024,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True\n",
        "    ).to(device)\n",
        "\n",
        "    # We set max_length to be close to the input length\n",
        "    # to encourage the model not to heavily compress.\n",
        "    # We use the number of tokens as a reference.\n",
        "    input_len = input_ids[\"input_ids\"].shape[1]\n",
        "    rephrase_max_length = int(input_len)  # Allow some expansion\n",
        "    rephrase_min_length = int(input_len * 0.4)  # Prevent too much compression\n",
        "\n",
        "    print(f\"Input text length (tokens): {input_len}\")\n",
        "    print(f\"Setting rephrase max_length to: {rephrase_max_length}\")\n",
        "    print(f\"Setting rephrase min_length to: {rephrase_min_length}\")\n",
        "\n",
        "    # Generate the rephrased text\n",
        "    rephrased_ids = bart_model.generate(\n",
        "        input_ids[\"input_ids\"],\n",
        "        num_beams=num_beams,\n",
        "        max_length=rephrase_max_length,\n",
        "        min_length=rephrase_min_length,\n",
        "        early_stopping=True,\n",
        "        length_penalty=0.1 # A smaller length_penalty encourages longer output\n",
        "    )\n",
        "\n",
        "    rephrased_text = bart_tokenizer.decode(rephrased_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    print(\"--- BART Fluent Rephrasing Complete ---\")\n",
        "    return rephrased_text\n",
        "\n",
        "# --- Example Usage ---\n",
        "# Assuming 'extractive_summary' is already a string of sentences.\n",
        "# If you don't have an extractive summary, you can use any long text.\n",
        "#extractive_summary = \"The study found that regular exercise significantly improves cardiovascular health. Participants who exercised for at least 150 minutes a week showed a 25% reduction in heart disease risk. This benefit was observed across all age groups and fitness levels. The researchers recommend incorporating both aerobic and strength-training activities into a weekly routine.\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Original Extractive Summary:\")\n",
        "print(extractive_summary)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Fluent Rephrased Version (using BART):\")\n",
        "rephrased_text = bart_fluent_rephrase(\n",
        "    extractive_summary,\n",
        "    num_beams=4\n",
        ")\n",
        "print(rephrased_text)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Rephrasing complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576,
          "referenced_widgets": [
            "22537df3b83c4f9aa4e4e58856a83cdc",
            "40f3661aaede4d398399e6b962ebd7cb",
            "76da52345e3a498c94269499ee4a92c4",
            "3668a72f28fa4d3c842f3d7b8c1e77df",
            "c003ff3b8ca94ecaafb17f7f49953c60",
            "830ec8e9a4d6469cb181803868ef11ee",
            "fac7d9c1fc644871942b372d6c280676",
            "1d5cd66bd4a94e6fbd86760e91cb50ca",
            "0afdd3a8776742d2a682348fec6a1695",
            "5aa53c4ee46647958645d47d6a01ade7",
            "adcc9dfd4f564776885fb55c58f900ed",
            "518e7080508d446c98afacdc625758c9",
            "d50375b8adc4427f9f7bece38b339e68",
            "63df4d908b454f98a99f77e98980d918",
            "f2d421fb036e4de39b4f6f7d83ee66f7",
            "c0cb47a7ef344658ab163cdb49fc963f",
            "f94d14b8b33a40fdb4abc88c7770bc80",
            "74ecf0fb6cf4421ea6755443918d46f4",
            "935ebf5b94f44dfea6307d170af82b25",
            "c130afc296d449b39f97cef531b63297",
            "ef46336c625c41faa09efb9949059e7c",
            "6487755510af44e395d02e73f1fadca8",
            "2f0a6d59a9864d209eb37083ad635f19",
            "6ce4b3904a2f42fabe095ed800132932",
            "496979664779400c9daa12354a5ee93b",
            "50b67aeea7d64100b32d9185ca0be4c7",
            "c02593a968ed460380acf2e65197cd2b",
            "e0d804d067aa490e99e006715f240bc0",
            "77d9c4c95123455b93825d8077678159",
            "244423e696874033ac23096e3b397b1b",
            "ff2b51400bb14de8a7802835f93faccf",
            "01e76dcf787c4f1a88960bb4b072f360",
            "b15d8c8f2f0b4653a1e2b0bf6c3d59fc",
            "19b2425326eb49df9c14e6518665d7ac",
            "99e2b523bd9c4e91a7a422a40be7291e",
            "11fec2d312324bac8631c5b3ded6735e",
            "3fbcdc6f34134741a5897aff2b3b265c",
            "75693058f5824163967ff9779ce68c79",
            "f4b1121adf8541a8ae58a74f5042dfc6",
            "04997f88a06944c8885fd7ef83d447e7",
            "c2b7dfc774c44a5e9e49e1fa1945219b",
            "bd64653d45a84e5eb6a97a9bee5e6801",
            "7574d97ce7e24ffba324c0f684d2ee4a",
            "4251cd99154b4a55b449c4a572e59170",
            "4493f98683da472a8157724a4c3184f0",
            "0ca3d330663943e89c102be90eb3e0f8",
            "a80f2595751848d8a608c6bbb8085101",
            "53953922e15f452db9b1d090d2ecb23e",
            "5018a79d8de842a29edc2d4b2fa7363e",
            "0c38ee423c544f7bb34efa6772459719",
            "9eb8761156eb447283bb61c7631db9f2",
            "996139d3fdcb4f56bd3dc79914eaeef0",
            "3cbfa6c7a6234a4fbc796bebf500a904",
            "22b8818fb6ee4dccb04b9be1930c06dd",
            "8e9cabb5b1674b98b65c0d4ddb42130d",
            "f26d4473ba1e41e7839d2ba9fac676e9",
            "614a102da597452baba1e0649d4b30aa",
            "69dd7d9061244c1390ec451c5db1a13e",
            "1c796f12024c4dcd83081a1d17f410ac",
            "b35402a7da524170b707232c68beee6d",
            "83c4e7e3ebb342beb24a8d729468a45f",
            "17a1c36a6dda491d912ba5ceadf40efc",
            "7ea161c5589d4846976a9c27961ecc43",
            "7f18590cc9af451bb55118ed64199b69",
            "bc0cd42a6b2a4af593a1603733368ddc",
            "9705759e7dbd47129c6795e2e145c161"
          ]
        },
        "id": "akL7J-I4XIiR",
        "outputId": "2a89ed87-6dda-491c-9713-98740c43f581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BART model and tokenizer for fluent rephrasing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22537df3b83c4f9aa4e4e58856a83cdc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "518e7080508d446c98afacdc625758c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f0a6d59a9864d209eb37083ad635f19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19b2425326eb49df9c14e6518665d7ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4493f98683da472a8157724a4c3184f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f26d4473ba1e41e7839d2ba9fac676e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BART using device: cuda\n",
            "BART model loaded.\n",
            "\n",
            "================================================================================\n",
            "Original Extractive Summary:\n",
            "FDA and USDA have responsibility for overseeing the safety of the food supply. General information about the process of making cell-cultured meat is available, but specific information about the technology being used and the eventual commercial production methods as well as the final products is not yet known. However, the technology and methods to commercially produce cell- cultured meat are still in development, and producers, regulators, and consumers do not yet have clarity on what these will entail. The composition of the final product is also not yet known. The general process for making cell-cultured meat contains five phases: biopsy, cell banking, growth, harvest, and food processing. The technology to produce cell-cultured meat at a commercial scale is still in development, and information about the methods to be used for commercial production and the composition of the final product are not yet known. Consequently, they have not finalized aspects of the technology and eventual commercial production methods to be used or the composition of the final product. As a result, certain information is not yet available to stakeholders—including cell-cultured meat firms themselves, regulators, and the public—about specific aspects of the technology and commercial production methods that will be used, such as the composition of the growth medium and of the final products. This lack of information results in unanswered questions about cell- cultured meat as it relates to the eventual technology and commercial production methods to be used and the composition of the final products. Some firms have developed prototypes of cell-cultured meat products as part of their research and development. In June 2019, FDA and USDA created three working groups to carry out the terms of the interagency agreement. FDA and USDA could more fully incorporate leading practices for collaboration in their interagency agreement and working groups. Developing and updating written guidance and agreements. However, the agreement does not describe how the agencies will track and monitor progress toward outcomes. Developing and updating written guidance and agreements. Developing and updating written guidance and agreements. Developing and updating written guidance and agreements. By more fully incorporating all seven leading practices for interagency collaboration early in the development of the three working groups, FDA and USDA could proactively minimize potential fragmentation and overlap in their oversight of cell-cultured meat, ensure consistency and efficient use of resources, and provide clarity to key stakeholders. While FDA and USDA officials told us they have decided who will oversee cell-cultured seafood, they have not formally announced or documented this decision, and some stakeholders have reported confusion or ambiguity about which agency will oversee cell-cultured seafood other than catfish. While FDA and USDA officials told us they had agreed that FDA would oversee cell-cultured seafood other than catfish, as of December 2019, the agencies had not formally announced or documented this agreement. Developing and updating written guidance and agreements is a leading practice for collaboration, as we have previously reported. Compounding this challenge is that specific information about key aspects of cell-cultured meat, such as the technology and production methods to be used as well as the composition of the products, is not yet known. FDA and USDA officials told us they have decided FDA will oversee most cell-cultured seafood, but the agencies have not formally documented this decision. We agree that the technology to produce cell-cultured meat is still in development and that information about the commercial production methods and composition of the final product are not yet known, as we state in our report. FDA concurred with two recommendations and partially concurred with one. USDA also concurred with two recommendations and partially concurred with one. FDA and USDA partially concurred with our recommendation, directed to each agency, to more fully incorporate the seven leading practices for effective collaboration into the agencies’ interagency agreement for the joint oversight of cell-cultured meat. We continue to believe that FDA and USDA should more fully incorporate the seven leading practices for effective collaboration into their interagency agreement for the joint oversight of cell-cultured meat. GAO staff who made key contributions to this report are listed in appendix V. Our report (1) describes what is known about methods for commercially producing cell-cultured meat and (2) examines the extent to which the Food and Drug Administration (FDA) and U.S. Department of Agriculture (USDA) are collaborating to provide regulatory oversight of cell-cultured meat. Developing and updating written guidance and agreements How will the collaborative mechanism be funded?\n",
            "\n",
            "================================================================================\n",
            "Fluent Rephrased Version (using BART):\n",
            "\n",
            "--- Starting BART Fluent Rephrasing ---\n",
            "Input text length (tokens): 893\n",
            "Setting rephrase max_length to: 893\n",
            "Setting rephrase min_length to: 357\n",
            "--- BART Fluent Rephrasing Complete ---\n",
            "FDA and USDA have responsibility for overseeing the safety of the food supply. The technology to produce cell-cultured meat at a commercial scale is still in development. The composition of the final product is also not yet known. FDA and USDA could more fully incorporate leading practices for collaboration into their interagency agreement for the joint oversight of cell- Cultured meat, the GAO says. The agreement does not describe how the agencies will track and monitor progress toward outcomes, the report says. the agencies could proactively minimize potential fragmentation and overlap in their oversight, ensure consistency and efficient use of resources, and provide clarity to key stakeholders, it adds. The GAO recommends that the agencies incorporate the seven leading practices into the agencies’ inter Agency agreement for. the joint Oversight of Cell Cultured Meat. The agencies should also develop and update written guidance and agreements for the development and production of cell cultured meat. The report also asks how the U.S. Department of Agriculture and FDA will be funded to provide regulatory oversight of the cell- cultured meat. the agencies have not formally announced or documented this agreement as of December 2019, theGAO says, and some stakeholders have reported confusion or ambiguity about which agency will oversee cell- cultured seafood other than catfish. The agency recommends the agencies fully incorporate the leading practices. for effective collaboration into the agency’s inter Agency Agreement for the Joint Oversight of cell Cultured. Meat. FDA concurred with two recommendations and partially concurring with one. USDA also concurred, directed to each agency, to more fully incorporated the seven. practices for effective. collaboration into its intergency agreement for cell-ultra-stocked meat. It also recommends developing and updating written guidance. and agreements, as we state in our report.\n",
            "\n",
            "================================================================================\n",
            "Rephrasing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#mount drive and install libraries"
      ],
      "metadata": {
        "id": "ziKxkcrE8yAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZcy6pyUVZbG",
        "outputId": "4d092884-47a0-4718-fc62-351fda898dda"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ7-CJ7DVlk_",
        "outputId": "1c506db4-957c-4482-b4af-7135de697738"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install rouge_score\n",
        "!pip install bert_score\n",
        "#!pip install BertForSequenceClassification\n",
        "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "#!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moidabAvbmYi",
        "outputId": "b3ac5503-2b17-431a-accb-d967b42a59ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.34.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.5\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=633f9bc54a3dcb8f969d1a382fe846450ca2634f1a98a9dc4a64a83bec44d926\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.54.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.34.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.8.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert_score) (1.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert_score\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bert_score-0.3.13 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    }
  ]
}